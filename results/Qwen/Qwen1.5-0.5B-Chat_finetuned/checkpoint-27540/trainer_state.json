{
  "best_metric": 0.4219246208667755,
  "best_model_checkpoint": "./results/Qwen/Qwen1.5-0.5B-Chat_finetuned/checkpoint-27540",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 27540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 64.04972076416016,
      "learning_rate": 9e-06,
      "loss": 12.2419,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 11.631272315979004,
      "learning_rate": 1.88e-05,
      "loss": 6.3549,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 2.2032947540283203,
      "learning_rate": 2.88e-05,
      "loss": 0.9275,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 4.570879936218262,
      "learning_rate": 3.88e-05,
      "loss": 0.5026,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.6001814603805542,
      "learning_rate": 4.88e-05,
      "loss": 0.4667,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 1.8884224891662598,
      "learning_rate": 4.9837278106508875e-05,
      "loss": 0.4791,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.5699498057365417,
      "learning_rate": 4.965236686390533e-05,
      "loss": 0.4563,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.6481728553771973,
      "learning_rate": 4.946745562130178e-05,
      "loss": 0.472,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.6715210676193237,
      "learning_rate": 4.928254437869823e-05,
      "loss": 0.4251,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 5.877320766448975,
      "learning_rate": 4.909763313609468e-05,
      "loss": 0.4219,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.36116382479667664,
      "learning_rate": 4.8912721893491126e-05,
      "loss": 0.4366,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 2.2116036415100098,
      "learning_rate": 4.872781065088758e-05,
      "loss": 0.4615,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.6033746600151062,
      "learning_rate": 4.8542899408284026e-05,
      "loss": 0.475,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.920131266117096,
      "learning_rate": 4.835798816568047e-05,
      "loss": 0.5385,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.4554869830608368,
      "learning_rate": 4.8173076923076925e-05,
      "loss": 0.4171,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.34214237332344055,
      "learning_rate": 4.798816568047337e-05,
      "loss": 0.4384,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.3212849795818329,
      "learning_rate": 4.7803254437869824e-05,
      "loss": 0.4224,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 1.2667738199234009,
      "learning_rate": 4.761834319526628e-05,
      "loss": 0.4463,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.2666592597961426,
      "learning_rate": 4.743343195266273e-05,
      "loss": 0.4372,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.7728605270385742,
      "learning_rate": 4.7248520710059176e-05,
      "loss": 0.3864,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.9098959565162659,
      "learning_rate": 4.706360946745562e-05,
      "loss": 0.4274,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.8496221303939819,
      "learning_rate": 4.6878698224852075e-05,
      "loss": 0.3781,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.2571764588356018,
      "learning_rate": 4.669378698224852e-05,
      "loss": 0.4488,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.5879747867584229,
      "learning_rate": 4.6508875739644975e-05,
      "loss": 0.4764,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.6175165772438049,
      "learning_rate": 4.632396449704142e-05,
      "loss": 0.41,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.7312668561935425,
      "learning_rate": 4.613905325443787e-05,
      "loss": 0.4927,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.7903152704238892,
      "learning_rate": 4.595414201183432e-05,
      "loss": 0.415,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.6992776393890381,
      "learning_rate": 4.576923076923077e-05,
      "loss": 0.4068,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.8023319244384766,
      "learning_rate": 4.5584319526627226e-05,
      "loss": 0.408,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.6706069707870483,
      "learning_rate": 4.539940828402367e-05,
      "loss": 0.3503,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.6931501030921936,
      "learning_rate": 4.5214497041420125e-05,
      "loss": 0.408,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.8935757279396057,
      "learning_rate": 4.502958579881657e-05,
      "loss": 0.4067,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 1.0114938020706177,
      "learning_rate": 4.484467455621302e-05,
      "loss": 0.4393,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.5516098737716675,
      "learning_rate": 4.465976331360947e-05,
      "loss": 0.5071,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.7390721440315247,
      "learning_rate": 4.447485207100592e-05,
      "loss": 0.3764,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.9125017523765564,
      "learning_rate": 4.428994082840237e-05,
      "loss": 0.4531,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.7681573629379272,
      "learning_rate": 4.4105029585798816e-05,
      "loss": 0.4138,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.7746248245239258,
      "learning_rate": 4.3921967455621306e-05,
      "loss": 0.4238,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.8007177114486694,
      "learning_rate": 4.373705621301775e-05,
      "loss": 0.4323,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.8174846172332764,
      "learning_rate": 4.3552144970414205e-05,
      "loss": 0.4761,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.4638083577156067,
      "learning_rate": 4.336723372781065e-05,
      "loss": 0.4412,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.8762468695640564,
      "learning_rate": 4.3182322485207105e-05,
      "loss": 0.386,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.6127588748931885,
      "learning_rate": 4.299741124260355e-05,
      "loss": 0.4415,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.21072432398796082,
      "learning_rate": 4.28125e-05,
      "loss": 0.4406,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.5719848871231079,
      "learning_rate": 4.262758875739645e-05,
      "loss": 0.4101,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.9786091446876526,
      "learning_rate": 4.24426775147929e-05,
      "loss": 0.4385,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.841009795665741,
      "learning_rate": 4.2257766272189356e-05,
      "loss": 0.4236,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.5245518088340759,
      "learning_rate": 4.20728550295858e-05,
      "loss": 0.3732,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.6227128505706787,
      "learning_rate": 4.1887943786982255e-05,
      "loss": 0.435,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.925540030002594,
      "learning_rate": 4.17030325443787e-05,
      "loss": 0.4758,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.6650662422180176,
      "learning_rate": 4.151812130177515e-05,
      "loss": 0.3665,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.474563330411911,
      "learning_rate": 4.13332100591716e-05,
      "loss": 0.4428,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.6567142605781555,
      "learning_rate": 4.114829881656805e-05,
      "loss": 0.4377,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.1159498691558838,
      "learning_rate": 4.09633875739645e-05,
      "loss": 0.4412,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.46054285764694214,
      "learning_rate": 4.0778476331360946e-05,
      "loss": 0.4016,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.8939189314842224,
      "learning_rate": 4.05935650887574e-05,
      "loss": 0.4334,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.6222503781318665,
      "learning_rate": 4.040865384615385e-05,
      "loss": 0.3972,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.6562085747718811,
      "learning_rate": 4.02237426035503e-05,
      "loss": 0.3891,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.6770157217979431,
      "learning_rate": 4.003883136094675e-05,
      "loss": 0.3755,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.7638810873031616,
      "learning_rate": 3.98539201183432e-05,
      "loss": 0.4521,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.7228004336357117,
      "learning_rate": 3.966900887573965e-05,
      "loss": 0.4208,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.6695002317428589,
      "learning_rate": 3.94840976331361e-05,
      "loss": 0.4567,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.4219883382320404,
      "learning_rate": 3.929918639053254e-05,
      "loss": 0.4229,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.37800994515419006,
      "learning_rate": 3.9114275147928996e-05,
      "loss": 0.454,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.37366387248039246,
      "learning_rate": 3.892936390532544e-05,
      "loss": 0.4512,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.8677705526351929,
      "learning_rate": 3.8744452662721895e-05,
      "loss": 0.3927,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.7658491134643555,
      "learning_rate": 3.855954142011835e-05,
      "loss": 0.4574,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.6900949478149414,
      "learning_rate": 3.8374630177514794e-05,
      "loss": 0.4186,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.8294160962104797,
      "learning_rate": 3.818971893491125e-05,
      "loss": 0.4767,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.23066987097263336,
      "learning_rate": 3.8004807692307693e-05,
      "loss": 0.456,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.7206637859344482,
      "learning_rate": 3.7819896449704146e-05,
      "loss": 0.4121,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.6606494784355164,
      "learning_rate": 3.763683431952663e-05,
      "loss": 0.4215,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.47847986221313477,
      "learning_rate": 3.7451923076923076e-05,
      "loss": 0.3857,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.4462446868419647,
      "learning_rate": 3.726701183431953e-05,
      "loss": 0.452,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.751960039138794,
      "learning_rate": 3.708210059171598e-05,
      "loss": 0.4134,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.7784746289253235,
      "learning_rate": 3.689718934911243e-05,
      "loss": 0.3982,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.5726194977760315,
      "learning_rate": 3.671227810650888e-05,
      "loss": 0.406,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.8245075941085815,
      "learning_rate": 3.652736686390533e-05,
      "loss": 0.4383,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 1.2966547012329102,
      "learning_rate": 3.6342455621301774e-05,
      "loss": 0.4445,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.9495937824249268,
      "learning_rate": 3.615754437869823e-05,
      "loss": 0.4122,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.4681567847728729,
      "learning_rate": 3.597263313609467e-05,
      "loss": 0.3778,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.46206364035606384,
      "learning_rate": 3.5787721893491126e-05,
      "loss": 0.4432,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.8720418810844421,
      "learning_rate": 3.560281065088757e-05,
      "loss": 0.4548,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.3295484185218811,
      "learning_rate": 3.5417899408284025e-05,
      "loss": 0.4049,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.37500301003456116,
      "learning_rate": 3.523298816568048e-05,
      "loss": 0.4267,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.6965214610099792,
      "learning_rate": 3.5048076923076924e-05,
      "loss": 0.4866,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.7521867156028748,
      "learning_rate": 3.486316568047338e-05,
      "loss": 0.4781,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.6308198571205139,
      "learning_rate": 3.4678254437869824e-05,
      "loss": 0.4007,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.8211206197738647,
      "learning_rate": 3.4493343195266276e-05,
      "loss": 0.4289,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.34797027707099915,
      "learning_rate": 3.430843195266272e-05,
      "loss": 0.4082,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.535792887210846,
      "learning_rate": 3.4123520710059176e-05,
      "loss": 0.3834,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.4334779381752014,
      "eval_runtime": 74.0033,
      "eval_samples_per_second": 50.809,
      "eval_steps_per_second": 12.702,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.4340839385986328,
      "learning_rate": 3.393860946745562e-05,
      "loss": 0.3983,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.6533392071723938,
      "learning_rate": 3.375369822485207e-05,
      "loss": 0.4622,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.5457403063774109,
      "learning_rate": 3.356878698224852e-05,
      "loss": 0.4308,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.9688844084739685,
      "learning_rate": 3.3383875739644974e-05,
      "loss": 0.4145,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.7950826287269592,
      "learning_rate": 3.319896449704143e-05,
      "loss": 0.3886,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.8739873170852661,
      "learning_rate": 3.301405325443787e-05,
      "loss": 0.4312,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.6960287690162659,
      "learning_rate": 3.282914201183432e-05,
      "loss": 0.3747,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.9556367993354797,
      "learning_rate": 3.264423076923077e-05,
      "loss": 0.3966,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.43931660056114197,
      "learning_rate": 3.245931952662722e-05,
      "loss": 0.4203,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 1.0185792446136475,
      "learning_rate": 3.227440828402367e-05,
      "loss": 0.4324,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.582528293132782,
      "learning_rate": 3.208949704142012e-05,
      "loss": 0.4138,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 0.7217904329299927,
      "learning_rate": 3.190458579881657e-05,
      "loss": 0.4149,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 1.0530952215194702,
      "learning_rate": 3.171967455621302e-05,
      "loss": 0.4259,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.4488348066806793,
      "learning_rate": 3.153476331360946e-05,
      "loss": 0.4395,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.8924036026000977,
      "learning_rate": 3.1349852071005916e-05,
      "loss": 0.4297,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.7961572408676147,
      "learning_rate": 3.116494082840237e-05,
      "loss": 0.3999,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.7123920321464539,
      "learning_rate": 3.098002958579882e-05,
      "loss": 0.413,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.23665733635425568,
      "learning_rate": 3.079511834319527e-05,
      "loss": 0.4167,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.6022851467132568,
      "learning_rate": 3.061020710059172e-05,
      "loss": 0.4193,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.9687831401824951,
      "learning_rate": 3.0425295857988168e-05,
      "loss": 0.4302,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 1.0251038074493408,
      "learning_rate": 3.0240384615384614e-05,
      "loss": 0.408,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.464552640914917,
      "learning_rate": 3.0055473372781067e-05,
      "loss": 0.4295,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.7386693954467773,
      "learning_rate": 2.9870562130177516e-05,
      "loss": 0.4511,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.6907594799995422,
      "learning_rate": 2.968565088757397e-05,
      "loss": 0.3978,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.994949996471405,
      "learning_rate": 2.9500739644970416e-05,
      "loss": 0.4484,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.6344269514083862,
      "learning_rate": 2.9315828402366862e-05,
      "loss": 0.3716,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.13114212453365326,
      "learning_rate": 2.9130917159763315e-05,
      "loss": 0.424,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.943494439125061,
      "learning_rate": 2.8946005917159764e-05,
      "loss": 0.4294,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 8.698081728653051e-06,
      "learning_rate": 2.8761094674556217e-05,
      "loss": 0.4045,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.8330889344215393,
      "learning_rate": 2.8576183431952664e-05,
      "loss": 0.406,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.5430751442909241,
      "learning_rate": 2.8391272189349117e-05,
      "loss": 0.4524,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 1.0536119937896729,
      "learning_rate": 2.8206360946745563e-05,
      "loss": 0.42,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.4780873954296112,
      "learning_rate": 2.8021449704142012e-05,
      "loss": 0.4477,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.507489025592804,
      "learning_rate": 2.7836538461538465e-05,
      "loss": 0.4414,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.5345278382301331,
      "learning_rate": 2.7651627218934912e-05,
      "loss": 0.3588,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.7203753590583801,
      "learning_rate": 2.7466715976331365e-05,
      "loss": 0.4265,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.9737878441810608,
      "learning_rate": 2.728180473372781e-05,
      "loss": 0.3935,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.7073540687561035,
      "learning_rate": 2.709689349112426e-05,
      "loss": 0.4238,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.4536120593547821,
      "learning_rate": 2.6911982248520713e-05,
      "loss": 0.405,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 0.7640891075134277,
      "learning_rate": 2.672707100591716e-05,
      "loss": 0.3909,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 1.1767284870147705,
      "learning_rate": 2.6542159763313613e-05,
      "loss": 0.4619,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.9839314222335815,
      "learning_rate": 2.635724852071006e-05,
      "loss": 0.3821,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.5689833164215088,
      "learning_rate": 2.6172337278106512e-05,
      "loss": 0.3495,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.1727741956710815,
      "learning_rate": 2.5987426035502958e-05,
      "loss": 0.4422,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.21033214032649994,
      "learning_rate": 2.5802514792899408e-05,
      "loss": 0.4577,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.09380107372999191,
      "learning_rate": 2.561760355029586e-05,
      "loss": 0.3735,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.3991899788379669,
      "learning_rate": 2.5432692307692307e-05,
      "loss": 0.3949,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.4157956838607788,
      "learning_rate": 2.524778106508876e-05,
      "loss": 0.4247,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.5498453378677368,
      "learning_rate": 2.5062869822485206e-05,
      "loss": 0.3786,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.6124791502952576,
      "learning_rate": 2.487795857988166e-05,
      "loss": 0.3955,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 0.7263675332069397,
      "learning_rate": 2.469304733727811e-05,
      "loss": 0.4269,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.6786733865737915,
      "learning_rate": 2.4508136094674558e-05,
      "loss": 0.4041,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.8058057427406311,
      "learning_rate": 2.4323224852071008e-05,
      "loss": 0.4436,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.8870447278022766,
      "learning_rate": 2.4138313609467454e-05,
      "loss": 0.4036,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.4017833471298218,
      "learning_rate": 2.3953402366863907e-05,
      "loss": 0.4119,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.6457136869430542,
      "learning_rate": 2.3768491124260357e-05,
      "loss": 0.3649,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.3283866345882416,
      "learning_rate": 2.3583579881656806e-05,
      "loss": 0.4401,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 0.6512420177459717,
      "learning_rate": 2.3398668639053256e-05,
      "loss": 0.3648,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.9022144675254822,
      "learning_rate": 2.3213757396449705e-05,
      "loss": 0.3946,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.3460899293422699,
      "learning_rate": 2.3028846153846155e-05,
      "loss": 0.405,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.635513424873352,
      "learning_rate": 2.2843934911242605e-05,
      "loss": 0.3953,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.18054237961769104,
      "learning_rate": 2.2659023668639054e-05,
      "loss": 0.4213,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.8961628079414368,
      "learning_rate": 2.2474112426035504e-05,
      "loss": 0.4278,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.8165940046310425,
      "learning_rate": 2.2289201183431953e-05,
      "loss": 0.372,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.49947261810302734,
      "learning_rate": 2.2104289940828403e-05,
      "loss": 0.4046,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.48827776312828064,
      "learning_rate": 2.1919378698224856e-05,
      "loss": 0.4262,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 0.6190614104270935,
      "learning_rate": 2.1734467455621302e-05,
      "loss": 0.3503,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.20506702363491058,
      "learning_rate": 2.1549556213017752e-05,
      "loss": 0.4038,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 2.0210418701171875,
      "learning_rate": 2.13646449704142e-05,
      "loss": 0.3955,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.7238019108772278,
      "learning_rate": 2.117973372781065e-05,
      "loss": 0.4616,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.7417299151420593,
      "learning_rate": 2.09948224852071e-05,
      "loss": 0.4484,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.982831597328186,
      "learning_rate": 2.0809911242603554e-05,
      "loss": 0.4672,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.6627276539802551,
      "learning_rate": 2.0625e-05,
      "loss": 0.3944,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.7698923945426941,
      "learning_rate": 2.044008875739645e-05,
      "loss": 0.4144,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 0.7938433885574341,
      "learning_rate": 2.02551775147929e-05,
      "loss": 0.4525,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.1626601219177246,
      "learning_rate": 2.007026627218935e-05,
      "loss": 0.3997,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.5236369967460632,
      "learning_rate": 1.98853550295858e-05,
      "loss": 0.4109,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.2266196608543396,
      "learning_rate": 1.970044378698225e-05,
      "loss": 0.4575,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.43497055768966675,
      "learning_rate": 1.9515532544378697e-05,
      "loss": 0.3943,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.5550044178962708,
      "learning_rate": 1.9330621301775147e-05,
      "loss": 0.4291,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.7834054231643677,
      "learning_rate": 1.9145710059171597e-05,
      "loss": 0.4116,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.519693911075592,
      "learning_rate": 1.896079881656805e-05,
      "loss": 0.4104,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.5096213817596436,
      "learning_rate": 1.87758875739645e-05,
      "loss": 0.4206,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.5347396731376648,
      "learning_rate": 1.859097633136095e-05,
      "loss": 0.3957,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.46045511960983276,
      "learning_rate": 1.8406065088757395e-05,
      "loss": 0.4186,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.9318269491195679,
      "learning_rate": 1.8221153846153845e-05,
      "loss": 0.4197,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.20112739503383636,
      "learning_rate": 1.8036242603550298e-05,
      "loss": 0.4101,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.3805740773677826,
      "learning_rate": 1.7851331360946747e-05,
      "loss": 0.3868,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.5968451499938965,
      "learning_rate": 1.7666420118343197e-05,
      "loss": 0.4072,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.8768048286437988,
      "learning_rate": 1.7481508875739646e-05,
      "loss": 0.4181,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.6617454290390015,
      "learning_rate": 1.7296597633136096e-05,
      "loss": 0.4262,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.5005815625190735,
      "learning_rate": 1.7111686390532546e-05,
      "loss": 0.401,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.42302206158638,
      "eval_runtime": 74.8631,
      "eval_samples_per_second": 50.225,
      "eval_steps_per_second": 12.556,
      "step": 18360
    },
    {
      "epoch": 2.0043572984749454,
      "grad_norm": 0.7435597777366638,
      "learning_rate": 1.6926775147928995e-05,
      "loss": 0.4169,
      "step": 18400
    },
    {
      "epoch": 2.0152505446623095,
      "grad_norm": 0.497974693775177,
      "learning_rate": 1.6741863905325445e-05,
      "loss": 0.3961,
      "step": 18500
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.43742236495018005,
      "learning_rate": 1.6556952662721894e-05,
      "loss": 0.4057,
      "step": 18600
    },
    {
      "epoch": 2.037037037037037,
      "grad_norm": 1.083342432975769,
      "learning_rate": 1.6372041420118344e-05,
      "loss": 0.3904,
      "step": 18700
    },
    {
      "epoch": 2.047930283224401,
      "grad_norm": 0.8216404318809509,
      "learning_rate": 1.6187130177514794e-05,
      "loss": 0.3913,
      "step": 18800
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.5811669230461121,
      "learning_rate": 1.6004068047337277e-05,
      "loss": 0.3807,
      "step": 18900
    },
    {
      "epoch": 2.0697167755991286,
      "grad_norm": 0.7262917160987854,
      "learning_rate": 1.581915680473373e-05,
      "loss": 0.4037,
      "step": 19000
    },
    {
      "epoch": 2.0806100217864922,
      "grad_norm": 0.7429524064064026,
      "learning_rate": 1.563424556213018e-05,
      "loss": 0.3887,
      "step": 19100
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.6895799040794373,
      "learning_rate": 1.544933431952663e-05,
      "loss": 0.4178,
      "step": 19200
    },
    {
      "epoch": 2.10239651416122,
      "grad_norm": 0.8351726531982422,
      "learning_rate": 1.526442307692308e-05,
      "loss": 0.3888,
      "step": 19300
    },
    {
      "epoch": 2.113289760348584,
      "grad_norm": 0.4807155728340149,
      "learning_rate": 1.5079511834319527e-05,
      "loss": 0.4357,
      "step": 19400
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 0.8114345073699951,
      "learning_rate": 1.4894600591715976e-05,
      "loss": 0.3809,
      "step": 19500
    },
    {
      "epoch": 2.1350762527233114,
      "grad_norm": 0.48160725831985474,
      "learning_rate": 1.4709689349112426e-05,
      "loss": 0.4182,
      "step": 19600
    },
    {
      "epoch": 2.1459694989106755,
      "grad_norm": 0.8791488409042358,
      "learning_rate": 1.4524778106508877e-05,
      "loss": 0.4315,
      "step": 19700
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.7051727771759033,
      "learning_rate": 1.4339866863905327e-05,
      "loss": 0.4173,
      "step": 19800
    },
    {
      "epoch": 2.167755991285403,
      "grad_norm": 0.46269744634628296,
      "learning_rate": 1.4154955621301777e-05,
      "loss": 0.3982,
      "step": 19900
    },
    {
      "epoch": 2.178649237472767,
      "grad_norm": 0.22810865938663483,
      "learning_rate": 1.3970044378698224e-05,
      "loss": 0.4125,
      "step": 20000
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 0.4538230001926422,
      "learning_rate": 1.3785133136094674e-05,
      "loss": 0.4582,
      "step": 20100
    },
    {
      "epoch": 2.2004357298474946,
      "grad_norm": 0.8154819011688232,
      "learning_rate": 1.3600221893491125e-05,
      "loss": 0.404,
      "step": 20200
    },
    {
      "epoch": 2.2113289760348582,
      "grad_norm": 0.3587926924228668,
      "learning_rate": 1.3415310650887575e-05,
      "loss": 0.3642,
      "step": 20300
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.6932384967803955,
      "learning_rate": 1.3230399408284025e-05,
      "loss": 0.369,
      "step": 20400
    },
    {
      "epoch": 2.233115468409586,
      "grad_norm": 0.5879182815551758,
      "learning_rate": 1.3045488165680476e-05,
      "loss": 0.3789,
      "step": 20500
    },
    {
      "epoch": 2.24400871459695,
      "grad_norm": 0.6211900115013123,
      "learning_rate": 1.2860576923076922e-05,
      "loss": 0.4059,
      "step": 20600
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 0.7269782423973083,
      "learning_rate": 1.2675665680473373e-05,
      "loss": 0.4071,
      "step": 20700
    },
    {
      "epoch": 2.265795206971678,
      "grad_norm": 0.8163368701934814,
      "learning_rate": 1.2490754437869823e-05,
      "loss": 0.4509,
      "step": 20800
    },
    {
      "epoch": 2.2766884531590414,
      "grad_norm": 0.6576777100563049,
      "learning_rate": 1.2305843195266273e-05,
      "loss": 0.4452,
      "step": 20900
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 1.0960209369659424,
      "learning_rate": 1.2120931952662724e-05,
      "loss": 0.4116,
      "step": 21000
    },
    {
      "epoch": 2.298474945533769,
      "grad_norm": 0.4919250011444092,
      "learning_rate": 1.1936020710059172e-05,
      "loss": 0.3714,
      "step": 21100
    },
    {
      "epoch": 2.309368191721133,
      "grad_norm": 0.19953036308288574,
      "learning_rate": 1.1751109467455621e-05,
      "loss": 0.4027,
      "step": 21200
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 0.642979085445404,
      "learning_rate": 1.1566198224852073e-05,
      "loss": 0.424,
      "step": 21300
    },
    {
      "epoch": 2.3311546840958606,
      "grad_norm": 0.6453372836112976,
      "learning_rate": 1.138128698224852e-05,
      "loss": 0.4476,
      "step": 21400
    },
    {
      "epoch": 2.342047930283224,
      "grad_norm": 0.8426482677459717,
      "learning_rate": 1.119637573964497e-05,
      "loss": 0.4088,
      "step": 21500
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.5423865914344788,
      "learning_rate": 1.1011464497041421e-05,
      "loss": 0.3878,
      "step": 21600
    },
    {
      "epoch": 2.363834422657952,
      "grad_norm": 0.9772096872329712,
      "learning_rate": 1.082655325443787e-05,
      "loss": 0.3704,
      "step": 21700
    },
    {
      "epoch": 2.374727668845316,
      "grad_norm": 0.8641853928565979,
      "learning_rate": 1.064164201183432e-05,
      "loss": 0.42,
      "step": 21800
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 0.6646125316619873,
      "learning_rate": 1.045673076923077e-05,
      "loss": 0.4026,
      "step": 21900
    },
    {
      "epoch": 2.3965141612200433,
      "grad_norm": 0.7070026993751526,
      "learning_rate": 1.0271819526627218e-05,
      "loss": 0.3718,
      "step": 22000
    },
    {
      "epoch": 2.4074074074074074,
      "grad_norm": 0.37944120168685913,
      "learning_rate": 1.008690828402367e-05,
      "loss": 0.4034,
      "step": 22100
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.0011630043154582381,
      "learning_rate": 9.901997041420119e-06,
      "loss": 0.4034,
      "step": 22200
    },
    {
      "epoch": 2.429193899782135,
      "grad_norm": 0.6943217515945435,
      "learning_rate": 9.717085798816569e-06,
      "loss": 0.4005,
      "step": 22300
    },
    {
      "epoch": 2.440087145969499,
      "grad_norm": 0.5329943299293518,
      "learning_rate": 9.532174556213018e-06,
      "loss": 0.4588,
      "step": 22400
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 0.6383951306343079,
      "learning_rate": 9.347263313609468e-06,
      "loss": 0.3872,
      "step": 22500
    },
    {
      "epoch": 2.4618736383442266,
      "grad_norm": 0.9263749718666077,
      "learning_rate": 9.162352071005917e-06,
      "loss": 0.449,
      "step": 22600
    },
    {
      "epoch": 2.47276688453159,
      "grad_norm": 0.735422670841217,
      "learning_rate": 8.977440828402367e-06,
      "loss": 0.3979,
      "step": 22700
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.6745180487632751,
      "learning_rate": 8.792529585798817e-06,
      "loss": 0.3631,
      "step": 22800
    },
    {
      "epoch": 2.494553376906318,
      "grad_norm": 0.5660250782966614,
      "learning_rate": 8.607618343195268e-06,
      "loss": 0.4594,
      "step": 22900
    },
    {
      "epoch": 2.505446623093682,
      "grad_norm": 0.9159849882125854,
      "learning_rate": 8.422707100591716e-06,
      "loss": 0.4351,
      "step": 23000
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 1.0757278203964233,
      "learning_rate": 8.237795857988165e-06,
      "loss": 0.4163,
      "step": 23100
    },
    {
      "epoch": 2.52723311546841,
      "grad_norm": 0.745202898979187,
      "learning_rate": 8.052884615384617e-06,
      "loss": 0.3658,
      "step": 23200
    },
    {
      "epoch": 2.5381263616557734,
      "grad_norm": 0.5461059808731079,
      "learning_rate": 7.867973372781065e-06,
      "loss": 0.4215,
      "step": 23300
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.9606163501739502,
      "learning_rate": 7.683062130177516e-06,
      "loss": 0.4051,
      "step": 23400
    },
    {
      "epoch": 2.559912854030501,
      "grad_norm": 0.466487318277359,
      "learning_rate": 7.4981508875739655e-06,
      "loss": 0.345,
      "step": 23500
    },
    {
      "epoch": 2.570806100217865,
      "grad_norm": 0.18099290132522583,
      "learning_rate": 7.313239644970414e-06,
      "loss": 0.4066,
      "step": 23600
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 0.29719892144203186,
      "learning_rate": 7.128328402366864e-06,
      "loss": 0.3691,
      "step": 23700
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.8216397166252136,
      "learning_rate": 6.945266272189349e-06,
      "loss": 0.4311,
      "step": 23800
    },
    {
      "epoch": 2.6034858387799567,
      "grad_norm": 0.6029112935066223,
      "learning_rate": 6.7603550295857994e-06,
      "loss": 0.4351,
      "step": 23900
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.7374087572097778,
      "learning_rate": 6.575443786982249e-06,
      "loss": 0.3704,
      "step": 24000
    },
    {
      "epoch": 2.625272331154684,
      "grad_norm": 0.534709632396698,
      "learning_rate": 6.390532544378698e-06,
      "loss": 0.4085,
      "step": 24100
    },
    {
      "epoch": 2.636165577342048,
      "grad_norm": 0.7375025749206543,
      "learning_rate": 6.205621301775148e-06,
      "loss": 0.3983,
      "step": 24200
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.687132716178894,
      "learning_rate": 6.020710059171598e-06,
      "loss": 0.3742,
      "step": 24300
    },
    {
      "epoch": 2.6579520697167753,
      "grad_norm": 0.5722280144691467,
      "learning_rate": 5.8357988165680474e-06,
      "loss": 0.3923,
      "step": 24400
    },
    {
      "epoch": 2.6688453159041394,
      "grad_norm": 0.0009844460291787982,
      "learning_rate": 5.650887573964497e-06,
      "loss": 0.4352,
      "step": 24500
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.6798281669616699,
      "learning_rate": 5.465976331360947e-06,
      "loss": 0.4497,
      "step": 24600
    },
    {
      "epoch": 2.690631808278867,
      "grad_norm": 0.8871850967407227,
      "learning_rate": 5.281065088757397e-06,
      "loss": 0.4174,
      "step": 24700
    },
    {
      "epoch": 2.701525054466231,
      "grad_norm": 0.7574030756950378,
      "learning_rate": 5.096153846153847e-06,
      "loss": 0.3745,
      "step": 24800
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 0.36322009563446045,
      "learning_rate": 4.9112426035502954e-06,
      "loss": 0.361,
      "step": 24900
    },
    {
      "epoch": 2.7233115468409586,
      "grad_norm": 0.403471440076828,
      "learning_rate": 4.726331360946746e-06,
      "loss": 0.3814,
      "step": 25000
    },
    {
      "epoch": 2.734204793028322,
      "grad_norm": 0.8059836626052856,
      "learning_rate": 4.5414201183431955e-06,
      "loss": 0.4016,
      "step": 25100
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.6218822002410889,
      "learning_rate": 4.356508875739645e-06,
      "loss": 0.4429,
      "step": 25200
    },
    {
      "epoch": 2.7559912854030504,
      "grad_norm": 0.5177469253540039,
      "learning_rate": 4.171597633136095e-06,
      "loss": 0.4304,
      "step": 25300
    },
    {
      "epoch": 2.766884531590414,
      "grad_norm": 0.34553062915802,
      "learning_rate": 3.986686390532544e-06,
      "loss": 0.4354,
      "step": 25400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.65328049659729,
      "learning_rate": 3.8017751479289947e-06,
      "loss": 0.4332,
      "step": 25500
    },
    {
      "epoch": 2.7886710239651418,
      "grad_norm": 0.4937220513820648,
      "learning_rate": 3.616863905325444e-06,
      "loss": 0.3745,
      "step": 25600
    },
    {
      "epoch": 2.7995642701525054,
      "grad_norm": 0.6506374478340149,
      "learning_rate": 3.4319526627218935e-06,
      "loss": 0.4564,
      "step": 25700
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.0013279400300234556,
      "learning_rate": 3.2470414201183435e-06,
      "loss": 0.3981,
      "step": 25800
    },
    {
      "epoch": 2.821350762527233,
      "grad_norm": 0.5531498789787292,
      "learning_rate": 3.062130177514793e-06,
      "loss": 0.4091,
      "step": 25900
    },
    {
      "epoch": 2.832244008714597,
      "grad_norm": 0.4500451982021332,
      "learning_rate": 2.8772189349112427e-06,
      "loss": 0.4183,
      "step": 26000
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 0.1987602412700653,
      "learning_rate": 2.6923076923076928e-06,
      "loss": 0.4199,
      "step": 26100
    },
    {
      "epoch": 2.8540305010893245,
      "grad_norm": 0.5421318411827087,
      "learning_rate": 2.507396449704142e-06,
      "loss": 0.3897,
      "step": 26200
    },
    {
      "epoch": 2.8649237472766886,
      "grad_norm": 0.7352844476699829,
      "learning_rate": 2.322485207100592e-06,
      "loss": 0.4209,
      "step": 26300
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.6966274976730347,
      "learning_rate": 2.1375739644970416e-06,
      "loss": 0.4663,
      "step": 26400
    },
    {
      "epoch": 2.886710239651416,
      "grad_norm": 0.4969979524612427,
      "learning_rate": 1.952662721893491e-06,
      "loss": 0.4447,
      "step": 26500
    },
    {
      "epoch": 2.89760348583878,
      "grad_norm": 0.8099727034568787,
      "learning_rate": 1.7677514792899408e-06,
      "loss": 0.3843,
      "step": 26600
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 0.775996208190918,
      "learning_rate": 1.5828402366863906e-06,
      "loss": 0.3741,
      "step": 26700
    },
    {
      "epoch": 2.9193899782135078,
      "grad_norm": 0.5889082551002502,
      "learning_rate": 1.3979289940828402e-06,
      "loss": 0.3626,
      "step": 26800
    },
    {
      "epoch": 2.9302832244008714,
      "grad_norm": 0.5580841302871704,
      "learning_rate": 1.21301775147929e-06,
      "loss": 0.4187,
      "step": 26900
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.7085564732551575,
      "learning_rate": 1.0281065088757396e-06,
      "loss": 0.4759,
      "step": 27000
    },
    {
      "epoch": 2.952069716775599,
      "grad_norm": 0.397280216217041,
      "learning_rate": 8.431952662721895e-07,
      "loss": 0.4245,
      "step": 27100
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.0012034588726237416,
      "learning_rate": 6.582840236686391e-07,
      "loss": 0.4019,
      "step": 27200
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 1.0665488243103027,
      "learning_rate": 4.733727810650888e-07,
      "loss": 0.3999,
      "step": 27300
    },
    {
      "epoch": 2.9847494553376905,
      "grad_norm": 0.43316274881362915,
      "learning_rate": 2.884615384615385e-07,
      "loss": 0.3957,
      "step": 27400
    },
    {
      "epoch": 2.9956427015250546,
      "grad_norm": 0.6888854503631592,
      "learning_rate": 1.0355029585798818e-07,
      "loss": 0.4143,
      "step": 27500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.4219246208667755,
      "eval_runtime": 73.3346,
      "eval_samples_per_second": 51.272,
      "eval_steps_per_second": 12.818,
      "step": 27540
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0449526580261683e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
