{
  "best_metric": 0.4334779381752014,
  "best_model_checkpoint": "./results/Qwen/Qwen1.5-0.5B-Chat_finetuned/checkpoint-9180",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 64.04972076416016,
      "learning_rate": 9e-06,
      "loss": 12.2419,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 11.631272315979004,
      "learning_rate": 1.88e-05,
      "loss": 6.3549,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 2.2032947540283203,
      "learning_rate": 2.88e-05,
      "loss": 0.9275,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 4.570879936218262,
      "learning_rate": 3.88e-05,
      "loss": 0.5026,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.6001814603805542,
      "learning_rate": 4.88e-05,
      "loss": 0.4667,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 1.8884224891662598,
      "learning_rate": 4.9837278106508875e-05,
      "loss": 0.4791,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.5699498057365417,
      "learning_rate": 4.965236686390533e-05,
      "loss": 0.4563,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.6481728553771973,
      "learning_rate": 4.946745562130178e-05,
      "loss": 0.472,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.6715210676193237,
      "learning_rate": 4.928254437869823e-05,
      "loss": 0.4251,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 5.877320766448975,
      "learning_rate": 4.909763313609468e-05,
      "loss": 0.4219,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.36116382479667664,
      "learning_rate": 4.8912721893491126e-05,
      "loss": 0.4366,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 2.2116036415100098,
      "learning_rate": 4.872781065088758e-05,
      "loss": 0.4615,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.6033746600151062,
      "learning_rate": 4.8542899408284026e-05,
      "loss": 0.475,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.920131266117096,
      "learning_rate": 4.835798816568047e-05,
      "loss": 0.5385,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.4554869830608368,
      "learning_rate": 4.8173076923076925e-05,
      "loss": 0.4171,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.34214237332344055,
      "learning_rate": 4.798816568047337e-05,
      "loss": 0.4384,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.3212849795818329,
      "learning_rate": 4.7803254437869824e-05,
      "loss": 0.4224,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 1.2667738199234009,
      "learning_rate": 4.761834319526628e-05,
      "loss": 0.4463,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.2666592597961426,
      "learning_rate": 4.743343195266273e-05,
      "loss": 0.4372,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.7728605270385742,
      "learning_rate": 4.7248520710059176e-05,
      "loss": 0.3864,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.9098959565162659,
      "learning_rate": 4.706360946745562e-05,
      "loss": 0.4274,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.8496221303939819,
      "learning_rate": 4.6878698224852075e-05,
      "loss": 0.3781,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.2571764588356018,
      "learning_rate": 4.669378698224852e-05,
      "loss": 0.4488,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.5879747867584229,
      "learning_rate": 4.6508875739644975e-05,
      "loss": 0.4764,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.6175165772438049,
      "learning_rate": 4.632396449704142e-05,
      "loss": 0.41,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.7312668561935425,
      "learning_rate": 4.613905325443787e-05,
      "loss": 0.4927,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.7903152704238892,
      "learning_rate": 4.595414201183432e-05,
      "loss": 0.415,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.6992776393890381,
      "learning_rate": 4.576923076923077e-05,
      "loss": 0.4068,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.8023319244384766,
      "learning_rate": 4.5584319526627226e-05,
      "loss": 0.408,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.6706069707870483,
      "learning_rate": 4.539940828402367e-05,
      "loss": 0.3503,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.6931501030921936,
      "learning_rate": 4.5214497041420125e-05,
      "loss": 0.408,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.8935757279396057,
      "learning_rate": 4.502958579881657e-05,
      "loss": 0.4067,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 1.0114938020706177,
      "learning_rate": 4.484467455621302e-05,
      "loss": 0.4393,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.5516098737716675,
      "learning_rate": 4.465976331360947e-05,
      "loss": 0.5071,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.7390721440315247,
      "learning_rate": 4.447485207100592e-05,
      "loss": 0.3764,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.9125017523765564,
      "learning_rate": 4.428994082840237e-05,
      "loss": 0.4531,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.7681573629379272,
      "learning_rate": 4.4105029585798816e-05,
      "loss": 0.4138,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.7746248245239258,
      "learning_rate": 4.3921967455621306e-05,
      "loss": 0.4238,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.8007177114486694,
      "learning_rate": 4.373705621301775e-05,
      "loss": 0.4323,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.8174846172332764,
      "learning_rate": 4.3552144970414205e-05,
      "loss": 0.4761,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.4638083577156067,
      "learning_rate": 4.336723372781065e-05,
      "loss": 0.4412,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.8762468695640564,
      "learning_rate": 4.3182322485207105e-05,
      "loss": 0.386,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.6127588748931885,
      "learning_rate": 4.299741124260355e-05,
      "loss": 0.4415,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.21072432398796082,
      "learning_rate": 4.28125e-05,
      "loss": 0.4406,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.5719848871231079,
      "learning_rate": 4.262758875739645e-05,
      "loss": 0.4101,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.9786091446876526,
      "learning_rate": 4.24426775147929e-05,
      "loss": 0.4385,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.841009795665741,
      "learning_rate": 4.2257766272189356e-05,
      "loss": 0.4236,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.5245518088340759,
      "learning_rate": 4.20728550295858e-05,
      "loss": 0.3732,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.6227128505706787,
      "learning_rate": 4.1887943786982255e-05,
      "loss": 0.435,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.925540030002594,
      "learning_rate": 4.17030325443787e-05,
      "loss": 0.4758,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.6650662422180176,
      "learning_rate": 4.151812130177515e-05,
      "loss": 0.3665,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.474563330411911,
      "learning_rate": 4.13332100591716e-05,
      "loss": 0.4428,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.6567142605781555,
      "learning_rate": 4.114829881656805e-05,
      "loss": 0.4377,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.1159498691558838,
      "learning_rate": 4.09633875739645e-05,
      "loss": 0.4412,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.46054285764694214,
      "learning_rate": 4.0778476331360946e-05,
      "loss": 0.4016,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.8939189314842224,
      "learning_rate": 4.05935650887574e-05,
      "loss": 0.4334,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.6222503781318665,
      "learning_rate": 4.040865384615385e-05,
      "loss": 0.3972,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.6562085747718811,
      "learning_rate": 4.02237426035503e-05,
      "loss": 0.3891,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.6770157217979431,
      "learning_rate": 4.003883136094675e-05,
      "loss": 0.3755,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.7638810873031616,
      "learning_rate": 3.98539201183432e-05,
      "loss": 0.4521,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.7228004336357117,
      "learning_rate": 3.966900887573965e-05,
      "loss": 0.4208,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.6695002317428589,
      "learning_rate": 3.94840976331361e-05,
      "loss": 0.4567,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.4219883382320404,
      "learning_rate": 3.929918639053254e-05,
      "loss": 0.4229,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.37800994515419006,
      "learning_rate": 3.9114275147928996e-05,
      "loss": 0.454,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.37366387248039246,
      "learning_rate": 3.892936390532544e-05,
      "loss": 0.4512,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.8677705526351929,
      "learning_rate": 3.8744452662721895e-05,
      "loss": 0.3927,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.7658491134643555,
      "learning_rate": 3.855954142011835e-05,
      "loss": 0.4574,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.6900949478149414,
      "learning_rate": 3.8374630177514794e-05,
      "loss": 0.4186,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.8294160962104797,
      "learning_rate": 3.818971893491125e-05,
      "loss": 0.4767,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.23066987097263336,
      "learning_rate": 3.8004807692307693e-05,
      "loss": 0.456,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.7206637859344482,
      "learning_rate": 3.7819896449704146e-05,
      "loss": 0.4121,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.6606494784355164,
      "learning_rate": 3.763683431952663e-05,
      "loss": 0.4215,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.47847986221313477,
      "learning_rate": 3.7451923076923076e-05,
      "loss": 0.3857,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.4462446868419647,
      "learning_rate": 3.726701183431953e-05,
      "loss": 0.452,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.751960039138794,
      "learning_rate": 3.708210059171598e-05,
      "loss": 0.4134,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.7784746289253235,
      "learning_rate": 3.689718934911243e-05,
      "loss": 0.3982,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.5726194977760315,
      "learning_rate": 3.671227810650888e-05,
      "loss": 0.406,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.8245075941085815,
      "learning_rate": 3.652736686390533e-05,
      "loss": 0.4383,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 1.2966547012329102,
      "learning_rate": 3.6342455621301774e-05,
      "loss": 0.4445,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.9495937824249268,
      "learning_rate": 3.615754437869823e-05,
      "loss": 0.4122,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.4681567847728729,
      "learning_rate": 3.597263313609467e-05,
      "loss": 0.3778,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.46206364035606384,
      "learning_rate": 3.5787721893491126e-05,
      "loss": 0.4432,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.8720418810844421,
      "learning_rate": 3.560281065088757e-05,
      "loss": 0.4548,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.3295484185218811,
      "learning_rate": 3.5417899408284025e-05,
      "loss": 0.4049,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.37500301003456116,
      "learning_rate": 3.523298816568048e-05,
      "loss": 0.4267,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.6965214610099792,
      "learning_rate": 3.5048076923076924e-05,
      "loss": 0.4866,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.7521867156028748,
      "learning_rate": 3.486316568047338e-05,
      "loss": 0.4781,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.6308198571205139,
      "learning_rate": 3.4678254437869824e-05,
      "loss": 0.4007,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.8211206197738647,
      "learning_rate": 3.4493343195266276e-05,
      "loss": 0.4289,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.34797027707099915,
      "learning_rate": 3.430843195266272e-05,
      "loss": 0.4082,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.535792887210846,
      "learning_rate": 3.4123520710059176e-05,
      "loss": 0.3834,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.4334779381752014,
      "eval_runtime": 74.0033,
      "eval_samples_per_second": 50.809,
      "eval_steps_per_second": 12.702,
      "step": 9180
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.4831755267538944e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
