{
  "best_metric": 0.36025989055633545,
  "best_model_checkpoint": "./results/Qwen/Qwen1.5-1.8B-Chat_finetuned/checkpoint-27540",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 27540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 80.83421325683594,
      "learning_rate": 9.4e-06,
      "loss": 21.3328,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 1.2909259796142578,
      "learning_rate": 1.94e-05,
      "loss": 10.6301,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.19133152067661285,
      "learning_rate": 2.93e-05,
      "loss": 1.922,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.2114923596382141,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.3971,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.6310795545578003,
      "learning_rate": 4.93e-05,
      "loss": 0.3789,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.2511726915836334,
      "learning_rate": 4.98280325443787e-05,
      "loss": 0.3918,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.7272100448608398,
      "learning_rate": 4.9643121301775155e-05,
      "loss": 0.3763,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.5290585160255432,
      "learning_rate": 4.94582100591716e-05,
      "loss": 0.3911,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.710492730140686,
      "learning_rate": 4.927329881656805e-05,
      "loss": 0.3484,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.15978257358074188,
      "learning_rate": 4.90883875739645e-05,
      "loss": 0.3482,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.18165622651576996,
      "learning_rate": 4.890347633136095e-05,
      "loss": 0.3602,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.5178987979888916,
      "learning_rate": 4.87185650887574e-05,
      "loss": 0.3796,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.558946430683136,
      "learning_rate": 4.8533653846153846e-05,
      "loss": 0.3918,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.6188768148422241,
      "learning_rate": 4.834874260355029e-05,
      "loss": 0.4407,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.2955007255077362,
      "learning_rate": 4.8163831360946745e-05,
      "loss": 0.3438,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.22589905560016632,
      "learning_rate": 4.79789201183432e-05,
      "loss": 0.3601,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.1315380036830902,
      "learning_rate": 4.779400887573965e-05,
      "loss": 0.3503,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 1.0192275047302246,
      "learning_rate": 4.76090976331361e-05,
      "loss": 0.3682,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.19429811835289001,
      "learning_rate": 4.742418639053255e-05,
      "loss": 0.3587,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.3295786678791046,
      "learning_rate": 4.7239275147929e-05,
      "loss": 0.3137,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.6512843370437622,
      "learning_rate": 4.705436390532544e-05,
      "loss": 0.3494,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.5908563137054443,
      "learning_rate": 4.6869452662721896e-05,
      "loss": 0.3083,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.21303889155387878,
      "learning_rate": 4.668454142011834e-05,
      "loss": 0.3719,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.41682180762290955,
      "learning_rate": 4.6499630177514795e-05,
      "loss": 0.3919,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.398600310087204,
      "learning_rate": 4.631471893491124e-05,
      "loss": 0.3684,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.5271196365356445,
      "learning_rate": 4.6129807692307694e-05,
      "loss": 0.4079,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5481675863265991,
      "learning_rate": 4.594489644970415e-05,
      "loss": 0.3427,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.5309851765632629,
      "learning_rate": 4.5759985207100594e-05,
      "loss": 0.3378,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.5440848469734192,
      "learning_rate": 4.557507396449705e-05,
      "loss": 0.3379,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.3674044609069824,
      "learning_rate": 4.539016272189349e-05,
      "loss": 0.2917,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.47402435541152954,
      "learning_rate": 4.5205251479289946e-05,
      "loss": 0.3378,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.6634379625320435,
      "learning_rate": 4.502034023668639e-05,
      "loss": 0.3426,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.6758142709732056,
      "learning_rate": 4.483542899408284e-05,
      "loss": 0.3652,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.3748576045036316,
      "learning_rate": 4.465051775147929e-05,
      "loss": 0.4228,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.5617247223854065,
      "learning_rate": 4.446560650887574e-05,
      "loss": 0.3126,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.701562225818634,
      "learning_rate": 4.428069526627219e-05,
      "loss": 0.3787,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5292501449584961,
      "learning_rate": 4.4095784023668643e-05,
      "loss": 0.343,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.5999346971511841,
      "learning_rate": 4.3910872781065096e-05,
      "loss": 0.3506,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.6210947036743164,
      "learning_rate": 4.372596153846154e-05,
      "loss": 0.3563,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.4810710847377777,
      "learning_rate": 4.354105029585799e-05,
      "loss": 0.3936,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.2806161344051361,
      "learning_rate": 4.335613905325444e-05,
      "loss": 0.3639,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.5863745808601379,
      "learning_rate": 4.317122781065089e-05,
      "loss": 0.32,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.3692825436592102,
      "learning_rate": 4.298631656804734e-05,
      "loss": 0.364,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.1634652316570282,
      "learning_rate": 4.280140532544379e-05,
      "loss": 0.3647,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.5065456628799438,
      "learning_rate": 4.261649408284024e-05,
      "loss": 0.3382,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.6882320642471313,
      "learning_rate": 4.2431582840236686e-05,
      "loss": 0.3621,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.48162364959716797,
      "learning_rate": 4.224667159763314e-05,
      "loss": 0.3516,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.4588416814804077,
      "learning_rate": 4.206176035502959e-05,
      "loss": 0.3094,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.40308162569999695,
      "learning_rate": 4.187684911242604e-05,
      "loss": 0.3609,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5915447473526001,
      "learning_rate": 4.169193786982249e-05,
      "loss": 0.396,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.38367873430252075,
      "learning_rate": 4.150702662721894e-05,
      "loss": 0.3011,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.28584223985671997,
      "learning_rate": 4.1322115384615384e-05,
      "loss": 0.3635,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.3983965218067169,
      "learning_rate": 4.113720414201184e-05,
      "loss": 0.3601,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.6988934874534607,
      "learning_rate": 4.095229289940828e-05,
      "loss": 0.363,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.3416675329208374,
      "learning_rate": 4.0767381656804736e-05,
      "loss": 0.3315,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.603011965751648,
      "learning_rate": 4.058247041420118e-05,
      "loss": 0.3572,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.3985421359539032,
      "learning_rate": 4.0397559171597635e-05,
      "loss": 0.3248,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.42064735293388367,
      "learning_rate": 4.021264792899408e-05,
      "loss": 0.3191,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.4503976106643677,
      "learning_rate": 4.0027736686390535e-05,
      "loss": 0.3104,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.5273100733757019,
      "learning_rate": 3.984282544378699e-05,
      "loss": 0.3735,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.4539676308631897,
      "learning_rate": 3.9657914201183434e-05,
      "loss": 0.3467,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.49267271161079407,
      "learning_rate": 3.947300295857989e-05,
      "loss": 0.3766,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.35598820447921753,
      "learning_rate": 3.928809171597633e-05,
      "loss": 0.3486,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.21251623332500458,
      "learning_rate": 3.910318047337278e-05,
      "loss": 0.3775,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.17756055295467377,
      "learning_rate": 3.891826923076923e-05,
      "loss": 0.3748,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.6846480369567871,
      "learning_rate": 3.873335798816568e-05,
      "loss": 0.3269,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.6083446741104126,
      "learning_rate": 3.854844674556213e-05,
      "loss": 0.3788,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.43551403284072876,
      "learning_rate": 3.836353550295858e-05,
      "loss": 0.3482,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.5863189697265625,
      "learning_rate": 3.817862426035503e-05,
      "loss": 0.3943,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.30619919300079346,
      "learning_rate": 3.7993713017751484e-05,
      "loss": 0.3808,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.6154221892356873,
      "learning_rate": 3.780880177514793e-05,
      "loss": 0.3416,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.38533440232276917,
      "learning_rate": 3.762389053254438e-05,
      "loss": 0.3491,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.3536249101161957,
      "learning_rate": 3.743897928994083e-05,
      "loss": 0.3198,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.30692431330680847,
      "learning_rate": 3.725406804733728e-05,
      "loss": 0.3734,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.4905880391597748,
      "learning_rate": 3.706915680473373e-05,
      "loss": 0.3432,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.4893220365047455,
      "learning_rate": 3.688424556213018e-05,
      "loss": 0.3275,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3644900619983673,
      "learning_rate": 3.669933431952663e-05,
      "loss": 0.3356,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5958585739135742,
      "learning_rate": 3.6514423076923074e-05,
      "loss": 0.3625,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.7869428396224976,
      "learning_rate": 3.632951183431953e-05,
      "loss": 0.3686,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.6275873184204102,
      "learning_rate": 3.614460059171598e-05,
      "loss": 0.3413,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.3707325756549835,
      "learning_rate": 3.595968934911243e-05,
      "loss": 0.312,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.2446625679731369,
      "learning_rate": 3.577477810650888e-05,
      "loss": 0.3671,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.572449266910553,
      "learning_rate": 3.5589866863905325e-05,
      "loss": 0.3759,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.20007368922233582,
      "learning_rate": 3.540495562130178e-05,
      "loss": 0.3349,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3062932789325714,
      "learning_rate": 3.5220044378698224e-05,
      "loss": 0.3525,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.2176121473312378,
      "learning_rate": 3.503513313609468e-05,
      "loss": 0.4029,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.4288899600505829,
      "learning_rate": 3.4850221893491123e-05,
      "loss": 0.3942,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.4553239643573761,
      "learning_rate": 3.4665310650887576e-05,
      "loss": 0.3294,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.5445596575737,
      "learning_rate": 3.448039940828402e-05,
      "loss": 0.3562,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.22682443261146545,
      "learning_rate": 3.4295488165680476e-05,
      "loss": 0.3367,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.4163375496864319,
      "learning_rate": 3.411057692307693e-05,
      "loss": 0.3179,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3603155314922333,
      "eval_runtime": 152.7906,
      "eval_samples_per_second": 24.609,
      "eval_steps_per_second": 6.152,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.3168826103210449,
      "learning_rate": 3.3925665680473375e-05,
      "loss": 0.3279,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.5042108297348022,
      "learning_rate": 3.374075443786983e-05,
      "loss": 0.3805,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.4094162881374359,
      "learning_rate": 3.3555843195266274e-05,
      "loss": 0.3561,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.6682782173156738,
      "learning_rate": 3.337093195266273e-05,
      "loss": 0.3409,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.4159986972808838,
      "learning_rate": 3.318602071005917e-05,
      "loss": 0.3168,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.4481099247932434,
      "learning_rate": 3.300110946745562e-05,
      "loss": 0.3548,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.5340312719345093,
      "learning_rate": 3.281619822485207e-05,
      "loss": 0.3097,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.6741578578948975,
      "learning_rate": 3.263128698224852e-05,
      "loss": 0.3271,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.2884957790374756,
      "learning_rate": 3.244637573964497e-05,
      "loss": 0.349,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 0.7694321870803833,
      "learning_rate": 3.2261464497041425e-05,
      "loss": 0.3587,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.4558497369289398,
      "learning_rate": 3.207655325443787e-05,
      "loss": 0.3403,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 0.5129042863845825,
      "learning_rate": 3.1891642011834324e-05,
      "loss": 0.3467,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 0.7218461036682129,
      "learning_rate": 3.170673076923077e-05,
      "loss": 0.3516,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.3407122492790222,
      "learning_rate": 3.152181952662722e-05,
      "loss": 0.3645,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.6624409556388855,
      "learning_rate": 3.133690828402367e-05,
      "loss": 0.3545,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.5424588322639465,
      "learning_rate": 3.115199704142012e-05,
      "loss": 0.3316,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.4024399518966675,
      "learning_rate": 3.096708579881657e-05,
      "loss": 0.3435,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.16027067601680756,
      "learning_rate": 3.0782174556213015e-05,
      "loss": 0.3472,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.445242702960968,
      "learning_rate": 3.059726331360947e-05,
      "loss": 0.3462,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.7249934077262878,
      "learning_rate": 3.0412352071005917e-05,
      "loss": 0.3549,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 0.7435768246650696,
      "learning_rate": 3.022744082840237e-05,
      "loss": 0.3374,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.43319275975227356,
      "learning_rate": 3.0042529585798816e-05,
      "loss": 0.3572,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.5368162393569946,
      "learning_rate": 2.9857618343195266e-05,
      "loss": 0.3746,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.48776233196258545,
      "learning_rate": 2.9674556213017753e-05,
      "loss": 0.3445,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.7782514691352844,
      "learning_rate": 2.9489644970414202e-05,
      "loss": 0.3707,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.5078378915786743,
      "learning_rate": 2.9304733727810652e-05,
      "loss": 0.3084,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.10137218981981277,
      "learning_rate": 2.9119822485207105e-05,
      "loss": 0.3515,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.6393419504165649,
      "learning_rate": 2.893491124260355e-05,
      "loss": 0.3568,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.004329855553805828,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.3377,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.7002895474433899,
      "learning_rate": 2.856508875739645e-05,
      "loss": 0.3364,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.3292664587497711,
      "learning_rate": 2.83801775147929e-05,
      "loss": 0.3783,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.5320890545845032,
      "learning_rate": 2.8195266272189353e-05,
      "loss": 0.3488,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.30143654346466064,
      "learning_rate": 2.80103550295858e-05,
      "loss": 0.3724,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.29772239923477173,
      "learning_rate": 2.7825443786982252e-05,
      "loss": 0.3663,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.3508232533931732,
      "learning_rate": 2.76405325443787e-05,
      "loss": 0.2994,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.5724742412567139,
      "learning_rate": 2.7455621301775148e-05,
      "loss": 0.3564,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.7234723567962646,
      "learning_rate": 2.72707100591716e-05,
      "loss": 0.3263,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.4938390851020813,
      "learning_rate": 2.7085798816568047e-05,
      "loss": 0.3495,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.31618377566337585,
      "learning_rate": 2.69008875739645e-05,
      "loss": 0.3395,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 0.5490106344223022,
      "learning_rate": 2.6715976331360946e-05,
      "loss": 0.3266,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.7289170026779175,
      "learning_rate": 2.6531065088757396e-05,
      "loss": 0.3853,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.6742773056030273,
      "learning_rate": 2.634615384615385e-05,
      "loss": 0.3202,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.44714421033859253,
      "learning_rate": 2.6161242603550295e-05,
      "loss": 0.2917,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.9804307818412781,
      "learning_rate": 2.5976331360946748e-05,
      "loss": 0.3708,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.16001029312610626,
      "learning_rate": 2.5793269230769235e-05,
      "loss": 0.4036,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.087917260825634,
      "learning_rate": 2.560835798816568e-05,
      "loss": 0.3107,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.4593690037727356,
      "learning_rate": 2.542344674556213e-05,
      "loss": 0.3286,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.4209933280944824,
      "learning_rate": 2.5238535502958584e-05,
      "loss": 0.3552,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.35051625967025757,
      "learning_rate": 2.505362426035503e-05,
      "loss": 0.3136,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.45288538932800293,
      "learning_rate": 2.486871301775148e-05,
      "loss": 0.3291,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 0.613213300704956,
      "learning_rate": 2.468380177514793e-05,
      "loss": 0.3575,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.569864809513092,
      "learning_rate": 2.449889053254438e-05,
      "loss": 0.3361,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.5285102128982544,
      "learning_rate": 2.4313979289940832e-05,
      "loss": 0.3747,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.5229607224464417,
      "learning_rate": 2.412906804733728e-05,
      "loss": 0.3398,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.2924060821533203,
      "learning_rate": 2.3944156804733728e-05,
      "loss": 0.3474,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.7364801168441772,
      "learning_rate": 2.3759245562130177e-05,
      "loss": 0.3057,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.23346269130706787,
      "learning_rate": 2.3574334319526627e-05,
      "loss": 0.3674,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 0.5009685158729553,
      "learning_rate": 2.338942307692308e-05,
      "loss": 0.3069,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.5982125401496887,
      "learning_rate": 2.320451183431953e-05,
      "loss": 0.329,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.2823423445224762,
      "learning_rate": 2.301960059171598e-05,
      "loss": 0.3392,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.6043540835380554,
      "learning_rate": 2.2834689349112425e-05,
      "loss": 0.3324,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.10498806834220886,
      "learning_rate": 2.2649778106508875e-05,
      "loss": 0.3522,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.6386160850524902,
      "learning_rate": 2.2464866863905325e-05,
      "loss": 0.3605,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.6218479871749878,
      "learning_rate": 2.2279955621301777e-05,
      "loss": 0.3111,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.3563989996910095,
      "learning_rate": 2.2095044378698227e-05,
      "loss": 0.3382,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.30218952894210815,
      "learning_rate": 2.1910133136094677e-05,
      "loss": 0.3557,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 0.24605819582939148,
      "learning_rate": 2.1725221893491126e-05,
      "loss": 0.2934,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.20662951469421387,
      "learning_rate": 2.1540310650887573e-05,
      "loss": 0.3373,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 0.31679895520210266,
      "learning_rate": 2.1355399408284025e-05,
      "loss": 0.3303,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.5312483906745911,
      "learning_rate": 2.1170488165680475e-05,
      "loss": 0.3862,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.5447067022323608,
      "learning_rate": 2.0985576923076925e-05,
      "loss": 0.3749,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.6582909822463989,
      "learning_rate": 2.0800665680473374e-05,
      "loss": 0.3921,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.47963660955429077,
      "learning_rate": 2.0615754437869824e-05,
      "loss": 0.3319,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.5324215292930603,
      "learning_rate": 2.0430843195266273e-05,
      "loss": 0.3469,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 0.6805230975151062,
      "learning_rate": 2.0245931952662723e-05,
      "loss": 0.3812,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.10730424523353577,
      "learning_rate": 2.0061020710059173e-05,
      "loss": 0.3379,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.4191274642944336,
      "learning_rate": 1.9876109467455622e-05,
      "loss": 0.3458,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.2475508153438568,
      "learning_rate": 1.9691198224852072e-05,
      "loss": 0.3823,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.3627088665962219,
      "learning_rate": 1.950628698224852e-05,
      "loss": 0.3302,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.2312418818473816,
      "learning_rate": 1.932137573964497e-05,
      "loss": 0.3617,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.6686165928840637,
      "learning_rate": 1.913646449704142e-05,
      "loss": 0.3445,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.37590962648391724,
      "learning_rate": 1.895155325443787e-05,
      "loss": 0.3461,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.35342153906822205,
      "learning_rate": 1.876664201183432e-05,
      "loss": 0.3541,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.4903281331062317,
      "learning_rate": 1.858173076923077e-05,
      "loss": 0.3324,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.3624219596385956,
      "learning_rate": 1.8396819526627222e-05,
      "loss": 0.3507,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.6808189749717712,
      "learning_rate": 1.821190828402367e-05,
      "loss": 0.354,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.12971383333206177,
      "learning_rate": 1.8026997041420118e-05,
      "loss": 0.3422,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.3061768412590027,
      "learning_rate": 1.7842085798816568e-05,
      "loss": 0.3241,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.4143460988998413,
      "learning_rate": 1.7657174556213017e-05,
      "loss": 0.3383,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.47863641381263733,
      "learning_rate": 1.7474112426035504e-05,
      "loss": 0.3513,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.4009464979171753,
      "learning_rate": 1.7289201183431954e-05,
      "loss": 0.3597,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.27755531668663025,
      "learning_rate": 1.7104289940828404e-05,
      "loss": 0.3365,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.3606180250644684,
      "eval_runtime": 152.6316,
      "eval_samples_per_second": 24.634,
      "eval_steps_per_second": 6.159,
      "step": 18360
    },
    {
      "epoch": 2.0043572984749454,
      "grad_norm": 0.4179304242134094,
      "learning_rate": 1.6919378698224853e-05,
      "loss": 0.3479,
      "step": 18400
    },
    {
      "epoch": 2.0152505446623095,
      "grad_norm": 0.36726605892181396,
      "learning_rate": 1.6734467455621303e-05,
      "loss": 0.333,
      "step": 18500
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.30316779017448425,
      "learning_rate": 1.6549556213017752e-05,
      "loss": 0.3375,
      "step": 18600
    },
    {
      "epoch": 2.037037037037037,
      "grad_norm": 0.7987281084060669,
      "learning_rate": 1.6364644970414202e-05,
      "loss": 0.323,
      "step": 18700
    },
    {
      "epoch": 2.047930283224401,
      "grad_norm": 0.6782745122909546,
      "learning_rate": 1.617973372781065e-05,
      "loss": 0.3253,
      "step": 18800
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.5108816027641296,
      "learning_rate": 1.59948224852071e-05,
      "loss": 0.3183,
      "step": 18900
    },
    {
      "epoch": 2.0697167755991286,
      "grad_norm": 0.5344465970993042,
      "learning_rate": 1.580991124260355e-05,
      "loss": 0.3375,
      "step": 19000
    },
    {
      "epoch": 2.0806100217864922,
      "grad_norm": 0.5984437465667725,
      "learning_rate": 1.5625e-05,
      "loss": 0.3231,
      "step": 19100
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.5614219307899475,
      "learning_rate": 1.544008875739645e-05,
      "loss": 0.3502,
      "step": 19200
    },
    {
      "epoch": 2.10239651416122,
      "grad_norm": 0.6169654130935669,
      "learning_rate": 1.5257026627218935e-05,
      "loss": 0.3266,
      "step": 19300
    },
    {
      "epoch": 2.113289760348584,
      "grad_norm": 0.33369848132133484,
      "learning_rate": 1.5072115384615385e-05,
      "loss": 0.3638,
      "step": 19400
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 0.7080594897270203,
      "learning_rate": 1.4887204142011834e-05,
      "loss": 0.3178,
      "step": 19500
    },
    {
      "epoch": 2.1350762527233114,
      "grad_norm": 0.36022648215293884,
      "learning_rate": 1.4702292899408286e-05,
      "loss": 0.3481,
      "step": 19600
    },
    {
      "epoch": 2.1459694989106755,
      "grad_norm": 0.6820595860481262,
      "learning_rate": 1.4517381656804735e-05,
      "loss": 0.361,
      "step": 19700
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.5313012003898621,
      "learning_rate": 1.4332470414201185e-05,
      "loss": 0.3509,
      "step": 19800
    },
    {
      "epoch": 2.167755991285403,
      "grad_norm": 0.2764686048030853,
      "learning_rate": 1.4147559171597633e-05,
      "loss": 0.3344,
      "step": 19900
    },
    {
      "epoch": 2.178649237472767,
      "grad_norm": 0.3734184503555298,
      "learning_rate": 1.3962647928994082e-05,
      "loss": 0.3471,
      "step": 20000
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 0.31160739064216614,
      "learning_rate": 1.3777736686390534e-05,
      "loss": 0.3835,
      "step": 20100
    },
    {
      "epoch": 2.2004357298474946,
      "grad_norm": 0.6378589868545532,
      "learning_rate": 1.3592825443786983e-05,
      "loss": 0.3383,
      "step": 20200
    },
    {
      "epoch": 2.2113289760348582,
      "grad_norm": 0.28984659910202026,
      "learning_rate": 1.3407914201183433e-05,
      "loss": 0.3055,
      "step": 20300
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.5494233965873718,
      "learning_rate": 1.3223002958579882e-05,
      "loss": 0.307,
      "step": 20400
    },
    {
      "epoch": 2.233115468409586,
      "grad_norm": 0.3162503242492676,
      "learning_rate": 1.3038091715976334e-05,
      "loss": 0.3173,
      "step": 20500
    },
    {
      "epoch": 2.24400871459695,
      "grad_norm": 0.41906237602233887,
      "learning_rate": 1.285318047337278e-05,
      "loss": 0.3389,
      "step": 20600
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 0.5859965682029724,
      "learning_rate": 1.2668269230769231e-05,
      "loss": 0.3407,
      "step": 20700
    },
    {
      "epoch": 2.265795206971678,
      "grad_norm": 0.5722532272338867,
      "learning_rate": 1.2485207100591716e-05,
      "loss": 0.3827,
      "step": 20800
    },
    {
      "epoch": 2.2766884531590414,
      "grad_norm": 0.4702242612838745,
      "learning_rate": 1.2300295857988166e-05,
      "loss": 0.3723,
      "step": 20900
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.8037410378456116,
      "learning_rate": 1.2115384615384615e-05,
      "loss": 0.346,
      "step": 21000
    },
    {
      "epoch": 2.298474945533769,
      "grad_norm": 0.40372174978256226,
      "learning_rate": 1.1930473372781067e-05,
      "loss": 0.3099,
      "step": 21100
    },
    {
      "epoch": 2.309368191721133,
      "grad_norm": 0.18725508451461792,
      "learning_rate": 1.1745562130177515e-05,
      "loss": 0.3375,
      "step": 21200
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 0.5713950395584106,
      "learning_rate": 1.1560650887573964e-05,
      "loss": 0.3555,
      "step": 21300
    },
    {
      "epoch": 2.3311546840958606,
      "grad_norm": 0.48898839950561523,
      "learning_rate": 1.1375739644970416e-05,
      "loss": 0.3712,
      "step": 21400
    },
    {
      "epoch": 2.342047930283224,
      "grad_norm": 0.6696298122406006,
      "learning_rate": 1.11926775147929e-05,
      "loss": 0.3559,
      "step": 21500
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.4106923043727875,
      "learning_rate": 1.100776627218935e-05,
      "loss": 0.3258,
      "step": 21600
    },
    {
      "epoch": 2.363834422657952,
      "grad_norm": 0.768940806388855,
      "learning_rate": 1.0822855029585798e-05,
      "loss": 0.3094,
      "step": 21700
    },
    {
      "epoch": 2.374727668845316,
      "grad_norm": 0.6622013449668884,
      "learning_rate": 1.063794378698225e-05,
      "loss": 0.3542,
      "step": 21800
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 0.7458147406578064,
      "learning_rate": 1.0453032544378699e-05,
      "loss": 0.3358,
      "step": 21900
    },
    {
      "epoch": 2.3965141612200433,
      "grad_norm": 0.46412402391433716,
      "learning_rate": 1.0268121301775149e-05,
      "loss": 0.3118,
      "step": 22000
    },
    {
      "epoch": 2.4074074074074074,
      "grad_norm": 0.29175296425819397,
      "learning_rate": 1.0083210059171598e-05,
      "loss": 0.3371,
      "step": 22100
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.004879345186054707,
      "learning_rate": 9.898298816568048e-06,
      "loss": 0.338,
      "step": 22200
    },
    {
      "epoch": 2.429193899782135,
      "grad_norm": 0.46371662616729736,
      "learning_rate": 9.713387573964498e-06,
      "loss": 0.3347,
      "step": 22300
    },
    {
      "epoch": 2.440087145969499,
      "grad_norm": 0.32792723178863525,
      "learning_rate": 9.528476331360947e-06,
      "loss": 0.3831,
      "step": 22400
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 0.461266428232193,
      "learning_rate": 9.343565088757397e-06,
      "loss": 0.322,
      "step": 22500
    },
    {
      "epoch": 2.4618736383442266,
      "grad_norm": 0.6764935851097107,
      "learning_rate": 9.158653846153846e-06,
      "loss": 0.3746,
      "step": 22600
    },
    {
      "epoch": 2.47276688453159,
      "grad_norm": 0.6179186105728149,
      "learning_rate": 8.973742603550296e-06,
      "loss": 0.3319,
      "step": 22700
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.5072828531265259,
      "learning_rate": 8.788831360946746e-06,
      "loss": 0.3027,
      "step": 22800
    },
    {
      "epoch": 2.494553376906318,
      "grad_norm": 0.46558043360710144,
      "learning_rate": 8.603920118343195e-06,
      "loss": 0.3849,
      "step": 22900
    },
    {
      "epoch": 2.505446623093682,
      "grad_norm": 0.7188488245010376,
      "learning_rate": 8.419008875739645e-06,
      "loss": 0.3629,
      "step": 23000
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 0.7012547254562378,
      "learning_rate": 8.234097633136096e-06,
      "loss": 0.3475,
      "step": 23100
    },
    {
      "epoch": 2.52723311546841,
      "grad_norm": 0.5101892948150635,
      "learning_rate": 8.049186390532546e-06,
      "loss": 0.3041,
      "step": 23200
    },
    {
      "epoch": 2.5381263616557734,
      "grad_norm": 0.47828400135040283,
      "learning_rate": 7.864275147928994e-06,
      "loss": 0.3537,
      "step": 23300
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.7755820751190186,
      "learning_rate": 7.679363905325445e-06,
      "loss": 0.3378,
      "step": 23400
    },
    {
      "epoch": 2.559912854030501,
      "grad_norm": 0.37970754504203796,
      "learning_rate": 7.494452662721894e-06,
      "loss": 0.2872,
      "step": 23500
    },
    {
      "epoch": 2.570806100217865,
      "grad_norm": 0.1410474181175232,
      "learning_rate": 7.309541420118343e-06,
      "loss": 0.3409,
      "step": 23600
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 0.2804144620895386,
      "learning_rate": 7.124630177514794e-06,
      "loss": 0.3061,
      "step": 23700
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.7283170819282532,
      "learning_rate": 6.939718934911243e-06,
      "loss": 0.3591,
      "step": 23800
    },
    {
      "epoch": 2.6034858387799567,
      "grad_norm": 0.40311944484710693,
      "learning_rate": 6.754807692307692e-06,
      "loss": 0.3655,
      "step": 23900
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.7039172053337097,
      "learning_rate": 6.5698964497041424e-06,
      "loss": 0.3107,
      "step": 24000
    },
    {
      "epoch": 2.625272331154684,
      "grad_norm": 0.3961588740348816,
      "learning_rate": 6.384985207100593e-06,
      "loss": 0.3403,
      "step": 24100
    },
    {
      "epoch": 2.636165577342048,
      "grad_norm": 0.5735014081001282,
      "learning_rate": 6.200073964497042e-06,
      "loss": 0.3321,
      "step": 24200
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.520255446434021,
      "learning_rate": 6.015162721893491e-06,
      "loss": 0.3126,
      "step": 24300
    },
    {
      "epoch": 2.6579520697167753,
      "grad_norm": 0.443643182516098,
      "learning_rate": 5.830251479289941e-06,
      "loss": 0.3256,
      "step": 24400
    },
    {
      "epoch": 2.6688453159041394,
      "grad_norm": 0.0014510754263028502,
      "learning_rate": 5.645340236686391e-06,
      "loss": 0.3651,
      "step": 24500
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.5655948519706726,
      "learning_rate": 5.46042899408284e-06,
      "loss": 0.3757,
      "step": 24600
    },
    {
      "epoch": 2.690631808278867,
      "grad_norm": 0.7128149271011353,
      "learning_rate": 5.27551775147929e-06,
      "loss": 0.3502,
      "step": 24700
    },
    {
      "epoch": 2.701525054466231,
      "grad_norm": 0.46119192242622375,
      "learning_rate": 5.09060650887574e-06,
      "loss": 0.3184,
      "step": 24800
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 0.30382004380226135,
      "learning_rate": 4.90569526627219e-06,
      "loss": 0.3036,
      "step": 24900
    },
    {
      "epoch": 2.7233115468409586,
      "grad_norm": 0.40538010001182556,
      "learning_rate": 4.720784023668639e-06,
      "loss": 0.3174,
      "step": 25000
    },
    {
      "epoch": 2.734204793028322,
      "grad_norm": 0.6680079698562622,
      "learning_rate": 4.535872781065089e-06,
      "loss": 0.3352,
      "step": 25100
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.5045273303985596,
      "learning_rate": 4.3509615384615385e-06,
      "loss": 0.3712,
      "step": 25200
    },
    {
      "epoch": 2.7559912854030504,
      "grad_norm": 0.4368208944797516,
      "learning_rate": 4.166050295857989e-06,
      "loss": 0.3585,
      "step": 25300
    },
    {
      "epoch": 2.766884531590414,
      "grad_norm": 0.25590819120407104,
      "learning_rate": 3.981139053254438e-06,
      "loss": 0.3639,
      "step": 25400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.521268367767334,
      "learning_rate": 3.7962278106508877e-06,
      "loss": 0.3635,
      "step": 25500
    },
    {
      "epoch": 2.7886710239651418,
      "grad_norm": 0.5017516613006592,
      "learning_rate": 3.6113165680473377e-06,
      "loss": 0.3154,
      "step": 25600
    },
    {
      "epoch": 2.7995642701525054,
      "grad_norm": 0.5351701378822327,
      "learning_rate": 3.426405325443787e-06,
      "loss": 0.3827,
      "step": 25700
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.0014037871733307838,
      "learning_rate": 3.2414940828402365e-06,
      "loss": 0.3338,
      "step": 25800
    },
    {
      "epoch": 2.821350762527233,
      "grad_norm": 0.4350534677505493,
      "learning_rate": 3.0565828402366865e-06,
      "loss": 0.3428,
      "step": 25900
    },
    {
      "epoch": 2.832244008714597,
      "grad_norm": 0.37458765506744385,
      "learning_rate": 2.871671597633136e-06,
      "loss": 0.3476,
      "step": 26000
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 0.08937598764896393,
      "learning_rate": 2.6867603550295857e-06,
      "loss": 0.3542,
      "step": 26100
    },
    {
      "epoch": 2.8540305010893245,
      "grad_norm": 0.43254202604293823,
      "learning_rate": 2.5018491124260357e-06,
      "loss": 0.3284,
      "step": 26200
    },
    {
      "epoch": 2.8649237472766886,
      "grad_norm": 0.5657524466514587,
      "learning_rate": 2.3169378698224853e-06,
      "loss": 0.3515,
      "step": 26300
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.537452220916748,
      "learning_rate": 2.132026627218935e-06,
      "loss": 0.3914,
      "step": 26400
    },
    {
      "epoch": 2.886710239651416,
      "grad_norm": 0.4072452187538147,
      "learning_rate": 1.9471153846153845e-06,
      "loss": 0.3766,
      "step": 26500
    },
    {
      "epoch": 2.89760348583878,
      "grad_norm": 0.642799437046051,
      "learning_rate": 1.7622041420118346e-06,
      "loss": 0.3217,
      "step": 26600
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 0.6280821561813354,
      "learning_rate": 1.577292899408284e-06,
      "loss": 0.3114,
      "step": 26700
    },
    {
      "epoch": 2.9193899782135078,
      "grad_norm": 0.5276960134506226,
      "learning_rate": 1.3923816568047338e-06,
      "loss": 0.3034,
      "step": 26800
    },
    {
      "epoch": 2.9302832244008714,
      "grad_norm": 0.49877506494522095,
      "learning_rate": 1.2074704142011836e-06,
      "loss": 0.3518,
      "step": 26900
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.5460222959518433,
      "learning_rate": 1.0225591715976332e-06,
      "loss": 0.4003,
      "step": 27000
    },
    {
      "epoch": 2.952069716775599,
      "grad_norm": 0.32118380069732666,
      "learning_rate": 8.37647928994083e-07,
      "loss": 0.3559,
      "step": 27100
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.0013548069400712848,
      "learning_rate": 6.527366863905326e-07,
      "loss": 0.3346,
      "step": 27200
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 0.7505878806114197,
      "learning_rate": 4.678254437869823e-07,
      "loss": 0.3364,
      "step": 27300
    },
    {
      "epoch": 2.9847494553376905,
      "grad_norm": 0.25503021478652954,
      "learning_rate": 2.8291420118343195e-07,
      "loss": 0.3292,
      "step": 27400
    },
    {
      "epoch": 2.9956427015250546,
      "grad_norm": 0.572030246257782,
      "learning_rate": 9.800295857988167e-08,
      "loss": 0.3475,
      "step": 27500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.36025989055633545,
      "eval_runtime": 152.7508,
      "eval_samples_per_second": 24.615,
      "eval_steps_per_second": 6.154,
      "step": 27540
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.165401887347835e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
