{
  "best_metric": 0.3603155314922333,
  "best_model_checkpoint": "./results/Qwen/Qwen1.5-1.8B-Chat_finetuned/checkpoint-9180",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 80.83421325683594,
      "learning_rate": 9.4e-06,
      "loss": 21.3328,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 1.2909259796142578,
      "learning_rate": 1.94e-05,
      "loss": 10.6301,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.19133152067661285,
      "learning_rate": 2.93e-05,
      "loss": 1.922,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.2114923596382141,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.3971,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.6310795545578003,
      "learning_rate": 4.93e-05,
      "loss": 0.3789,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.2511726915836334,
      "learning_rate": 4.98280325443787e-05,
      "loss": 0.3918,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.7272100448608398,
      "learning_rate": 4.9643121301775155e-05,
      "loss": 0.3763,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.5290585160255432,
      "learning_rate": 4.94582100591716e-05,
      "loss": 0.3911,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.710492730140686,
      "learning_rate": 4.927329881656805e-05,
      "loss": 0.3484,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.15978257358074188,
      "learning_rate": 4.90883875739645e-05,
      "loss": 0.3482,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.18165622651576996,
      "learning_rate": 4.890347633136095e-05,
      "loss": 0.3602,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.5178987979888916,
      "learning_rate": 4.87185650887574e-05,
      "loss": 0.3796,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.558946430683136,
      "learning_rate": 4.8533653846153846e-05,
      "loss": 0.3918,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.6188768148422241,
      "learning_rate": 4.834874260355029e-05,
      "loss": 0.4407,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.2955007255077362,
      "learning_rate": 4.8163831360946745e-05,
      "loss": 0.3438,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.22589905560016632,
      "learning_rate": 4.79789201183432e-05,
      "loss": 0.3601,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.1315380036830902,
      "learning_rate": 4.779400887573965e-05,
      "loss": 0.3503,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 1.0192275047302246,
      "learning_rate": 4.76090976331361e-05,
      "loss": 0.3682,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.19429811835289001,
      "learning_rate": 4.742418639053255e-05,
      "loss": 0.3587,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.3295786678791046,
      "learning_rate": 4.7239275147929e-05,
      "loss": 0.3137,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.6512843370437622,
      "learning_rate": 4.705436390532544e-05,
      "loss": 0.3494,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.5908563137054443,
      "learning_rate": 4.6869452662721896e-05,
      "loss": 0.3083,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.21303889155387878,
      "learning_rate": 4.668454142011834e-05,
      "loss": 0.3719,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.41682180762290955,
      "learning_rate": 4.6499630177514795e-05,
      "loss": 0.3919,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.398600310087204,
      "learning_rate": 4.631471893491124e-05,
      "loss": 0.3684,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.5271196365356445,
      "learning_rate": 4.6129807692307694e-05,
      "loss": 0.4079,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5481675863265991,
      "learning_rate": 4.594489644970415e-05,
      "loss": 0.3427,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.5309851765632629,
      "learning_rate": 4.5759985207100594e-05,
      "loss": 0.3378,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.5440848469734192,
      "learning_rate": 4.557507396449705e-05,
      "loss": 0.3379,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.3674044609069824,
      "learning_rate": 4.539016272189349e-05,
      "loss": 0.2917,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.47402435541152954,
      "learning_rate": 4.5205251479289946e-05,
      "loss": 0.3378,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.6634379625320435,
      "learning_rate": 4.502034023668639e-05,
      "loss": 0.3426,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.6758142709732056,
      "learning_rate": 4.483542899408284e-05,
      "loss": 0.3652,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.3748576045036316,
      "learning_rate": 4.465051775147929e-05,
      "loss": 0.4228,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.5617247223854065,
      "learning_rate": 4.446560650887574e-05,
      "loss": 0.3126,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.701562225818634,
      "learning_rate": 4.428069526627219e-05,
      "loss": 0.3787,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5292501449584961,
      "learning_rate": 4.4095784023668643e-05,
      "loss": 0.343,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.5999346971511841,
      "learning_rate": 4.3910872781065096e-05,
      "loss": 0.3506,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.6210947036743164,
      "learning_rate": 4.372596153846154e-05,
      "loss": 0.3563,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.4810710847377777,
      "learning_rate": 4.354105029585799e-05,
      "loss": 0.3936,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.2806161344051361,
      "learning_rate": 4.335613905325444e-05,
      "loss": 0.3639,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.5863745808601379,
      "learning_rate": 4.317122781065089e-05,
      "loss": 0.32,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.3692825436592102,
      "learning_rate": 4.298631656804734e-05,
      "loss": 0.364,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.1634652316570282,
      "learning_rate": 4.280140532544379e-05,
      "loss": 0.3647,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.5065456628799438,
      "learning_rate": 4.261649408284024e-05,
      "loss": 0.3382,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.6882320642471313,
      "learning_rate": 4.2431582840236686e-05,
      "loss": 0.3621,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.48162364959716797,
      "learning_rate": 4.224667159763314e-05,
      "loss": 0.3516,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.4588416814804077,
      "learning_rate": 4.206176035502959e-05,
      "loss": 0.3094,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.40308162569999695,
      "learning_rate": 4.187684911242604e-05,
      "loss": 0.3609,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5915447473526001,
      "learning_rate": 4.169193786982249e-05,
      "loss": 0.396,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.38367873430252075,
      "learning_rate": 4.150702662721894e-05,
      "loss": 0.3011,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.28584223985671997,
      "learning_rate": 4.1322115384615384e-05,
      "loss": 0.3635,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.3983965218067169,
      "learning_rate": 4.113720414201184e-05,
      "loss": 0.3601,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.6988934874534607,
      "learning_rate": 4.095229289940828e-05,
      "loss": 0.363,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.3416675329208374,
      "learning_rate": 4.0767381656804736e-05,
      "loss": 0.3315,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.603011965751648,
      "learning_rate": 4.058247041420118e-05,
      "loss": 0.3572,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.3985421359539032,
      "learning_rate": 4.0397559171597635e-05,
      "loss": 0.3248,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.42064735293388367,
      "learning_rate": 4.021264792899408e-05,
      "loss": 0.3191,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.4503976106643677,
      "learning_rate": 4.0027736686390535e-05,
      "loss": 0.3104,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.5273100733757019,
      "learning_rate": 3.984282544378699e-05,
      "loss": 0.3735,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.4539676308631897,
      "learning_rate": 3.9657914201183434e-05,
      "loss": 0.3467,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.49267271161079407,
      "learning_rate": 3.947300295857989e-05,
      "loss": 0.3766,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.35598820447921753,
      "learning_rate": 3.928809171597633e-05,
      "loss": 0.3486,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.21251623332500458,
      "learning_rate": 3.910318047337278e-05,
      "loss": 0.3775,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.17756055295467377,
      "learning_rate": 3.891826923076923e-05,
      "loss": 0.3748,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.6846480369567871,
      "learning_rate": 3.873335798816568e-05,
      "loss": 0.3269,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.6083446741104126,
      "learning_rate": 3.854844674556213e-05,
      "loss": 0.3788,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.43551403284072876,
      "learning_rate": 3.836353550295858e-05,
      "loss": 0.3482,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.5863189697265625,
      "learning_rate": 3.817862426035503e-05,
      "loss": 0.3943,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.30619919300079346,
      "learning_rate": 3.7993713017751484e-05,
      "loss": 0.3808,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.6154221892356873,
      "learning_rate": 3.780880177514793e-05,
      "loss": 0.3416,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.38533440232276917,
      "learning_rate": 3.762389053254438e-05,
      "loss": 0.3491,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.3536249101161957,
      "learning_rate": 3.743897928994083e-05,
      "loss": 0.3198,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.30692431330680847,
      "learning_rate": 3.725406804733728e-05,
      "loss": 0.3734,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.4905880391597748,
      "learning_rate": 3.706915680473373e-05,
      "loss": 0.3432,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.4893220365047455,
      "learning_rate": 3.688424556213018e-05,
      "loss": 0.3275,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3644900619983673,
      "learning_rate": 3.669933431952663e-05,
      "loss": 0.3356,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5958585739135742,
      "learning_rate": 3.6514423076923074e-05,
      "loss": 0.3625,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.7869428396224976,
      "learning_rate": 3.632951183431953e-05,
      "loss": 0.3686,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.6275873184204102,
      "learning_rate": 3.614460059171598e-05,
      "loss": 0.3413,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.3707325756549835,
      "learning_rate": 3.595968934911243e-05,
      "loss": 0.312,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.2446625679731369,
      "learning_rate": 3.577477810650888e-05,
      "loss": 0.3671,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.572449266910553,
      "learning_rate": 3.5589866863905325e-05,
      "loss": 0.3759,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.20007368922233582,
      "learning_rate": 3.540495562130178e-05,
      "loss": 0.3349,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3062932789325714,
      "learning_rate": 3.5220044378698224e-05,
      "loss": 0.3525,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.2176121473312378,
      "learning_rate": 3.503513313609468e-05,
      "loss": 0.4029,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.4288899600505829,
      "learning_rate": 3.4850221893491123e-05,
      "loss": 0.3942,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.4553239643573761,
      "learning_rate": 3.4665310650887576e-05,
      "loss": 0.3294,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.5445596575737,
      "learning_rate": 3.448039940828402e-05,
      "loss": 0.3562,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.22682443261146545,
      "learning_rate": 3.4295488165680476e-05,
      "loss": 0.3367,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.4163375496864319,
      "learning_rate": 3.411057692307693e-05,
      "loss": 0.3179,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3603155314922333,
      "eval_runtime": 152.7906,
      "eval_samples_per_second": 24.609,
      "eval_steps_per_second": 6.152,
      "step": 9180
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.721800629115945e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
