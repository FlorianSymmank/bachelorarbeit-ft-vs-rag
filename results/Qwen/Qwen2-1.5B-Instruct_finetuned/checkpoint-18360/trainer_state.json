{
  "best_metric": 0.334541380405426,
  "best_model_checkpoint": "./results/Qwen/Qwen2-1.5B-Instruct_finetuned/checkpoint-18360",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 18360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 12.083918571472168,
      "learning_rate": 9.5e-06,
      "loss": 12.8675,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 35.299076080322266,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 8.8568,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.32841232419013977,
      "learning_rate": 2.95e-05,
      "loss": 1.6023,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.22325512766838074,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.3765,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.45392006635665894,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.3633,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.20565181970596313,
      "learning_rate": 4.982433431952663e-05,
      "loss": 0.3705,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.3723401725292206,
      "learning_rate": 4.963942307692308e-05,
      "loss": 0.3565,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.3990717828273773,
      "learning_rate": 4.945451183431953e-05,
      "loss": 0.3673,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.5462934374809265,
      "learning_rate": 4.926960059171598e-05,
      "loss": 0.3281,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.1545502245426178,
      "learning_rate": 4.9084689349112426e-05,
      "loss": 0.3276,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.174901083111763,
      "learning_rate": 4.889977810650887e-05,
      "loss": 0.3457,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.4043067991733551,
      "learning_rate": 4.8714866863905326e-05,
      "loss": 0.3586,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.39245927333831787,
      "learning_rate": 4.852995562130178e-05,
      "loss": 0.3702,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.4685964584350586,
      "learning_rate": 4.834504437869823e-05,
      "loss": 0.4133,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.1691027283668518,
      "learning_rate": 4.816013313609468e-05,
      "loss": 0.3227,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.18538448214530945,
      "learning_rate": 4.797522189349113e-05,
      "loss": 0.3388,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.11917532980442047,
      "learning_rate": 4.779031065088758e-05,
      "loss": 0.3292,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.7014557123184204,
      "learning_rate": 4.760539940828402e-05,
      "loss": 0.3463,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.1376897245645523,
      "learning_rate": 4.7420488165680476e-05,
      "loss": 0.3383,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.2871016561985016,
      "learning_rate": 4.723557692307692e-05,
      "loss": 0.2936,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.43602779507637024,
      "learning_rate": 4.7050665680473375e-05,
      "loss": 0.3331,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.4520796239376068,
      "learning_rate": 4.686575443786982e-05,
      "loss": 0.2894,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.2780871093273163,
      "learning_rate": 4.6680843195266275e-05,
      "loss": 0.3536,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.3343901038169861,
      "learning_rate": 4.649593195266273e-05,
      "loss": 0.3669,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.31560030579566956,
      "learning_rate": 4.6311020710059174e-05,
      "loss": 0.3192,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.4252532422542572,
      "learning_rate": 4.612610946745563e-05,
      "loss": 0.3825,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5418998599052429,
      "learning_rate": 4.594119822485207e-05,
      "loss": 0.3214,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.44918689131736755,
      "learning_rate": 4.5756286982248526e-05,
      "loss": 0.3177,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.44237133860588074,
      "learning_rate": 4.557137573964497e-05,
      "loss": 0.3175,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.4408884644508362,
      "learning_rate": 4.538646449704142e-05,
      "loss": 0.2737,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.36876562237739563,
      "learning_rate": 4.520155325443787e-05,
      "loss": 0.3168,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.49361294507980347,
      "learning_rate": 4.501664201183432e-05,
      "loss": 0.3137,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.5234456062316895,
      "learning_rate": 4.483173076923077e-05,
      "loss": 0.3432,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.30367541313171387,
      "learning_rate": 4.4646819526627224e-05,
      "loss": 0.4,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.4734489619731903,
      "learning_rate": 4.4461908284023677e-05,
      "loss": 0.294,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.5055679678916931,
      "learning_rate": 4.427699704142012e-05,
      "loss": 0.3566,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5375090837478638,
      "learning_rate": 4.409208579881657e-05,
      "loss": 0.3222,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.456465482711792,
      "learning_rate": 4.390717455621302e-05,
      "loss": 0.3459,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.423255056142807,
      "learning_rate": 4.372226331360947e-05,
      "loss": 0.333,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.3970271944999695,
      "learning_rate": 4.353735207100592e-05,
      "loss": 0.3704,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.3171963393688202,
      "learning_rate": 4.335244082840237e-05,
      "loss": 0.3419,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.4922843277454376,
      "learning_rate": 4.3167529585798814e-05,
      "loss": 0.302,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.31832608580589294,
      "learning_rate": 4.2982618343195267e-05,
      "loss": 0.3436,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.14710088074207306,
      "learning_rate": 4.279770710059172e-05,
      "loss": 0.3432,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.4422033429145813,
      "learning_rate": 4.261279585798817e-05,
      "loss": 0.3188,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.5480875372886658,
      "learning_rate": 4.242788461538462e-05,
      "loss": 0.3391,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.4543750584125519,
      "learning_rate": 4.224297337278107e-05,
      "loss": 0.3315,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.2452051341533661,
      "learning_rate": 4.205806213017752e-05,
      "loss": 0.2899,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.31269317865371704,
      "learning_rate": 4.1873150887573964e-05,
      "loss": 0.3393,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5186188817024231,
      "learning_rate": 4.168823964497042e-05,
      "loss": 0.3728,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.3152714967727661,
      "learning_rate": 4.150332840236686e-05,
      "loss": 0.2815,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.29964298009872437,
      "learning_rate": 4.1318417159763316e-05,
      "loss": 0.341,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.32271814346313477,
      "learning_rate": 4.113350591715976e-05,
      "loss": 0.3384,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.5111860632896423,
      "learning_rate": 4.0948594674556216e-05,
      "loss": 0.3415,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.3029319643974304,
      "learning_rate": 4.07655325443787e-05,
      "loss": 0.3185,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.5347898006439209,
      "learning_rate": 4.058062130177515e-05,
      "loss": 0.3572,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 1.85247004032135,
      "learning_rate": 4.03957100591716e-05,
      "loss": 0.306,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.3657984435558319,
      "learning_rate": 4.021079881656805e-05,
      "loss": 0.2999,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.4676787853240967,
      "learning_rate": 4.00258875739645e-05,
      "loss": 0.2917,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.38811057806015015,
      "learning_rate": 3.9840976331360944e-05,
      "loss": 0.3508,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.3421308696269989,
      "learning_rate": 3.96560650887574e-05,
      "loss": 0.3264,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.4813695549964905,
      "learning_rate": 3.947115384615385e-05,
      "loss": 0.3533,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.2690696716308594,
      "learning_rate": 3.92862426035503e-05,
      "loss": 0.3287,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.20071455836296082,
      "learning_rate": 3.910133136094675e-05,
      "loss": 0.3548,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.17227068543434143,
      "learning_rate": 3.89164201183432e-05,
      "loss": 0.3532,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.5270490646362305,
      "learning_rate": 3.873150887573965e-05,
      "loss": 0.3076,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.45984238386154175,
      "learning_rate": 3.8546597633136094e-05,
      "loss": 0.3559,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.3911660611629486,
      "learning_rate": 3.836168639053255e-05,
      "loss": 0.3278,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.46101465821266174,
      "learning_rate": 3.8176775147928993e-05,
      "loss": 0.3684,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.1499391496181488,
      "learning_rate": 3.7991863905325446e-05,
      "loss": 0.3586,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.38246503472328186,
      "learning_rate": 3.780695266272189e-05,
      "loss": 0.321,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.3217396140098572,
      "learning_rate": 3.7622041420118346e-05,
      "loss": 0.3284,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.2382480949163437,
      "learning_rate": 3.74371301775148e-05,
      "loss": 0.3029,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.23380298912525177,
      "learning_rate": 3.7252218934911245e-05,
      "loss": 0.3508,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.3705536723136902,
      "learning_rate": 3.70673076923077e-05,
      "loss": 0.3239,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.4131792187690735,
      "learning_rate": 3.6882396449704144e-05,
      "loss": 0.3087,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3169497549533844,
      "learning_rate": 3.66974852071006e-05,
      "loss": 0.3166,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5084013342857361,
      "learning_rate": 3.651257396449704e-05,
      "loss": 0.3415,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.6120607852935791,
      "learning_rate": 3.632766272189349e-05,
      "loss": 0.3454,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.5013637542724609,
      "learning_rate": 3.614275147928994e-05,
      "loss": 0.3218,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.36776936054229736,
      "learning_rate": 3.595784023668639e-05,
      "loss": 0.2946,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.2302335798740387,
      "learning_rate": 3.577292899408284e-05,
      "loss": 0.3457,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.4934726357460022,
      "learning_rate": 3.558801775147929e-05,
      "loss": 0.3521,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.21710312366485596,
      "learning_rate": 3.540310650887574e-05,
      "loss": 0.3142,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3391862213611603,
      "learning_rate": 3.5218195266272194e-05,
      "loss": 0.3324,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.20327623188495636,
      "learning_rate": 3.503328402366864e-05,
      "loss": 0.3784,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.313965380191803,
      "learning_rate": 3.484837278106509e-05,
      "loss": 0.3731,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.4422021508216858,
      "learning_rate": 3.466346153846154e-05,
      "loss": 0.3103,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.3779517114162445,
      "learning_rate": 3.447855029585799e-05,
      "loss": 0.3355,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.19053377211093903,
      "learning_rate": 3.429363905325444e-05,
      "loss": 0.3173,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.3443893790245056,
      "learning_rate": 3.4108727810650885e-05,
      "loss": 0.2994,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.33543336391448975,
      "eval_runtime": 149.6512,
      "eval_samples_per_second": 25.125,
      "eval_steps_per_second": 6.281,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.2728087902069092,
      "learning_rate": 3.392381656804734e-05,
      "loss": 0.3092,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.4168395400047302,
      "learning_rate": 3.3738905325443784e-05,
      "loss": 0.36,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.3270339369773865,
      "learning_rate": 3.355399408284024e-05,
      "loss": 0.3366,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.5011565685272217,
      "learning_rate": 3.336908284023669e-05,
      "loss": 0.3242,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.4682576060295105,
      "learning_rate": 3.318417159763314e-05,
      "loss": 0.3005,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.41979822516441345,
      "learning_rate": 3.299926035502959e-05,
      "loss": 0.3361,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.38179343938827515,
      "learning_rate": 3.2814349112426035e-05,
      "loss": 0.2938,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.5419378876686096,
      "learning_rate": 3.262943786982249e-05,
      "loss": 0.3105,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.2629750072956085,
      "learning_rate": 3.2444526627218934e-05,
      "loss": 0.3315,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 0.584373950958252,
      "learning_rate": 3.225961538461539e-05,
      "loss": 0.3384,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.33859845995903015,
      "learning_rate": 3.2074704142011834e-05,
      "loss": 0.3219,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 0.5449312925338745,
      "learning_rate": 3.188979289940828e-05,
      "loss": 0.3298,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 0.587112545967102,
      "learning_rate": 3.170488165680473e-05,
      "loss": 0.335,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.25086361169815063,
      "learning_rate": 3.1519970414201186e-05,
      "loss": 0.3445,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.48903822898864746,
      "learning_rate": 3.133505917159764e-05,
      "loss": 0.337,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.42592328786849976,
      "learning_rate": 3.1150147928994085e-05,
      "loss": 0.312,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.3354107439517975,
      "learning_rate": 3.096523668639054e-05,
      "loss": 0.325,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.1471644937992096,
      "learning_rate": 3.0780325443786984e-05,
      "loss": 0.3288,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.4027262330055237,
      "learning_rate": 3.059541420118343e-05,
      "loss": 0.3297,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.5394635796546936,
      "learning_rate": 3.0410502958579883e-05,
      "loss": 0.3357,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 0.5319342017173767,
      "learning_rate": 3.0225591715976333e-05,
      "loss": 0.32,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.32667073607444763,
      "learning_rate": 3.0040680473372783e-05,
      "loss": 0.3374,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.3816269338130951,
      "learning_rate": 2.9855769230769232e-05,
      "loss": 0.3523,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.44087401032447815,
      "learning_rate": 2.9670857988165685e-05,
      "loss": 0.3147,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.5419476628303528,
      "learning_rate": 2.948594674556213e-05,
      "loss": 0.3494,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.3785238265991211,
      "learning_rate": 2.9301035502958578e-05,
      "loss": 0.2937,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.09985829889774323,
      "learning_rate": 2.911612426035503e-05,
      "loss": 0.3331,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.49108827114105225,
      "learning_rate": 2.893121301775148e-05,
      "loss": 0.3375,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.003074086969718337,
      "learning_rate": 2.8746301775147933e-05,
      "loss": 0.3192,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.581308901309967,
      "learning_rate": 2.856139053254438e-05,
      "loss": 0.318,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.27485334873199463,
      "learning_rate": 2.8376479289940826e-05,
      "loss": 0.3575,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.44903892278671265,
      "learning_rate": 2.819156804733728e-05,
      "loss": 0.3294,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.2626290023326874,
      "learning_rate": 2.8006656804733728e-05,
      "loss": 0.3526,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.3063274025917053,
      "learning_rate": 2.782174556213018e-05,
      "loss": 0.3466,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.3004022538661957,
      "learning_rate": 2.7636834319526627e-05,
      "loss": 0.284,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.4437371790409088,
      "learning_rate": 2.745192307692308e-05,
      "loss": 0.3385,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.534461498260498,
      "learning_rate": 2.7267011834319527e-05,
      "loss": 0.3101,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.409223735332489,
      "learning_rate": 2.7082100591715976e-05,
      "loss": 0.3295,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.29216068983078003,
      "learning_rate": 2.689718934911243e-05,
      "loss": 0.3206,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 0.3953162729740143,
      "learning_rate": 2.6712278106508875e-05,
      "loss": 0.3066,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.536665678024292,
      "learning_rate": 2.652736686390533e-05,
      "loss": 0.3644,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.544749915599823,
      "learning_rate": 2.6342455621301775e-05,
      "loss": 0.3018,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.9345158934593201,
      "learning_rate": 2.6157544378698228e-05,
      "loss": 0.275,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.875901460647583,
      "learning_rate": 2.5972633136094677e-05,
      "loss": 0.3504,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.14648018777370453,
      "learning_rate": 2.5787721893491123e-05,
      "loss": 0.3616,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.05457475036382675,
      "learning_rate": 2.5602810650887576e-05,
      "loss": 0.2938,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.4773337244987488,
      "learning_rate": 2.5417899408284023e-05,
      "loss": 0.3108,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.2656041979789734,
      "learning_rate": 2.5232988165680476e-05,
      "loss": 0.3358,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.37222832441329956,
      "learning_rate": 2.5048076923076925e-05,
      "loss": 0.2973,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.34127745032310486,
      "learning_rate": 2.4863165680473375e-05,
      "loss": 0.3114,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 0.4364180862903595,
      "learning_rate": 2.4678254437869824e-05,
      "loss": 0.3391,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.3789009153842926,
      "learning_rate": 2.4493343195266274e-05,
      "loss": 0.3176,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.3613814115524292,
      "learning_rate": 2.430843195266272e-05,
      "loss": 0.3569,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.4399675726890564,
      "learning_rate": 2.4123520710059173e-05,
      "loss": 0.3232,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.2335621416568756,
      "learning_rate": 2.3938609467455623e-05,
      "loss": 0.3297,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.3551502823829651,
      "learning_rate": 2.3753698224852072e-05,
      "loss": 0.2905,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.19352726638317108,
      "learning_rate": 2.3568786982248522e-05,
      "loss": 0.3484,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 0.4489802122116089,
      "learning_rate": 2.338387573964497e-05,
      "loss": 0.2913,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.4172099828720093,
      "learning_rate": 2.319896449704142e-05,
      "loss": 0.313,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.1936250627040863,
      "learning_rate": 2.301405325443787e-05,
      "loss": 0.3208,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.49476826190948486,
      "learning_rate": 2.282914201183432e-05,
      "loss": 0.3133,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.10827871412038803,
      "learning_rate": 2.264423076923077e-05,
      "loss": 0.3349,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.4835253059864044,
      "learning_rate": 2.245931952662722e-05,
      "loss": 0.3418,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.5105867981910706,
      "learning_rate": 2.227440828402367e-05,
      "loss": 0.2946,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.24920959770679474,
      "learning_rate": 2.2089497041420122e-05,
      "loss": 0.3195,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.2540547549724579,
      "learning_rate": 2.190458579881657e-05,
      "loss": 0.3358,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 0.27658531069755554,
      "learning_rate": 2.1719674556213018e-05,
      "loss": 0.2787,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.12258279323577881,
      "learning_rate": 2.1534763313609468e-05,
      "loss": 0.3186,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 0.20420484244823456,
      "learning_rate": 2.1349852071005917e-05,
      "loss": 0.3123,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.3878079354763031,
      "learning_rate": 2.116494082840237e-05,
      "loss": 0.3642,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.5369937419891357,
      "learning_rate": 2.098002958579882e-05,
      "loss": 0.3562,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.5124796628952026,
      "learning_rate": 2.0795118343195266e-05,
      "loss": 0.3716,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.36729103326797485,
      "learning_rate": 2.0610207100591716e-05,
      "loss": 0.314,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.40872427821159363,
      "learning_rate": 2.0425295857988165e-05,
      "loss": 0.3295,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 0.4453684985637665,
      "learning_rate": 2.0240384615384618e-05,
      "loss": 0.3601,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.13359762728214264,
      "learning_rate": 2.0055473372781068e-05,
      "loss": 0.3206,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.3406856656074524,
      "learning_rate": 1.9870562130177517e-05,
      "loss": 0.3269,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.21421606838703156,
      "learning_rate": 1.9685650887573964e-05,
      "loss": 0.3624,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.28234612941741943,
      "learning_rate": 1.9500739644970413e-05,
      "loss": 0.3139,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.29307034611701965,
      "learning_rate": 1.9315828402366866e-05,
      "loss": 0.3436,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.4331623315811157,
      "learning_rate": 1.9130917159763316e-05,
      "loss": 0.3265,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.28533291816711426,
      "learning_rate": 1.8946005917159765e-05,
      "loss": 0.3284,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.2694450616836548,
      "learning_rate": 1.8761094674556215e-05,
      "loss": 0.3353,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.4831714332103729,
      "learning_rate": 1.857618343195266e-05,
      "loss": 0.3164,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.28395968675613403,
      "learning_rate": 1.839127218934911e-05,
      "loss": 0.3303,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.44813352823257446,
      "learning_rate": 1.8206360946745564e-05,
      "loss": 0.337,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.18531902134418488,
      "learning_rate": 1.8021449704142013e-05,
      "loss": 0.3243,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.22352084517478943,
      "learning_rate": 1.7836538461538463e-05,
      "loss": 0.3061,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.33280467987060547,
      "learning_rate": 1.7651627218934913e-05,
      "loss": 0.3213,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.42859482765197754,
      "learning_rate": 1.7466715976331362e-05,
      "loss": 0.3316,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.325950026512146,
      "learning_rate": 1.7281804733727812e-05,
      "loss": 0.34,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.42180800437927246,
      "learning_rate": 1.709689349112426e-05,
      "loss": 0.3198,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.334541380405426,
      "eval_runtime": 149.6613,
      "eval_samples_per_second": 25.123,
      "eval_steps_per_second": 6.281,
      "step": 18360
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.957297002657874e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
