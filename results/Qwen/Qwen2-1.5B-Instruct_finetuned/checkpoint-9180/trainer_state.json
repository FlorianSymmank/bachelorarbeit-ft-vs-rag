{
  "best_metric": 0.33543336391448975,
  "best_model_checkpoint": "./results/Qwen/Qwen2-1.5B-Instruct_finetuned/checkpoint-9180",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 12.083918571472168,
      "learning_rate": 9.5e-06,
      "loss": 12.8675,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 35.299076080322266,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 8.8568,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.32841232419013977,
      "learning_rate": 2.95e-05,
      "loss": 1.6023,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.22325512766838074,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.3765,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.45392006635665894,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.3633,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.20565181970596313,
      "learning_rate": 4.982433431952663e-05,
      "loss": 0.3705,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.3723401725292206,
      "learning_rate": 4.963942307692308e-05,
      "loss": 0.3565,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.3990717828273773,
      "learning_rate": 4.945451183431953e-05,
      "loss": 0.3673,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.5462934374809265,
      "learning_rate": 4.926960059171598e-05,
      "loss": 0.3281,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.1545502245426178,
      "learning_rate": 4.9084689349112426e-05,
      "loss": 0.3276,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.174901083111763,
      "learning_rate": 4.889977810650887e-05,
      "loss": 0.3457,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.4043067991733551,
      "learning_rate": 4.8714866863905326e-05,
      "loss": 0.3586,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.39245927333831787,
      "learning_rate": 4.852995562130178e-05,
      "loss": 0.3702,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.4685964584350586,
      "learning_rate": 4.834504437869823e-05,
      "loss": 0.4133,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.1691027283668518,
      "learning_rate": 4.816013313609468e-05,
      "loss": 0.3227,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.18538448214530945,
      "learning_rate": 4.797522189349113e-05,
      "loss": 0.3388,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.11917532980442047,
      "learning_rate": 4.779031065088758e-05,
      "loss": 0.3292,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.7014557123184204,
      "learning_rate": 4.760539940828402e-05,
      "loss": 0.3463,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.1376897245645523,
      "learning_rate": 4.7420488165680476e-05,
      "loss": 0.3383,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.2871016561985016,
      "learning_rate": 4.723557692307692e-05,
      "loss": 0.2936,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.43602779507637024,
      "learning_rate": 4.7050665680473375e-05,
      "loss": 0.3331,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.4520796239376068,
      "learning_rate": 4.686575443786982e-05,
      "loss": 0.2894,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.2780871093273163,
      "learning_rate": 4.6680843195266275e-05,
      "loss": 0.3536,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.3343901038169861,
      "learning_rate": 4.649593195266273e-05,
      "loss": 0.3669,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.31560030579566956,
      "learning_rate": 4.6311020710059174e-05,
      "loss": 0.3192,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.4252532422542572,
      "learning_rate": 4.612610946745563e-05,
      "loss": 0.3825,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5418998599052429,
      "learning_rate": 4.594119822485207e-05,
      "loss": 0.3214,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.44918689131736755,
      "learning_rate": 4.5756286982248526e-05,
      "loss": 0.3177,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.44237133860588074,
      "learning_rate": 4.557137573964497e-05,
      "loss": 0.3175,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.4408884644508362,
      "learning_rate": 4.538646449704142e-05,
      "loss": 0.2737,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.36876562237739563,
      "learning_rate": 4.520155325443787e-05,
      "loss": 0.3168,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.49361294507980347,
      "learning_rate": 4.501664201183432e-05,
      "loss": 0.3137,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.5234456062316895,
      "learning_rate": 4.483173076923077e-05,
      "loss": 0.3432,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.30367541313171387,
      "learning_rate": 4.4646819526627224e-05,
      "loss": 0.4,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.4734489619731903,
      "learning_rate": 4.4461908284023677e-05,
      "loss": 0.294,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.5055679678916931,
      "learning_rate": 4.427699704142012e-05,
      "loss": 0.3566,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5375090837478638,
      "learning_rate": 4.409208579881657e-05,
      "loss": 0.3222,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.456465482711792,
      "learning_rate": 4.390717455621302e-05,
      "loss": 0.3459,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.423255056142807,
      "learning_rate": 4.372226331360947e-05,
      "loss": 0.333,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.3970271944999695,
      "learning_rate": 4.353735207100592e-05,
      "loss": 0.3704,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.3171963393688202,
      "learning_rate": 4.335244082840237e-05,
      "loss": 0.3419,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.4922843277454376,
      "learning_rate": 4.3167529585798814e-05,
      "loss": 0.302,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.31832608580589294,
      "learning_rate": 4.2982618343195267e-05,
      "loss": 0.3436,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.14710088074207306,
      "learning_rate": 4.279770710059172e-05,
      "loss": 0.3432,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.4422033429145813,
      "learning_rate": 4.261279585798817e-05,
      "loss": 0.3188,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.5480875372886658,
      "learning_rate": 4.242788461538462e-05,
      "loss": 0.3391,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.4543750584125519,
      "learning_rate": 4.224297337278107e-05,
      "loss": 0.3315,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.2452051341533661,
      "learning_rate": 4.205806213017752e-05,
      "loss": 0.2899,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.31269317865371704,
      "learning_rate": 4.1873150887573964e-05,
      "loss": 0.3393,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5186188817024231,
      "learning_rate": 4.168823964497042e-05,
      "loss": 0.3728,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.3152714967727661,
      "learning_rate": 4.150332840236686e-05,
      "loss": 0.2815,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.29964298009872437,
      "learning_rate": 4.1318417159763316e-05,
      "loss": 0.341,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.32271814346313477,
      "learning_rate": 4.113350591715976e-05,
      "loss": 0.3384,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.5111860632896423,
      "learning_rate": 4.0948594674556216e-05,
      "loss": 0.3415,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.3029319643974304,
      "learning_rate": 4.07655325443787e-05,
      "loss": 0.3185,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.5347898006439209,
      "learning_rate": 4.058062130177515e-05,
      "loss": 0.3572,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 1.85247004032135,
      "learning_rate": 4.03957100591716e-05,
      "loss": 0.306,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.3657984435558319,
      "learning_rate": 4.021079881656805e-05,
      "loss": 0.2999,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.4676787853240967,
      "learning_rate": 4.00258875739645e-05,
      "loss": 0.2917,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.38811057806015015,
      "learning_rate": 3.9840976331360944e-05,
      "loss": 0.3508,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.3421308696269989,
      "learning_rate": 3.96560650887574e-05,
      "loss": 0.3264,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.4813695549964905,
      "learning_rate": 3.947115384615385e-05,
      "loss": 0.3533,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.2690696716308594,
      "learning_rate": 3.92862426035503e-05,
      "loss": 0.3287,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.20071455836296082,
      "learning_rate": 3.910133136094675e-05,
      "loss": 0.3548,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.17227068543434143,
      "learning_rate": 3.89164201183432e-05,
      "loss": 0.3532,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.5270490646362305,
      "learning_rate": 3.873150887573965e-05,
      "loss": 0.3076,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.45984238386154175,
      "learning_rate": 3.8546597633136094e-05,
      "loss": 0.3559,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.3911660611629486,
      "learning_rate": 3.836168639053255e-05,
      "loss": 0.3278,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.46101465821266174,
      "learning_rate": 3.8176775147928993e-05,
      "loss": 0.3684,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.1499391496181488,
      "learning_rate": 3.7991863905325446e-05,
      "loss": 0.3586,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.38246503472328186,
      "learning_rate": 3.780695266272189e-05,
      "loss": 0.321,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.3217396140098572,
      "learning_rate": 3.7622041420118346e-05,
      "loss": 0.3284,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.2382480949163437,
      "learning_rate": 3.74371301775148e-05,
      "loss": 0.3029,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.23380298912525177,
      "learning_rate": 3.7252218934911245e-05,
      "loss": 0.3508,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.3705536723136902,
      "learning_rate": 3.70673076923077e-05,
      "loss": 0.3239,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.4131792187690735,
      "learning_rate": 3.6882396449704144e-05,
      "loss": 0.3087,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3169497549533844,
      "learning_rate": 3.66974852071006e-05,
      "loss": 0.3166,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5084013342857361,
      "learning_rate": 3.651257396449704e-05,
      "loss": 0.3415,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.6120607852935791,
      "learning_rate": 3.632766272189349e-05,
      "loss": 0.3454,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.5013637542724609,
      "learning_rate": 3.614275147928994e-05,
      "loss": 0.3218,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.36776936054229736,
      "learning_rate": 3.595784023668639e-05,
      "loss": 0.2946,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.2302335798740387,
      "learning_rate": 3.577292899408284e-05,
      "loss": 0.3457,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.4934726357460022,
      "learning_rate": 3.558801775147929e-05,
      "loss": 0.3521,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.21710312366485596,
      "learning_rate": 3.540310650887574e-05,
      "loss": 0.3142,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3391862213611603,
      "learning_rate": 3.5218195266272194e-05,
      "loss": 0.3324,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.20327623188495636,
      "learning_rate": 3.503328402366864e-05,
      "loss": 0.3784,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.313965380191803,
      "learning_rate": 3.484837278106509e-05,
      "loss": 0.3731,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.4422021508216858,
      "learning_rate": 3.466346153846154e-05,
      "loss": 0.3103,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.3779517114162445,
      "learning_rate": 3.447855029585799e-05,
      "loss": 0.3355,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.19053377211093903,
      "learning_rate": 3.429363905325444e-05,
      "loss": 0.3173,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.3443893790245056,
      "learning_rate": 3.4108727810650885e-05,
      "loss": 0.2994,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.33543336391448975,
      "eval_runtime": 149.6512,
      "eval_samples_per_second": 25.125,
      "eval_steps_per_second": 6.281,
      "step": 9180
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.478648501328937e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
