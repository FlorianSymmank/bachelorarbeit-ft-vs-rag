{
  "best_metric": 0.3343360424041748,
  "best_model_checkpoint": "./results/Qwen/Qwen2-1.5B-Instruct_finetuned/checkpoint-27540",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 27540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 12.083918571472168,
      "learning_rate": 9.5e-06,
      "loss": 12.8675,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 35.299076080322266,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 8.8568,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.32841232419013977,
      "learning_rate": 2.95e-05,
      "loss": 1.6023,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.22325512766838074,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.3765,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.45392006635665894,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.3633,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.20565181970596313,
      "learning_rate": 4.982433431952663e-05,
      "loss": 0.3705,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.3723401725292206,
      "learning_rate": 4.963942307692308e-05,
      "loss": 0.3565,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.3990717828273773,
      "learning_rate": 4.945451183431953e-05,
      "loss": 0.3673,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.5462934374809265,
      "learning_rate": 4.926960059171598e-05,
      "loss": 0.3281,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.1545502245426178,
      "learning_rate": 4.9084689349112426e-05,
      "loss": 0.3276,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.174901083111763,
      "learning_rate": 4.889977810650887e-05,
      "loss": 0.3457,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.4043067991733551,
      "learning_rate": 4.8714866863905326e-05,
      "loss": 0.3586,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.39245927333831787,
      "learning_rate": 4.852995562130178e-05,
      "loss": 0.3702,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.4685964584350586,
      "learning_rate": 4.834504437869823e-05,
      "loss": 0.4133,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.1691027283668518,
      "learning_rate": 4.816013313609468e-05,
      "loss": 0.3227,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.18538448214530945,
      "learning_rate": 4.797522189349113e-05,
      "loss": 0.3388,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.11917532980442047,
      "learning_rate": 4.779031065088758e-05,
      "loss": 0.3292,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.7014557123184204,
      "learning_rate": 4.760539940828402e-05,
      "loss": 0.3463,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.1376897245645523,
      "learning_rate": 4.7420488165680476e-05,
      "loss": 0.3383,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.2871016561985016,
      "learning_rate": 4.723557692307692e-05,
      "loss": 0.2936,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.43602779507637024,
      "learning_rate": 4.7050665680473375e-05,
      "loss": 0.3331,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.4520796239376068,
      "learning_rate": 4.686575443786982e-05,
      "loss": 0.2894,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.2780871093273163,
      "learning_rate": 4.6680843195266275e-05,
      "loss": 0.3536,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.3343901038169861,
      "learning_rate": 4.649593195266273e-05,
      "loss": 0.3669,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.31560030579566956,
      "learning_rate": 4.6311020710059174e-05,
      "loss": 0.3192,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.4252532422542572,
      "learning_rate": 4.612610946745563e-05,
      "loss": 0.3825,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5418998599052429,
      "learning_rate": 4.594119822485207e-05,
      "loss": 0.3214,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.44918689131736755,
      "learning_rate": 4.5756286982248526e-05,
      "loss": 0.3177,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.44237133860588074,
      "learning_rate": 4.557137573964497e-05,
      "loss": 0.3175,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.4408884644508362,
      "learning_rate": 4.538646449704142e-05,
      "loss": 0.2737,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.36876562237739563,
      "learning_rate": 4.520155325443787e-05,
      "loss": 0.3168,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.49361294507980347,
      "learning_rate": 4.501664201183432e-05,
      "loss": 0.3137,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.5234456062316895,
      "learning_rate": 4.483173076923077e-05,
      "loss": 0.3432,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.30367541313171387,
      "learning_rate": 4.4646819526627224e-05,
      "loss": 0.4,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.4734489619731903,
      "learning_rate": 4.4461908284023677e-05,
      "loss": 0.294,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.5055679678916931,
      "learning_rate": 4.427699704142012e-05,
      "loss": 0.3566,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5375090837478638,
      "learning_rate": 4.409208579881657e-05,
      "loss": 0.3222,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.456465482711792,
      "learning_rate": 4.390717455621302e-05,
      "loss": 0.3459,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.423255056142807,
      "learning_rate": 4.372226331360947e-05,
      "loss": 0.333,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.3970271944999695,
      "learning_rate": 4.353735207100592e-05,
      "loss": 0.3704,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.3171963393688202,
      "learning_rate": 4.335244082840237e-05,
      "loss": 0.3419,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.4922843277454376,
      "learning_rate": 4.3167529585798814e-05,
      "loss": 0.302,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.31832608580589294,
      "learning_rate": 4.2982618343195267e-05,
      "loss": 0.3436,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.14710088074207306,
      "learning_rate": 4.279770710059172e-05,
      "loss": 0.3432,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.4422033429145813,
      "learning_rate": 4.261279585798817e-05,
      "loss": 0.3188,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.5480875372886658,
      "learning_rate": 4.242788461538462e-05,
      "loss": 0.3391,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.4543750584125519,
      "learning_rate": 4.224297337278107e-05,
      "loss": 0.3315,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.2452051341533661,
      "learning_rate": 4.205806213017752e-05,
      "loss": 0.2899,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.31269317865371704,
      "learning_rate": 4.1873150887573964e-05,
      "loss": 0.3393,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5186188817024231,
      "learning_rate": 4.168823964497042e-05,
      "loss": 0.3728,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.3152714967727661,
      "learning_rate": 4.150332840236686e-05,
      "loss": 0.2815,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.29964298009872437,
      "learning_rate": 4.1318417159763316e-05,
      "loss": 0.341,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.32271814346313477,
      "learning_rate": 4.113350591715976e-05,
      "loss": 0.3384,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.5111860632896423,
      "learning_rate": 4.0948594674556216e-05,
      "loss": 0.3415,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.3029319643974304,
      "learning_rate": 4.07655325443787e-05,
      "loss": 0.3185,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.5347898006439209,
      "learning_rate": 4.058062130177515e-05,
      "loss": 0.3572,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 1.85247004032135,
      "learning_rate": 4.03957100591716e-05,
      "loss": 0.306,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.3657984435558319,
      "learning_rate": 4.021079881656805e-05,
      "loss": 0.2999,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.4676787853240967,
      "learning_rate": 4.00258875739645e-05,
      "loss": 0.2917,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.38811057806015015,
      "learning_rate": 3.9840976331360944e-05,
      "loss": 0.3508,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.3421308696269989,
      "learning_rate": 3.96560650887574e-05,
      "loss": 0.3264,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.4813695549964905,
      "learning_rate": 3.947115384615385e-05,
      "loss": 0.3533,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.2690696716308594,
      "learning_rate": 3.92862426035503e-05,
      "loss": 0.3287,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.20071455836296082,
      "learning_rate": 3.910133136094675e-05,
      "loss": 0.3548,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.17227068543434143,
      "learning_rate": 3.89164201183432e-05,
      "loss": 0.3532,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.5270490646362305,
      "learning_rate": 3.873150887573965e-05,
      "loss": 0.3076,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.45984238386154175,
      "learning_rate": 3.8546597633136094e-05,
      "loss": 0.3559,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.3911660611629486,
      "learning_rate": 3.836168639053255e-05,
      "loss": 0.3278,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.46101465821266174,
      "learning_rate": 3.8176775147928993e-05,
      "loss": 0.3684,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.1499391496181488,
      "learning_rate": 3.7991863905325446e-05,
      "loss": 0.3586,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.38246503472328186,
      "learning_rate": 3.780695266272189e-05,
      "loss": 0.321,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.3217396140098572,
      "learning_rate": 3.7622041420118346e-05,
      "loss": 0.3284,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.2382480949163437,
      "learning_rate": 3.74371301775148e-05,
      "loss": 0.3029,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.23380298912525177,
      "learning_rate": 3.7252218934911245e-05,
      "loss": 0.3508,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.3705536723136902,
      "learning_rate": 3.70673076923077e-05,
      "loss": 0.3239,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.4131792187690735,
      "learning_rate": 3.6882396449704144e-05,
      "loss": 0.3087,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3169497549533844,
      "learning_rate": 3.66974852071006e-05,
      "loss": 0.3166,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5084013342857361,
      "learning_rate": 3.651257396449704e-05,
      "loss": 0.3415,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.6120607852935791,
      "learning_rate": 3.632766272189349e-05,
      "loss": 0.3454,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.5013637542724609,
      "learning_rate": 3.614275147928994e-05,
      "loss": 0.3218,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.36776936054229736,
      "learning_rate": 3.595784023668639e-05,
      "loss": 0.2946,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.2302335798740387,
      "learning_rate": 3.577292899408284e-05,
      "loss": 0.3457,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.4934726357460022,
      "learning_rate": 3.558801775147929e-05,
      "loss": 0.3521,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.21710312366485596,
      "learning_rate": 3.540310650887574e-05,
      "loss": 0.3142,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3391862213611603,
      "learning_rate": 3.5218195266272194e-05,
      "loss": 0.3324,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.20327623188495636,
      "learning_rate": 3.503328402366864e-05,
      "loss": 0.3784,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.313965380191803,
      "learning_rate": 3.484837278106509e-05,
      "loss": 0.3731,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.4422021508216858,
      "learning_rate": 3.466346153846154e-05,
      "loss": 0.3103,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.3779517114162445,
      "learning_rate": 3.447855029585799e-05,
      "loss": 0.3355,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.19053377211093903,
      "learning_rate": 3.429363905325444e-05,
      "loss": 0.3173,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.3443893790245056,
      "learning_rate": 3.4108727810650885e-05,
      "loss": 0.2994,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.33543336391448975,
      "eval_runtime": 149.6512,
      "eval_samples_per_second": 25.125,
      "eval_steps_per_second": 6.281,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.2728087902069092,
      "learning_rate": 3.392381656804734e-05,
      "loss": 0.3092,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.4168395400047302,
      "learning_rate": 3.3738905325443784e-05,
      "loss": 0.36,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.3270339369773865,
      "learning_rate": 3.355399408284024e-05,
      "loss": 0.3366,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.5011565685272217,
      "learning_rate": 3.336908284023669e-05,
      "loss": 0.3242,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.4682576060295105,
      "learning_rate": 3.318417159763314e-05,
      "loss": 0.3005,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.41979822516441345,
      "learning_rate": 3.299926035502959e-05,
      "loss": 0.3361,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.38179343938827515,
      "learning_rate": 3.2814349112426035e-05,
      "loss": 0.2938,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.5419378876686096,
      "learning_rate": 3.262943786982249e-05,
      "loss": 0.3105,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.2629750072956085,
      "learning_rate": 3.2444526627218934e-05,
      "loss": 0.3315,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 0.584373950958252,
      "learning_rate": 3.225961538461539e-05,
      "loss": 0.3384,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.33859845995903015,
      "learning_rate": 3.2074704142011834e-05,
      "loss": 0.3219,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 0.5449312925338745,
      "learning_rate": 3.188979289940828e-05,
      "loss": 0.3298,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 0.587112545967102,
      "learning_rate": 3.170488165680473e-05,
      "loss": 0.335,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.25086361169815063,
      "learning_rate": 3.1519970414201186e-05,
      "loss": 0.3445,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.48903822898864746,
      "learning_rate": 3.133505917159764e-05,
      "loss": 0.337,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.42592328786849976,
      "learning_rate": 3.1150147928994085e-05,
      "loss": 0.312,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.3354107439517975,
      "learning_rate": 3.096523668639054e-05,
      "loss": 0.325,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.1471644937992096,
      "learning_rate": 3.0780325443786984e-05,
      "loss": 0.3288,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.4027262330055237,
      "learning_rate": 3.059541420118343e-05,
      "loss": 0.3297,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.5394635796546936,
      "learning_rate": 3.0410502958579883e-05,
      "loss": 0.3357,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 0.5319342017173767,
      "learning_rate": 3.0225591715976333e-05,
      "loss": 0.32,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.32667073607444763,
      "learning_rate": 3.0040680473372783e-05,
      "loss": 0.3374,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.3816269338130951,
      "learning_rate": 2.9855769230769232e-05,
      "loss": 0.3523,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.44087401032447815,
      "learning_rate": 2.9670857988165685e-05,
      "loss": 0.3147,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.5419476628303528,
      "learning_rate": 2.948594674556213e-05,
      "loss": 0.3494,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.3785238265991211,
      "learning_rate": 2.9301035502958578e-05,
      "loss": 0.2937,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.09985829889774323,
      "learning_rate": 2.911612426035503e-05,
      "loss": 0.3331,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.49108827114105225,
      "learning_rate": 2.893121301775148e-05,
      "loss": 0.3375,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.003074086969718337,
      "learning_rate": 2.8746301775147933e-05,
      "loss": 0.3192,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.581308901309967,
      "learning_rate": 2.856139053254438e-05,
      "loss": 0.318,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.27485334873199463,
      "learning_rate": 2.8376479289940826e-05,
      "loss": 0.3575,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.44903892278671265,
      "learning_rate": 2.819156804733728e-05,
      "loss": 0.3294,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.2626290023326874,
      "learning_rate": 2.8006656804733728e-05,
      "loss": 0.3526,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.3063274025917053,
      "learning_rate": 2.782174556213018e-05,
      "loss": 0.3466,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.3004022538661957,
      "learning_rate": 2.7636834319526627e-05,
      "loss": 0.284,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.4437371790409088,
      "learning_rate": 2.745192307692308e-05,
      "loss": 0.3385,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.534461498260498,
      "learning_rate": 2.7267011834319527e-05,
      "loss": 0.3101,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.409223735332489,
      "learning_rate": 2.7082100591715976e-05,
      "loss": 0.3295,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.29216068983078003,
      "learning_rate": 2.689718934911243e-05,
      "loss": 0.3206,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 0.3953162729740143,
      "learning_rate": 2.6712278106508875e-05,
      "loss": 0.3066,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.536665678024292,
      "learning_rate": 2.652736686390533e-05,
      "loss": 0.3644,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.544749915599823,
      "learning_rate": 2.6342455621301775e-05,
      "loss": 0.3018,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.9345158934593201,
      "learning_rate": 2.6157544378698228e-05,
      "loss": 0.275,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.875901460647583,
      "learning_rate": 2.5972633136094677e-05,
      "loss": 0.3504,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.14648018777370453,
      "learning_rate": 2.5787721893491123e-05,
      "loss": 0.3616,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.05457475036382675,
      "learning_rate": 2.5602810650887576e-05,
      "loss": 0.2938,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.4773337244987488,
      "learning_rate": 2.5417899408284023e-05,
      "loss": 0.3108,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.2656041979789734,
      "learning_rate": 2.5232988165680476e-05,
      "loss": 0.3358,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.37222832441329956,
      "learning_rate": 2.5048076923076925e-05,
      "loss": 0.2973,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.34127745032310486,
      "learning_rate": 2.4863165680473375e-05,
      "loss": 0.3114,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 0.4364180862903595,
      "learning_rate": 2.4678254437869824e-05,
      "loss": 0.3391,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.3789009153842926,
      "learning_rate": 2.4493343195266274e-05,
      "loss": 0.3176,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.3613814115524292,
      "learning_rate": 2.430843195266272e-05,
      "loss": 0.3569,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.4399675726890564,
      "learning_rate": 2.4123520710059173e-05,
      "loss": 0.3232,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.2335621416568756,
      "learning_rate": 2.3938609467455623e-05,
      "loss": 0.3297,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.3551502823829651,
      "learning_rate": 2.3753698224852072e-05,
      "loss": 0.2905,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.19352726638317108,
      "learning_rate": 2.3568786982248522e-05,
      "loss": 0.3484,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 0.4489802122116089,
      "learning_rate": 2.338387573964497e-05,
      "loss": 0.2913,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.4172099828720093,
      "learning_rate": 2.319896449704142e-05,
      "loss": 0.313,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.1936250627040863,
      "learning_rate": 2.301405325443787e-05,
      "loss": 0.3208,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.49476826190948486,
      "learning_rate": 2.282914201183432e-05,
      "loss": 0.3133,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.10827871412038803,
      "learning_rate": 2.264423076923077e-05,
      "loss": 0.3349,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.4835253059864044,
      "learning_rate": 2.245931952662722e-05,
      "loss": 0.3418,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.5105867981910706,
      "learning_rate": 2.227440828402367e-05,
      "loss": 0.2946,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.24920959770679474,
      "learning_rate": 2.2089497041420122e-05,
      "loss": 0.3195,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.2540547549724579,
      "learning_rate": 2.190458579881657e-05,
      "loss": 0.3358,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 0.27658531069755554,
      "learning_rate": 2.1719674556213018e-05,
      "loss": 0.2787,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.12258279323577881,
      "learning_rate": 2.1534763313609468e-05,
      "loss": 0.3186,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 0.20420484244823456,
      "learning_rate": 2.1349852071005917e-05,
      "loss": 0.3123,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.3878079354763031,
      "learning_rate": 2.116494082840237e-05,
      "loss": 0.3642,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.5369937419891357,
      "learning_rate": 2.098002958579882e-05,
      "loss": 0.3562,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.5124796628952026,
      "learning_rate": 2.0795118343195266e-05,
      "loss": 0.3716,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.36729103326797485,
      "learning_rate": 2.0610207100591716e-05,
      "loss": 0.314,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.40872427821159363,
      "learning_rate": 2.0425295857988165e-05,
      "loss": 0.3295,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 0.4453684985637665,
      "learning_rate": 2.0240384615384618e-05,
      "loss": 0.3601,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.13359762728214264,
      "learning_rate": 2.0055473372781068e-05,
      "loss": 0.3206,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.3406856656074524,
      "learning_rate": 1.9870562130177517e-05,
      "loss": 0.3269,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.21421606838703156,
      "learning_rate": 1.9685650887573964e-05,
      "loss": 0.3624,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.28234612941741943,
      "learning_rate": 1.9500739644970413e-05,
      "loss": 0.3139,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.29307034611701965,
      "learning_rate": 1.9315828402366866e-05,
      "loss": 0.3436,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.4331623315811157,
      "learning_rate": 1.9130917159763316e-05,
      "loss": 0.3265,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.28533291816711426,
      "learning_rate": 1.8946005917159765e-05,
      "loss": 0.3284,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.2694450616836548,
      "learning_rate": 1.8761094674556215e-05,
      "loss": 0.3353,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.4831714332103729,
      "learning_rate": 1.857618343195266e-05,
      "loss": 0.3164,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.28395968675613403,
      "learning_rate": 1.839127218934911e-05,
      "loss": 0.3303,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.44813352823257446,
      "learning_rate": 1.8206360946745564e-05,
      "loss": 0.337,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.18531902134418488,
      "learning_rate": 1.8021449704142013e-05,
      "loss": 0.3243,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.22352084517478943,
      "learning_rate": 1.7836538461538463e-05,
      "loss": 0.3061,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.33280467987060547,
      "learning_rate": 1.7651627218934913e-05,
      "loss": 0.3213,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.42859482765197754,
      "learning_rate": 1.7466715976331362e-05,
      "loss": 0.3316,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.325950026512146,
      "learning_rate": 1.7281804733727812e-05,
      "loss": 0.34,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.42180800437927246,
      "learning_rate": 1.709689349112426e-05,
      "loss": 0.3198,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.334541380405426,
      "eval_runtime": 149.6613,
      "eval_samples_per_second": 25.123,
      "eval_steps_per_second": 6.281,
      "step": 18360
    },
    {
      "epoch": 2.0043572984749454,
      "grad_norm": 0.3144282400608063,
      "learning_rate": 1.691198224852071e-05,
      "loss": 0.3297,
      "step": 18400
    },
    {
      "epoch": 2.0152505446623095,
      "grad_norm": 0.33364373445510864,
      "learning_rate": 1.672707100591716e-05,
      "loss": 0.3186,
      "step": 18500
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.24327144026756287,
      "learning_rate": 1.654215976331361e-05,
      "loss": 0.3216,
      "step": 18600
    },
    {
      "epoch": 2.037037037037037,
      "grad_norm": 0.7045795917510986,
      "learning_rate": 1.635724852071006e-05,
      "loss": 0.307,
      "step": 18700
    },
    {
      "epoch": 2.047930283224401,
      "grad_norm": 0.5293974280357361,
      "learning_rate": 1.617233727810651e-05,
      "loss": 0.3105,
      "step": 18800
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.34824272990226746,
      "learning_rate": 1.598742603550296e-05,
      "loss": 0.3035,
      "step": 18900
    },
    {
      "epoch": 2.0697167755991286,
      "grad_norm": 0.4438057541847229,
      "learning_rate": 1.580251479289941e-05,
      "loss": 0.3195,
      "step": 19000
    },
    {
      "epoch": 2.0806100217864922,
      "grad_norm": 0.5254501104354858,
      "learning_rate": 1.5617603550295858e-05,
      "loss": 0.3084,
      "step": 19100
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.3807109594345093,
      "learning_rate": 1.5432692307692308e-05,
      "loss": 0.3328,
      "step": 19200
    },
    {
      "epoch": 2.10239651416122,
      "grad_norm": 0.4794992208480835,
      "learning_rate": 1.5247781065088759e-05,
      "loss": 0.311,
      "step": 19300
    },
    {
      "epoch": 2.113289760348584,
      "grad_norm": 0.2705475687980652,
      "learning_rate": 1.5062869822485207e-05,
      "loss": 0.3478,
      "step": 19400
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 0.5632755160331726,
      "learning_rate": 1.488165680473373e-05,
      "loss": 0.3034,
      "step": 19500
    },
    {
      "epoch": 2.1350762527233114,
      "grad_norm": 0.30118510127067566,
      "learning_rate": 1.4696745562130179e-05,
      "loss": 0.3296,
      "step": 19600
    },
    {
      "epoch": 2.1459694989106755,
      "grad_norm": 0.544930100440979,
      "learning_rate": 1.4511834319526627e-05,
      "loss": 0.3415,
      "step": 19700
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.38708582520484924,
      "learning_rate": 1.4326923076923076e-05,
      "loss": 0.3334,
      "step": 19800
    },
    {
      "epoch": 2.167755991285403,
      "grad_norm": 0.31875771284103394,
      "learning_rate": 1.4142011834319526e-05,
      "loss": 0.3191,
      "step": 19900
    },
    {
      "epoch": 2.178649237472767,
      "grad_norm": 0.26267775893211365,
      "learning_rate": 1.3957100591715977e-05,
      "loss": 0.3292,
      "step": 20000
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 0.2667739987373352,
      "learning_rate": 1.3772189349112427e-05,
      "loss": 0.3644,
      "step": 20100
    },
    {
      "epoch": 2.2004357298474946,
      "grad_norm": 0.48438218235969543,
      "learning_rate": 1.3587278106508877e-05,
      "loss": 0.322,
      "step": 20200
    },
    {
      "epoch": 2.2113289760348582,
      "grad_norm": 0.23734784126281738,
      "learning_rate": 1.3402366863905328e-05,
      "loss": 0.2907,
      "step": 20300
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.4929323196411133,
      "learning_rate": 1.3217455621301774e-05,
      "loss": 0.2926,
      "step": 20400
    },
    {
      "epoch": 2.233115468409586,
      "grad_norm": 0.33105042576789856,
      "learning_rate": 1.3032544378698225e-05,
      "loss": 0.3021,
      "step": 20500
    },
    {
      "epoch": 2.24400871459695,
      "grad_norm": 0.41902557015419006,
      "learning_rate": 1.2847633136094675e-05,
      "loss": 0.3215,
      "step": 20600
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 0.4374207556247711,
      "learning_rate": 1.2662721893491125e-05,
      "loss": 0.3253,
      "step": 20700
    },
    {
      "epoch": 2.265795206971678,
      "grad_norm": 0.5027772188186646,
      "learning_rate": 1.2477810650887574e-05,
      "loss": 0.3577,
      "step": 20800
    },
    {
      "epoch": 2.2766884531590414,
      "grad_norm": 0.30872201919555664,
      "learning_rate": 1.2292899408284024e-05,
      "loss": 0.3531,
      "step": 20900
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.6076123118400574,
      "learning_rate": 1.2107988165680473e-05,
      "loss": 0.3292,
      "step": 21000
    },
    {
      "epoch": 2.298474945533769,
      "grad_norm": 0.33537963032722473,
      "learning_rate": 1.1923076923076925e-05,
      "loss": 0.2959,
      "step": 21100
    },
    {
      "epoch": 2.309368191721133,
      "grad_norm": 0.1421593576669693,
      "learning_rate": 1.1738165680473373e-05,
      "loss": 0.3209,
      "step": 21200
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 0.3904847502708435,
      "learning_rate": 1.1553254437869824e-05,
      "loss": 0.3383,
      "step": 21300
    },
    {
      "epoch": 2.3311546840958606,
      "grad_norm": 0.41377735137939453,
      "learning_rate": 1.1368343195266273e-05,
      "loss": 0.3521,
      "step": 21400
    },
    {
      "epoch": 2.342047930283224,
      "grad_norm": 0.5692260265350342,
      "learning_rate": 1.1183431952662721e-05,
      "loss": 0.3245,
      "step": 21500
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.3180845379829407,
      "learning_rate": 1.0998520710059173e-05,
      "loss": 0.3096,
      "step": 21600
    },
    {
      "epoch": 2.363834422657952,
      "grad_norm": 0.6013484001159668,
      "learning_rate": 1.0813609467455622e-05,
      "loss": 0.2945,
      "step": 21700
    },
    {
      "epoch": 2.374727668845316,
      "grad_norm": 0.5802135467529297,
      "learning_rate": 1.0628698224852072e-05,
      "loss": 0.3365,
      "step": 21800
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 0.42410215735435486,
      "learning_rate": 1.0443786982248521e-05,
      "loss": 0.3208,
      "step": 21900
    },
    {
      "epoch": 2.3965141612200433,
      "grad_norm": 0.31027016043663025,
      "learning_rate": 1.0258875739644971e-05,
      "loss": 0.2964,
      "step": 22000
    },
    {
      "epoch": 2.4074074074074074,
      "grad_norm": 0.25657370686531067,
      "learning_rate": 1.007396449704142e-05,
      "loss": 0.3211,
      "step": 22100
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.0017859510844573379,
      "learning_rate": 9.88905325443787e-06,
      "loss": 0.3232,
      "step": 22200
    },
    {
      "epoch": 2.429193899782135,
      "grad_norm": 0.2732713222503662,
      "learning_rate": 9.70414201183432e-06,
      "loss": 0.3188,
      "step": 22300
    },
    {
      "epoch": 2.440087145969499,
      "grad_norm": 0.25704139471054077,
      "learning_rate": 9.51923076923077e-06,
      "loss": 0.3664,
      "step": 22400
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 0.32226303219795227,
      "learning_rate": 9.334319526627219e-06,
      "loss": 0.3056,
      "step": 22500
    },
    {
      "epoch": 2.4618736383442266,
      "grad_norm": 0.49723827838897705,
      "learning_rate": 9.149408284023669e-06,
      "loss": 0.3568,
      "step": 22600
    },
    {
      "epoch": 2.47276688453159,
      "grad_norm": 0.5191864371299744,
      "learning_rate": 8.964497041420118e-06,
      "loss": 0.316,
      "step": 22700
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.4186653792858124,
      "learning_rate": 8.779585798816568e-06,
      "loss": 0.2879,
      "step": 22800
    },
    {
      "epoch": 2.494553376906318,
      "grad_norm": 0.3056560456752777,
      "learning_rate": 8.594674556213019e-06,
      "loss": 0.3667,
      "step": 22900
    },
    {
      "epoch": 2.505446623093682,
      "grad_norm": 0.5359150767326355,
      "learning_rate": 8.409763313609467e-06,
      "loss": 0.346,
      "step": 23000
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 0.5547944903373718,
      "learning_rate": 8.224852071005917e-06,
      "loss": 0.3322,
      "step": 23100
    },
    {
      "epoch": 2.52723311546841,
      "grad_norm": 0.37799322605133057,
      "learning_rate": 8.039940828402368e-06,
      "loss": 0.2898,
      "step": 23200
    },
    {
      "epoch": 2.5381263616557734,
      "grad_norm": 0.47642016410827637,
      "learning_rate": 7.855029585798816e-06,
      "loss": 0.3368,
      "step": 23300
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.5452662706375122,
      "learning_rate": 7.670118343195267e-06,
      "loss": 0.3205,
      "step": 23400
    },
    {
      "epoch": 2.559912854030501,
      "grad_norm": 0.3024633228778839,
      "learning_rate": 7.485207100591717e-06,
      "loss": 0.2732,
      "step": 23500
    },
    {
      "epoch": 2.570806100217865,
      "grad_norm": 0.14685437083244324,
      "learning_rate": 7.300295857988166e-06,
      "loss": 0.3252,
      "step": 23600
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 0.16091355681419373,
      "learning_rate": 7.115384615384615e-06,
      "loss": 0.2933,
      "step": 23700
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.5031288862228394,
      "learning_rate": 6.9304733727810655e-06,
      "loss": 0.3423,
      "step": 23800
    },
    {
      "epoch": 2.6034858387799567,
      "grad_norm": 0.3297833204269409,
      "learning_rate": 6.745562130177516e-06,
      "loss": 0.3508,
      "step": 23900
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.4685778319835663,
      "learning_rate": 6.564349112426035e-06,
      "loss": 0.2954,
      "step": 24000
    },
    {
      "epoch": 2.625272331154684,
      "grad_norm": 0.326387882232666,
      "learning_rate": 6.379437869822485e-06,
      "loss": 0.3219,
      "step": 24100
    },
    {
      "epoch": 2.636165577342048,
      "grad_norm": 0.3794260323047638,
      "learning_rate": 6.194526627218935e-06,
      "loss": 0.3163,
      "step": 24200
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.45082980394363403,
      "learning_rate": 6.0096153846153855e-06,
      "loss": 0.2972,
      "step": 24300
    },
    {
      "epoch": 2.6579520697167753,
      "grad_norm": 0.3462315499782562,
      "learning_rate": 5.824704142011834e-06,
      "loss": 0.3087,
      "step": 24400
    },
    {
      "epoch": 2.6688453159041394,
      "grad_norm": 0.0019421769538894296,
      "learning_rate": 5.639792899408284e-06,
      "loss": 0.3489,
      "step": 24500
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.36389070749282837,
      "learning_rate": 5.454881656804734e-06,
      "loss": 0.3584,
      "step": 24600
    },
    {
      "epoch": 2.690631808278867,
      "grad_norm": 0.6075351238250732,
      "learning_rate": 5.269970414201184e-06,
      "loss": 0.3325,
      "step": 24700
    },
    {
      "epoch": 2.701525054466231,
      "grad_norm": 0.3631156384944916,
      "learning_rate": 5.0850591715976335e-06,
      "loss": 0.3044,
      "step": 24800
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 0.2250618189573288,
      "learning_rate": 4.900147928994083e-06,
      "loss": 0.2884,
      "step": 24900
    },
    {
      "epoch": 2.7233115468409586,
      "grad_norm": 0.25563856959342957,
      "learning_rate": 4.715236686390533e-06,
      "loss": 0.3024,
      "step": 25000
    },
    {
      "epoch": 2.734204793028322,
      "grad_norm": 0.4953233301639557,
      "learning_rate": 4.530325443786983e-06,
      "loss": 0.3176,
      "step": 25100
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.3268318474292755,
      "learning_rate": 4.345414201183432e-06,
      "loss": 0.354,
      "step": 25200
    },
    {
      "epoch": 2.7559912854030504,
      "grad_norm": 0.3799433410167694,
      "learning_rate": 4.1605029585798815e-06,
      "loss": 0.3406,
      "step": 25300
    },
    {
      "epoch": 2.766884531590414,
      "grad_norm": 0.26628345251083374,
      "learning_rate": 3.975591715976332e-06,
      "loss": 0.3478,
      "step": 25400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.3601437211036682,
      "learning_rate": 3.790680473372781e-06,
      "loss": 0.3459,
      "step": 25500
    },
    {
      "epoch": 2.7886710239651418,
      "grad_norm": 0.3279104232788086,
      "learning_rate": 3.6057692307692307e-06,
      "loss": 0.3,
      "step": 25600
    },
    {
      "epoch": 2.7995642701525054,
      "grad_norm": 0.43863293528556824,
      "learning_rate": 3.4208579881656807e-06,
      "loss": 0.366,
      "step": 25700
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.0018058056011795998,
      "learning_rate": 3.2359467455621303e-06,
      "loss": 0.3189,
      "step": 25800
    },
    {
      "epoch": 2.821350762527233,
      "grad_norm": 0.3219521939754486,
      "learning_rate": 3.05103550295858e-06,
      "loss": 0.3273,
      "step": 25900
    },
    {
      "epoch": 2.832244008714597,
      "grad_norm": 0.2958621680736542,
      "learning_rate": 2.86612426035503e-06,
      "loss": 0.3311,
      "step": 26000
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 0.13893947005271912,
      "learning_rate": 2.6812130177514795e-06,
      "loss": 0.3384,
      "step": 26100
    },
    {
      "epoch": 2.8540305010893245,
      "grad_norm": 0.34060680866241455,
      "learning_rate": 2.496301775147929e-06,
      "loss": 0.3125,
      "step": 26200
    },
    {
      "epoch": 2.8649237472766886,
      "grad_norm": 0.49720099568367004,
      "learning_rate": 2.3113905325443787e-06,
      "loss": 0.3329,
      "step": 26300
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.37394237518310547,
      "learning_rate": 2.1264792899408288e-06,
      "loss": 0.3727,
      "step": 26400
    },
    {
      "epoch": 2.886710239651416,
      "grad_norm": 0.25581711530685425,
      "learning_rate": 1.941568047337278e-06,
      "loss": 0.3581,
      "step": 26500
    },
    {
      "epoch": 2.89760348583878,
      "grad_norm": 0.5788483619689941,
      "learning_rate": 1.7566568047337277e-06,
      "loss": 0.3075,
      "step": 26600
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 0.44522109627723694,
      "learning_rate": 1.5717455621301776e-06,
      "loss": 0.2967,
      "step": 26700
    },
    {
      "epoch": 2.9193899782135078,
      "grad_norm": 0.35868892073631287,
      "learning_rate": 1.3868343195266272e-06,
      "loss": 0.2882,
      "step": 26800
    },
    {
      "epoch": 2.9302832244008714,
      "grad_norm": 0.31343746185302734,
      "learning_rate": 1.201923076923077e-06,
      "loss": 0.3364,
      "step": 26900
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.40947434306144714,
      "learning_rate": 1.0170118343195266e-06,
      "loss": 0.3812,
      "step": 27000
    },
    {
      "epoch": 2.952069716775599,
      "grad_norm": 0.27632078528404236,
      "learning_rate": 8.321005917159765e-07,
      "loss": 0.34,
      "step": 27100
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.0018969132797792554,
      "learning_rate": 6.471893491124261e-07,
      "loss": 0.318,
      "step": 27200
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 0.6454443335533142,
      "learning_rate": 4.622781065088758e-07,
      "loss": 0.3208,
      "step": 27300
    },
    {
      "epoch": 2.9847494553376905,
      "grad_norm": 0.2358398735523224,
      "learning_rate": 2.7736686390532544e-07,
      "loss": 0.3131,
      "step": 27400
    },
    {
      "epoch": 2.9956427015250546,
      "grad_norm": 0.38519757986068726,
      "learning_rate": 9.245562130177515e-08,
      "loss": 0.3319,
      "step": 27500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.3343360424041748,
      "eval_runtime": 150.1704,
      "eval_samples_per_second": 25.038,
      "eval_steps_per_second": 6.26,
      "step": 27540
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.435945503986811e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
