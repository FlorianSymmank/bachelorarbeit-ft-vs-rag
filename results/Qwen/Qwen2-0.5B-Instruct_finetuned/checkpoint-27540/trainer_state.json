{
  "best_metric": 0.380516916513443,
  "best_model_checkpoint": "./results/Qwen/Qwen2-0.5B-Instruct_finetuned/checkpoint-27540",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 27540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 105.62371826171875,
      "learning_rate": 9.2e-06,
      "loss": 9.2428,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 2.6055655479431152,
      "learning_rate": 1.91e-05,
      "loss": 3.7343,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.6012031435966492,
      "learning_rate": 2.91e-05,
      "loss": 0.4123,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.2355773150920868,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.442,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.7239788770675659,
      "learning_rate": 4.9e-05,
      "loss": 0.5015,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 108.85816955566406,
      "learning_rate": 4.983357988165681e-05,
      "loss": 0.5353,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 16.85833740234375,
      "learning_rate": 4.964866863905326e-05,
      "loss": 0.4672,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 13.091717720031738,
      "learning_rate": 4.9463757396449707e-05,
      "loss": 0.4615,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.9120664596557617,
      "learning_rate": 4.927884615384616e-05,
      "loss": 0.4061,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.9277171492576599,
      "learning_rate": 4.9093934911242606e-05,
      "loss": 0.3784,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.4205596446990967,
      "learning_rate": 4.890902366863905e-05,
      "loss": 0.3912,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 2.127251148223877,
      "learning_rate": 4.8724112426035505e-05,
      "loss": 0.4142,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 21.504764556884766,
      "learning_rate": 4.853920118343195e-05,
      "loss": 0.4286,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.9009342789649963,
      "learning_rate": 4.8354289940828404e-05,
      "loss": 0.4762,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.49441197514533997,
      "learning_rate": 4.816937869822486e-05,
      "loss": 0.3702,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.34060677886009216,
      "learning_rate": 4.79844674556213e-05,
      "loss": 0.3885,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.40754181146621704,
      "learning_rate": 4.7799556213017756e-05,
      "loss": 0.38,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 6.363555431365967,
      "learning_rate": 4.76146449704142e-05,
      "loss": 0.4115,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.500272274017334,
      "learning_rate": 4.7429733727810656e-05,
      "loss": 0.3896,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.9673653244972229,
      "learning_rate": 4.72448224852071e-05,
      "loss": 0.341,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 85.03998565673828,
      "learning_rate": 4.7059911242603555e-05,
      "loss": 0.378,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.865860104560852,
      "learning_rate": 4.6875e-05,
      "loss": 0.3334,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.3088706135749817,
      "learning_rate": 4.669008875739645e-05,
      "loss": 0.4006,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.7995489835739136,
      "learning_rate": 4.65051775147929e-05,
      "loss": 0.4223,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 1.0194612741470337,
      "learning_rate": 4.632026627218935e-05,
      "loss": 0.3643,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.6931456923484802,
      "learning_rate": 4.6135355029585806e-05,
      "loss": 0.4372,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 1.0489588975906372,
      "learning_rate": 4.595044378698225e-05,
      "loss": 0.3684,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.7142845988273621,
      "learning_rate": 4.5765532544378705e-05,
      "loss": 0.3637,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.723638117313385,
      "learning_rate": 4.558062130177515e-05,
      "loss": 0.3636,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.7815013527870178,
      "learning_rate": 4.53957100591716e-05,
      "loss": 0.3123,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.6374711394309998,
      "learning_rate": 4.521079881656805e-05,
      "loss": 0.3637,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 1.0448187589645386,
      "learning_rate": 4.50258875739645e-05,
      "loss": 0.3616,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 1.0237454175949097,
      "learning_rate": 4.484097633136095e-05,
      "loss": 0.39,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.6566723585128784,
      "learning_rate": 4.4656065088757396e-05,
      "loss": 0.4541,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.6311634182929993,
      "learning_rate": 4.447115384615384e-05,
      "loss": 0.3346,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.9347183108329773,
      "learning_rate": 4.4286242603550295e-05,
      "loss": 0.4047,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.776522159576416,
      "learning_rate": 4.410133136094675e-05,
      "loss": 0.3676,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.8351211547851562,
      "learning_rate": 4.39164201183432e-05,
      "loss": 0.3762,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.7610623240470886,
      "learning_rate": 4.373150887573965e-05,
      "loss": 0.381,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.8610846400260925,
      "learning_rate": 4.35465976331361e-05,
      "loss": 0.421,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.411176472902298,
      "learning_rate": 4.336168639053255e-05,
      "loss": 0.3902,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.8221755623817444,
      "learning_rate": 4.317677514792899e-05,
      "loss": 0.3425,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.6072688102722168,
      "learning_rate": 4.2991863905325446e-05,
      "loss": 0.391,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.49926093220710754,
      "learning_rate": 4.280695266272189e-05,
      "loss": 0.3893,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.6220537424087524,
      "learning_rate": 4.2622041420118345e-05,
      "loss": 0.3625,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.878628134727478,
      "learning_rate": 4.243713017751479e-05,
      "loss": 0.3872,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.6484164595603943,
      "learning_rate": 4.2252218934911244e-05,
      "loss": 0.3769,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.5418857932090759,
      "learning_rate": 4.20673076923077e-05,
      "loss": 0.3303,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.5652867555618286,
      "learning_rate": 4.1882396449704144e-05,
      "loss": 0.3859,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.7693144083023071,
      "learning_rate": 4.1697485207100597e-05,
      "loss": 0.4203,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.5214940905570984,
      "learning_rate": 4.151257396449704e-05,
      "loss": 0.324,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.6434569358825684,
      "learning_rate": 4.1327662721893496e-05,
      "loss": 0.3901,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.8299868702888489,
      "learning_rate": 4.114275147928994e-05,
      "loss": 0.3879,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.8346062302589417,
      "learning_rate": 4.095784023668639e-05,
      "loss": 0.3903,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.39007505774497986,
      "learning_rate": 4.077292899408284e-05,
      "loss": 0.3553,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 1.0470235347747803,
      "learning_rate": 4.058801775147929e-05,
      "loss": 0.3852,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.4971875846385956,
      "learning_rate": 4.040310650887574e-05,
      "loss": 0.3496,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.5399430394172668,
      "learning_rate": 4.021819526627219e-05,
      "loss": 0.3419,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.8807582259178162,
      "learning_rate": 4.0033284023668646e-05,
      "loss": 0.3344,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.7638674378395081,
      "learning_rate": 3.984837278106509e-05,
      "loss": 0.4023,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.6130251884460449,
      "learning_rate": 3.966346153846154e-05,
      "loss": 0.3729,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.6843592524528503,
      "learning_rate": 3.947855029585799e-05,
      "loss": 0.4049,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.368865430355072,
      "learning_rate": 3.929363905325444e-05,
      "loss": 0.3742,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.35295844078063965,
      "learning_rate": 3.910872781065089e-05,
      "loss": 0.4053,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.3707742691040039,
      "learning_rate": 3.892381656804734e-05,
      "loss": 0.4015,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.9093976020812988,
      "learning_rate": 3.873890532544378e-05,
      "loss": 0.3514,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.8623837828636169,
      "learning_rate": 3.8553994082840236e-05,
      "loss": 0.4068,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.6721979975700378,
      "learning_rate": 3.836908284023669e-05,
      "loss": 0.3751,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.7002836465835571,
      "learning_rate": 3.818417159763314e-05,
      "loss": 0.4232,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.35613763332366943,
      "learning_rate": 3.799926035502959e-05,
      "loss": 0.4094,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.6556509137153625,
      "learning_rate": 3.781434911242604e-05,
      "loss": 0.3682,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.681384801864624,
      "learning_rate": 3.762943786982249e-05,
      "loss": 0.3763,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.43811357021331787,
      "learning_rate": 3.7444526627218934e-05,
      "loss": 0.3447,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.40129923820495605,
      "learning_rate": 3.725961538461539e-05,
      "loss": 0.4014,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.6946911215782166,
      "learning_rate": 3.707470414201183e-05,
      "loss": 0.3687,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.7925137281417847,
      "learning_rate": 3.6889792899408286e-05,
      "loss": 0.3539,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.535254716873169,
      "learning_rate": 3.670488165680473e-05,
      "loss": 0.3592,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.7346944808959961,
      "learning_rate": 3.6519970414201185e-05,
      "loss": 0.3878,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 1.034429907798767,
      "learning_rate": 3.633505917159764e-05,
      "loss": 0.3946,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.7240991592407227,
      "learning_rate": 3.6150147928994085e-05,
      "loss": 0.3661,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.417341947555542,
      "learning_rate": 3.596523668639054e-05,
      "loss": 0.3345,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.9493842124938965,
      "learning_rate": 3.5780325443786984e-05,
      "loss": 0.3939,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.9266827702522278,
      "learning_rate": 3.559541420118344e-05,
      "loss": 0.4019,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.7368626594543457,
      "learning_rate": 3.541050295857988e-05,
      "loss": 0.3582,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.5193295478820801,
      "learning_rate": 3.522559171597633e-05,
      "loss": 0.3789,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.9104666709899902,
      "learning_rate": 3.504068047337278e-05,
      "loss": 0.4312,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.5399556159973145,
      "learning_rate": 3.485576923076923e-05,
      "loss": 0.4232,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.5979005694389343,
      "learning_rate": 3.467085798816568e-05,
      "loss": 0.3542,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.6207601428031921,
      "learning_rate": 3.4485946745562134e-05,
      "loss": 0.3806,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.33755016326904297,
      "learning_rate": 3.430103550295858e-05,
      "loss": 0.3609,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.5451485514640808,
      "learning_rate": 3.4116124260355034e-05,
      "loss": 0.3418,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3822547197341919,
      "eval_runtime": 73.9697,
      "eval_samples_per_second": 50.832,
      "eval_steps_per_second": 12.708,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.3904242217540741,
      "learning_rate": 3.393121301775148e-05,
      "loss": 0.3531,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.6423860788345337,
      "learning_rate": 3.374630177514793e-05,
      "loss": 0.4111,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.5342118740081787,
      "learning_rate": 3.356139053254438e-05,
      "loss": 0.3848,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.9288251996040344,
      "learning_rate": 3.337647928994083e-05,
      "loss": 0.369,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.9111500382423401,
      "learning_rate": 3.319156804733728e-05,
      "loss": 0.3449,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.7586154341697693,
      "learning_rate": 3.300665680473373e-05,
      "loss": 0.3843,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.667133629322052,
      "learning_rate": 3.282174556213018e-05,
      "loss": 0.3346,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.8836100101470947,
      "learning_rate": 3.263868343195267e-05,
      "loss": 0.3551,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.38101083040237427,
      "learning_rate": 3.2453772189349114e-05,
      "loss": 0.3761,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 0.8466500043869019,
      "learning_rate": 3.226886094674557e-05,
      "loss": 0.3861,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.5473566651344299,
      "learning_rate": 3.208394970414201e-05,
      "loss": 0.3692,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 1.0822962522506714,
      "learning_rate": 3.189903846153846e-05,
      "loss": 0.3742,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 0.8401780724525452,
      "learning_rate": 3.171412721893491e-05,
      "loss": 0.3809,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.44483283162117004,
      "learning_rate": 3.152921597633136e-05,
      "loss": 0.3943,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.8000989556312561,
      "learning_rate": 3.134430473372781e-05,
      "loss": 0.3859,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.7236023545265198,
      "learning_rate": 3.1159393491124264e-05,
      "loss": 0.3564,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.5662515759468079,
      "learning_rate": 3.097448224852072e-05,
      "loss": 0.3716,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.2528456151485443,
      "learning_rate": 3.0789571005917164e-05,
      "loss": 0.3735,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.46331414580345154,
      "learning_rate": 3.060465976331361e-05,
      "loss": 0.3768,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.8304349780082703,
      "learning_rate": 3.0419748520710063e-05,
      "loss": 0.3842,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 0.8858566284179688,
      "learning_rate": 3.023483727810651e-05,
      "loss": 0.365,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.4489497244358063,
      "learning_rate": 3.0049926035502962e-05,
      "loss": 0.3838,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.6789712905883789,
      "learning_rate": 2.9865014792899408e-05,
      "loss": 0.4052,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.6046361923217773,
      "learning_rate": 2.9680103550295858e-05,
      "loss": 0.36,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.9240265488624573,
      "learning_rate": 2.949519230769231e-05,
      "loss": 0.4018,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.5001474022865295,
      "learning_rate": 2.9310281065088757e-05,
      "loss": 0.3349,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.17512916028499603,
      "learning_rate": 2.912536982248521e-05,
      "loss": 0.3795,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.8315237760543823,
      "learning_rate": 2.8940458579881656e-05,
      "loss": 0.3858,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.004785910248756409,
      "learning_rate": 2.875554733727811e-05,
      "loss": 0.3644,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.9405527114868164,
      "learning_rate": 2.857063609467456e-05,
      "loss": 0.3651,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.5504268407821655,
      "learning_rate": 2.8385724852071005e-05,
      "loss": 0.4094,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.6365273594856262,
      "learning_rate": 2.8200813609467458e-05,
      "loss": 0.3786,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.3585309684276581,
      "learning_rate": 2.8015902366863904e-05,
      "loss": 0.4015,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.8146622776985168,
      "learning_rate": 2.7830991124260357e-05,
      "loss": 0.3971,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.630963921546936,
      "learning_rate": 2.7646079881656807e-05,
      "loss": 0.3227,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.6897190809249878,
      "learning_rate": 2.7461168639053253e-05,
      "loss": 0.3857,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.9065166115760803,
      "learning_rate": 2.7276257396449706e-05,
      "loss": 0.3569,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.5793470740318298,
      "learning_rate": 2.7093195266272193e-05,
      "loss": 0.3911,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.40803277492523193,
      "learning_rate": 2.690828402366864e-05,
      "loss": 0.3659,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 68.09601593017578,
      "learning_rate": 2.6723372781065092e-05,
      "loss": 0.3557,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.9100403189659119,
      "learning_rate": 2.6538461538461538e-05,
      "loss": 0.4169,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.799099326133728,
      "learning_rate": 2.6353550295857988e-05,
      "loss": 0.3459,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.545759379863739,
      "learning_rate": 2.616863905325444e-05,
      "loss": 0.3158,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.351840615272522,
      "learning_rate": 2.5983727810650887e-05,
      "loss": 0.4011,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.3663208782672882,
      "learning_rate": 2.579881656804734e-05,
      "loss": 0.4139,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.1351063847541809,
      "learning_rate": 2.5613905325443786e-05,
      "loss": 0.3361,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.4995329976081848,
      "learning_rate": 2.542899408284024e-05,
      "loss": 0.3571,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.8183411955833435,
      "learning_rate": 2.524408284023669e-05,
      "loss": 0.384,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.9428404569625854,
      "learning_rate": 2.5059171597633135e-05,
      "loss": 0.3412,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.532735288143158,
      "learning_rate": 2.4874260355029588e-05,
      "loss": 0.3573,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 1.3097999095916748,
      "learning_rate": 2.4689349112426034e-05,
      "loss": 0.3884,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.9843536615371704,
      "learning_rate": 2.4504437869822487e-05,
      "loss": 0.3629,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.5926337838172913,
      "learning_rate": 2.4319526627218937e-05,
      "loss": 0.4048,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.6587401032447815,
      "learning_rate": 2.4134615384615386e-05,
      "loss": 0.3667,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.32755398750305176,
      "learning_rate": 2.3949704142011836e-05,
      "loss": 0.3756,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.6388418674468994,
      "learning_rate": 2.3764792899408286e-05,
      "loss": 0.3307,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.30511733889579773,
      "learning_rate": 2.3579881656804735e-05,
      "loss": 0.3971,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 1.3084845542907715,
      "learning_rate": 2.3394970414201185e-05,
      "loss": 0.3329,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.704243004322052,
      "learning_rate": 2.3210059171597634e-05,
      "loss": 0.3569,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.271373450756073,
      "learning_rate": 2.3025147928994084e-05,
      "loss": 0.3669,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.7306023836135864,
      "learning_rate": 2.2840236686390534e-05,
      "loss": 0.3589,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.2853826582431793,
      "learning_rate": 2.2655325443786983e-05,
      "loss": 0.3821,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.8745772242546082,
      "learning_rate": 2.2470414201183433e-05,
      "loss": 0.387,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.6887449026107788,
      "learning_rate": 2.2285502958579882e-05,
      "loss": 0.3374,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.40269625186920166,
      "learning_rate": 2.2100591715976332e-05,
      "loss": 0.367,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.7512320280075073,
      "learning_rate": 2.191568047337278e-05,
      "loss": 0.3854,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 1.3879576921463013,
      "learning_rate": 2.173076923076923e-05,
      "loss": 0.3181,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.18095846474170685,
      "learning_rate": 2.154585798816568e-05,
      "loss": 0.3645,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 0.40324699878692627,
      "learning_rate": 2.136094674556213e-05,
      "loss": 0.3588,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.7211184501647949,
      "learning_rate": 2.117603550295858e-05,
      "loss": 0.4157,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.7380110025405884,
      "learning_rate": 2.099112426035503e-05,
      "loss": 0.407,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.8711483478546143,
      "learning_rate": 2.0808062130177516e-05,
      "loss": 0.4234,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.5405778288841248,
      "learning_rate": 2.0623150887573966e-05,
      "loss": 0.3581,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.7022573351860046,
      "learning_rate": 2.0438239644970412e-05,
      "loss": 0.3758,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 1.107786774635315,
      "learning_rate": 2.0253328402366865e-05,
      "loss": 0.4103,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.30884096026420593,
      "learning_rate": 2.0068417159763315e-05,
      "loss": 0.3638,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.4864565432071686,
      "learning_rate": 1.9883505917159764e-05,
      "loss": 0.3737,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.253869891166687,
      "learning_rate": 1.9698594674556214e-05,
      "loss": 0.4147,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.4329172372817993,
      "learning_rate": 1.9513683431952664e-05,
      "loss": 0.3596,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.556205153465271,
      "learning_rate": 1.9328772189349113e-05,
      "loss": 0.3904,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.6913254857063293,
      "learning_rate": 1.9143860946745563e-05,
      "loss": 0.3731,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.5102167725563049,
      "learning_rate": 1.8958949704142012e-05,
      "loss": 0.3728,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.4500056505203247,
      "learning_rate": 1.8774038461538462e-05,
      "loss": 0.3833,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.9107269048690796,
      "learning_rate": 1.858912721893491e-05,
      "loss": 0.3602,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.7315026521682739,
      "learning_rate": 1.840421597633136e-05,
      "loss": 0.3778,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.7389885187149048,
      "learning_rate": 1.8219304733727814e-05,
      "loss": 0.3848,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.3833453953266144,
      "learning_rate": 1.803439349112426e-05,
      "loss": 0.3725,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.4290637671947479,
      "learning_rate": 1.784948224852071e-05,
      "loss": 0.351,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.46921879053115845,
      "learning_rate": 1.766457100591716e-05,
      "loss": 0.3687,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.6414704918861389,
      "learning_rate": 1.747965976331361e-05,
      "loss": 0.3797,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.7786303758621216,
      "learning_rate": 1.7294748520710062e-05,
      "loss": 0.3881,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.6336289048194885,
      "learning_rate": 1.7109837278106512e-05,
      "loss": 0.3648,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.3808087408542633,
      "eval_runtime": 73.2704,
      "eval_samples_per_second": 51.317,
      "eval_steps_per_second": 12.829,
      "step": 18360
    },
    {
      "epoch": 2.0043572984749454,
      "grad_norm": 0.5548420548439026,
      "learning_rate": 1.6924926035502958e-05,
      "loss": 0.377,
      "step": 18400
    },
    {
      "epoch": 2.0152505446623095,
      "grad_norm": 0.41667214035987854,
      "learning_rate": 1.6740014792899408e-05,
      "loss": 0.3617,
      "step": 18500
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.34476032853126526,
      "learning_rate": 1.6556952662721894e-05,
      "loss": 0.369,
      "step": 18600
    },
    {
      "epoch": 2.037037037037037,
      "grad_norm": 1.0973633527755737,
      "learning_rate": 1.6372041420118344e-05,
      "loss": 0.3519,
      "step": 18700
    },
    {
      "epoch": 2.047930283224401,
      "grad_norm": 0.7808068990707397,
      "learning_rate": 1.6187130177514794e-05,
      "loss": 0.3563,
      "step": 18800
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.5894073843955994,
      "learning_rate": 1.6002218934911243e-05,
      "loss": 0.3469,
      "step": 18900
    },
    {
      "epoch": 2.0697167755991286,
      "grad_norm": 1.351292371749878,
      "learning_rate": 1.5817307692307693e-05,
      "loss": 0.3674,
      "step": 19000
    },
    {
      "epoch": 2.0806100217864922,
      "grad_norm": 0.9173813462257385,
      "learning_rate": 1.5632396449704142e-05,
      "loss": 0.3529,
      "step": 19100
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.6522893309593201,
      "learning_rate": 1.5447485207100592e-05,
      "loss": 0.3803,
      "step": 19200
    },
    {
      "epoch": 2.10239651416122,
      "grad_norm": 0.9295551776885986,
      "learning_rate": 1.526257396449704e-05,
      "loss": 0.356,
      "step": 19300
    },
    {
      "epoch": 2.113289760348584,
      "grad_norm": 0.43504759669303894,
      "learning_rate": 1.5077662721893493e-05,
      "loss": 0.3974,
      "step": 19400
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 9.549342155456543,
      "learning_rate": 1.4892751479289941e-05,
      "loss": 0.3474,
      "step": 19500
    },
    {
      "epoch": 2.1350762527233114,
      "grad_norm": 4.265612602233887,
      "learning_rate": 1.470784023668639e-05,
      "loss": 0.3792,
      "step": 19600
    },
    {
      "epoch": 2.1459694989106755,
      "grad_norm": 0.8592677116394043,
      "learning_rate": 1.452292899408284e-05,
      "loss": 0.3911,
      "step": 19700
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 2.4241549968719482,
      "learning_rate": 1.4338017751479291e-05,
      "loss": 0.3812,
      "step": 19800
    },
    {
      "epoch": 2.167755991285403,
      "grad_norm": 0.8264802694320679,
      "learning_rate": 1.4153106508875741e-05,
      "loss": 0.3626,
      "step": 19900
    },
    {
      "epoch": 2.178649237472767,
      "grad_norm": 0.23581603169441223,
      "learning_rate": 1.396819526627219e-05,
      "loss": 0.3763,
      "step": 20000
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 0.4454445242881775,
      "learning_rate": 1.3783284023668638e-05,
      "loss": 0.4173,
      "step": 20100
    },
    {
      "epoch": 2.2004357298474946,
      "grad_norm": 0.758918285369873,
      "learning_rate": 1.3598372781065088e-05,
      "loss": 0.3675,
      "step": 20200
    },
    {
      "epoch": 2.2113289760348582,
      "grad_norm": 0.3328995406627655,
      "learning_rate": 1.341346153846154e-05,
      "loss": 0.3318,
      "step": 20300
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 5.155374526977539,
      "learning_rate": 1.3228550295857989e-05,
      "loss": 0.3353,
      "step": 20400
    },
    {
      "epoch": 2.233115468409586,
      "grad_norm": 0.6234642863273621,
      "learning_rate": 1.3043639053254439e-05,
      "loss": 0.3467,
      "step": 20500
    },
    {
      "epoch": 2.24400871459695,
      "grad_norm": 0.7231196165084839,
      "learning_rate": 1.285872781065089e-05,
      "loss": 0.3694,
      "step": 20600
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 0.5921378135681152,
      "learning_rate": 1.267381656804734e-05,
      "loss": 0.3706,
      "step": 20700
    },
    {
      "epoch": 2.265795206971678,
      "grad_norm": 1.0750908851623535,
      "learning_rate": 1.2488905325443787e-05,
      "loss": 0.4111,
      "step": 20800
    },
    {
      "epoch": 2.2766884531590414,
      "grad_norm": 0.4500095546245575,
      "learning_rate": 1.2303994082840237e-05,
      "loss": 0.4044,
      "step": 20900
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 1.7890821695327759,
      "learning_rate": 1.2119082840236687e-05,
      "loss": 0.3756,
      "step": 21000
    },
    {
      "epoch": 2.298474945533769,
      "grad_norm": 0.6415348052978516,
      "learning_rate": 1.1934171597633136e-05,
      "loss": 0.3375,
      "step": 21100
    },
    {
      "epoch": 2.309368191721133,
      "grad_norm": 0.19541990756988525,
      "learning_rate": 1.1749260355029586e-05,
      "loss": 0.3673,
      "step": 21200
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 3.9516706466674805,
      "learning_rate": 1.1564349112426035e-05,
      "loss": 0.3867,
      "step": 21300
    },
    {
      "epoch": 2.3311546840958606,
      "grad_norm": 0.6029195785522461,
      "learning_rate": 1.1379437869822487e-05,
      "loss": 0.4059,
      "step": 21400
    },
    {
      "epoch": 2.342047930283224,
      "grad_norm": 2.789017677307129,
      "learning_rate": 1.1194526627218936e-05,
      "loss": 0.3727,
      "step": 21500
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.4153103530406952,
      "learning_rate": 1.1009615384615384e-05,
      "loss": 0.3542,
      "step": 21600
    },
    {
      "epoch": 2.363834422657952,
      "grad_norm": 0.8845919370651245,
      "learning_rate": 1.0824704142011835e-05,
      "loss": 0.3366,
      "step": 21700
    },
    {
      "epoch": 2.374727668845316,
      "grad_norm": 0.8747199773788452,
      "learning_rate": 1.0639792899408285e-05,
      "loss": 0.3832,
      "step": 21800
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 0.7162448167800903,
      "learning_rate": 1.0454881656804735e-05,
      "loss": 0.3667,
      "step": 21900
    },
    {
      "epoch": 2.3965141612200433,
      "grad_norm": 0.5102538466453552,
      "learning_rate": 1.0269970414201184e-05,
      "loss": 0.3384,
      "step": 22000
    },
    {
      "epoch": 2.4074074074074074,
      "grad_norm": 0.38287535309791565,
      "learning_rate": 1.0085059171597634e-05,
      "loss": 0.3669,
      "step": 22100
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.004434575326740742,
      "learning_rate": 9.900147928994083e-06,
      "loss": 0.3678,
      "step": 22200
    },
    {
      "epoch": 2.429193899782135,
      "grad_norm": 0.3990110754966736,
      "learning_rate": 9.715236686390533e-06,
      "loss": 0.3658,
      "step": 22300
    },
    {
      "epoch": 2.440087145969499,
      "grad_norm": 0.34602028131484985,
      "learning_rate": 9.530325443786983e-06,
      "loss": 0.418,
      "step": 22400
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 0.5666471719741821,
      "learning_rate": 9.345414201183432e-06,
      "loss": 0.3519,
      "step": 22500
    },
    {
      "epoch": 2.4618736383442266,
      "grad_norm": 0.7104515433311462,
      "learning_rate": 9.160502958579882e-06,
      "loss": 0.4078,
      "step": 22600
    },
    {
      "epoch": 2.47276688453159,
      "grad_norm": 0.7415529489517212,
      "learning_rate": 8.975591715976331e-06,
      "loss": 0.364,
      "step": 22700
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.5637965798377991,
      "learning_rate": 8.790680473372781e-06,
      "loss": 0.3296,
      "step": 22800
    },
    {
      "epoch": 2.494553376906318,
      "grad_norm": 0.42447662353515625,
      "learning_rate": 8.60576923076923e-06,
      "loss": 0.419,
      "step": 22900
    },
    {
      "epoch": 2.505446623093682,
      "grad_norm": 0.8567332029342651,
      "learning_rate": 8.420857988165682e-06,
      "loss": 0.3947,
      "step": 23000
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 0.8381098508834839,
      "learning_rate": 8.23594674556213e-06,
      "loss": 0.3792,
      "step": 23100
    },
    {
      "epoch": 2.52723311546841,
      "grad_norm": 0.5397210121154785,
      "learning_rate": 8.05103550295858e-06,
      "loss": 0.3313,
      "step": 23200
    },
    {
      "epoch": 2.5381263616557734,
      "grad_norm": 0.4445629119873047,
      "learning_rate": 7.86612426035503e-06,
      "loss": 0.3856,
      "step": 23300
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.8502700328826904,
      "learning_rate": 7.681213017751479e-06,
      "loss": 0.3671,
      "step": 23400
    },
    {
      "epoch": 2.559912854030501,
      "grad_norm": 0.5560805797576904,
      "learning_rate": 7.496301775147929e-06,
      "loss": 0.3147,
      "step": 23500
    },
    {
      "epoch": 2.570806100217865,
      "grad_norm": 0.2746567130088806,
      "learning_rate": 7.3113905325443796e-06,
      "loss": 0.3705,
      "step": 23600
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 0.28423798084259033,
      "learning_rate": 7.126479289940828e-06,
      "loss": 0.3358,
      "step": 23700
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.8298843502998352,
      "learning_rate": 6.941568047337278e-06,
      "loss": 0.3917,
      "step": 23800
    },
    {
      "epoch": 2.6034858387799567,
      "grad_norm": 0.5714948773384094,
      "learning_rate": 6.756656804733728e-06,
      "loss": 0.3985,
      "step": 23900
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.6326885223388672,
      "learning_rate": 6.571745562130179e-06,
      "loss": 0.3378,
      "step": 24000
    },
    {
      "epoch": 2.625272331154684,
      "grad_norm": 0.7956373691558838,
      "learning_rate": 6.388683431952663e-06,
      "loss": 0.3715,
      "step": 24100
    },
    {
      "epoch": 2.636165577342048,
      "grad_norm": 0.5360644459724426,
      "learning_rate": 6.203772189349113e-06,
      "loss": 0.3629,
      "step": 24200
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.6026975512504578,
      "learning_rate": 6.018860946745562e-06,
      "loss": 0.3414,
      "step": 24300
    },
    {
      "epoch": 2.6579520697167753,
      "grad_norm": 0.4610294997692108,
      "learning_rate": 5.833949704142013e-06,
      "loss": 0.3546,
      "step": 24400
    },
    {
      "epoch": 2.6688453159041394,
      "grad_norm": 0.004167500883340836,
      "learning_rate": 5.6490384615384615e-06,
      "loss": 0.3975,
      "step": 24500
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.7638142108917236,
      "learning_rate": 5.464127218934911e-06,
      "loss": 0.409,
      "step": 24600
    },
    {
      "epoch": 2.690631808278867,
      "grad_norm": 0.8402972221374512,
      "learning_rate": 5.2792159763313615e-06,
      "loss": 0.3799,
      "step": 24700
    },
    {
      "epoch": 2.701525054466231,
      "grad_norm": 0.5409176349639893,
      "learning_rate": 5.094304733727811e-06,
      "loss": 0.3451,
      "step": 24800
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 0.26006245613098145,
      "learning_rate": 4.909393491124261e-06,
      "loss": 0.3302,
      "step": 24900
    },
    {
      "epoch": 2.7233115468409586,
      "grad_norm": 0.4052956700325012,
      "learning_rate": 4.72448224852071e-06,
      "loss": 0.3463,
      "step": 25000
    },
    {
      "epoch": 2.734204793028322,
      "grad_norm": 0.667942464351654,
      "learning_rate": 4.53957100591716e-06,
      "loss": 0.3656,
      "step": 25100
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.5377097725868225,
      "learning_rate": 4.356508875739645e-06,
      "loss": 0.4038,
      "step": 25200
    },
    {
      "epoch": 2.7559912854030504,
      "grad_norm": 0.5598827600479126,
      "learning_rate": 4.171597633136095e-06,
      "loss": 0.3907,
      "step": 25300
    },
    {
      "epoch": 2.766884531590414,
      "grad_norm": 0.3098725378513336,
      "learning_rate": 3.986686390532544e-06,
      "loss": 0.3969,
      "step": 25400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.5143808722496033,
      "learning_rate": 3.8017751479289947e-06,
      "loss": 0.396,
      "step": 25500
    },
    {
      "epoch": 2.7886710239651418,
      "grad_norm": 0.4520931541919708,
      "learning_rate": 3.616863905325444e-06,
      "loss": 0.3412,
      "step": 25600
    },
    {
      "epoch": 2.7995642701525054,
      "grad_norm": 0.5730434656143188,
      "learning_rate": 3.4319526627218935e-06,
      "loss": 0.4152,
      "step": 25700
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.0042767454870045185,
      "learning_rate": 3.2470414201183435e-06,
      "loss": 0.3635,
      "step": 25800
    },
    {
      "epoch": 2.821350762527233,
      "grad_norm": 0.5552605390548706,
      "learning_rate": 3.062130177514793e-06,
      "loss": 0.3729,
      "step": 25900
    },
    {
      "epoch": 2.832244008714597,
      "grad_norm": 0.37423112988471985,
      "learning_rate": 2.8772189349112427e-06,
      "loss": 0.3811,
      "step": 26000
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 2.3796303272247314,
      "learning_rate": 2.6923076923076928e-06,
      "loss": 0.3871,
      "step": 26100
    },
    {
      "epoch": 2.8540305010893245,
      "grad_norm": 0.8867341876029968,
      "learning_rate": 2.507396449704142e-06,
      "loss": 0.3571,
      "step": 26200
    },
    {
      "epoch": 2.8649237472766886,
      "grad_norm": 0.6701913475990295,
      "learning_rate": 2.322485207100592e-06,
      "loss": 0.3834,
      "step": 26300
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.6783595681190491,
      "learning_rate": 2.1375739644970416e-06,
      "loss": 0.4242,
      "step": 26400
    },
    {
      "epoch": 2.886710239651416,
      "grad_norm": 0.408475399017334,
      "learning_rate": 1.952662721893491e-06,
      "loss": 0.4064,
      "step": 26500
    },
    {
      "epoch": 2.89760348583878,
      "grad_norm": 0.7773042321205139,
      "learning_rate": 1.7677514792899408e-06,
      "loss": 0.351,
      "step": 26600
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 0.7445942163467407,
      "learning_rate": 1.5828402366863906e-06,
      "loss": 0.3409,
      "step": 26700
    },
    {
      "epoch": 2.9193899782135078,
      "grad_norm": 0.44984427094459534,
      "learning_rate": 1.3979289940828402e-06,
      "loss": 0.3307,
      "step": 26800
    },
    {
      "epoch": 2.9302832244008714,
      "grad_norm": 0.5525537729263306,
      "learning_rate": 1.21301775147929e-06,
      "loss": 0.3834,
      "step": 26900
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.692561149597168,
      "learning_rate": 1.0281065088757396e-06,
      "loss": 0.4321,
      "step": 27000
    },
    {
      "epoch": 2.952069716775599,
      "grad_norm": 0.4233519732952118,
      "learning_rate": 8.431952662721895e-07,
      "loss": 0.3881,
      "step": 27100
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.0038918359205126762,
      "learning_rate": 6.582840236686391e-07,
      "loss": 0.3646,
      "step": 27200
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 1.606959581375122,
      "learning_rate": 4.733727810650888e-07,
      "loss": 0.3659,
      "step": 27300
    },
    {
      "epoch": 2.9847494553376905,
      "grad_norm": 1.8286799192428589,
      "learning_rate": 2.884615384615385e-07,
      "loss": 0.3597,
      "step": 27400
    },
    {
      "epoch": 2.9956427015250546,
      "grad_norm": 1.9591015577316284,
      "learning_rate": 1.0355029585798818e-07,
      "loss": 0.3772,
      "step": 27500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.380516916513443,
      "eval_runtime": 77.3492,
      "eval_samples_per_second": 48.611,
      "eval_steps_per_second": 12.153,
      "step": 27540
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2120172714288742e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
