{
  "best_metric": 0.3822547197341919,
  "best_model_checkpoint": "./results/Qwen/Qwen2-0.5B-Instruct_finetuned/checkpoint-9180",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 105.62371826171875,
      "learning_rate": 9.2e-06,
      "loss": 9.2428,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 2.6055655479431152,
      "learning_rate": 1.91e-05,
      "loss": 3.7343,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.6012031435966492,
      "learning_rate": 2.91e-05,
      "loss": 0.4123,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.2355773150920868,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.442,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.7239788770675659,
      "learning_rate": 4.9e-05,
      "loss": 0.5015,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 108.85816955566406,
      "learning_rate": 4.983357988165681e-05,
      "loss": 0.5353,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 16.85833740234375,
      "learning_rate": 4.964866863905326e-05,
      "loss": 0.4672,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 13.091717720031738,
      "learning_rate": 4.9463757396449707e-05,
      "loss": 0.4615,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.9120664596557617,
      "learning_rate": 4.927884615384616e-05,
      "loss": 0.4061,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.9277171492576599,
      "learning_rate": 4.9093934911242606e-05,
      "loss": 0.3784,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.4205596446990967,
      "learning_rate": 4.890902366863905e-05,
      "loss": 0.3912,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 2.127251148223877,
      "learning_rate": 4.8724112426035505e-05,
      "loss": 0.4142,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 21.504764556884766,
      "learning_rate": 4.853920118343195e-05,
      "loss": 0.4286,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.9009342789649963,
      "learning_rate": 4.8354289940828404e-05,
      "loss": 0.4762,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.49441197514533997,
      "learning_rate": 4.816937869822486e-05,
      "loss": 0.3702,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.34060677886009216,
      "learning_rate": 4.79844674556213e-05,
      "loss": 0.3885,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.40754181146621704,
      "learning_rate": 4.7799556213017756e-05,
      "loss": 0.38,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 6.363555431365967,
      "learning_rate": 4.76146449704142e-05,
      "loss": 0.4115,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.500272274017334,
      "learning_rate": 4.7429733727810656e-05,
      "loss": 0.3896,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.9673653244972229,
      "learning_rate": 4.72448224852071e-05,
      "loss": 0.341,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 85.03998565673828,
      "learning_rate": 4.7059911242603555e-05,
      "loss": 0.378,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.865860104560852,
      "learning_rate": 4.6875e-05,
      "loss": 0.3334,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.3088706135749817,
      "learning_rate": 4.669008875739645e-05,
      "loss": 0.4006,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.7995489835739136,
      "learning_rate": 4.65051775147929e-05,
      "loss": 0.4223,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 1.0194612741470337,
      "learning_rate": 4.632026627218935e-05,
      "loss": 0.3643,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.6931456923484802,
      "learning_rate": 4.6135355029585806e-05,
      "loss": 0.4372,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 1.0489588975906372,
      "learning_rate": 4.595044378698225e-05,
      "loss": 0.3684,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.7142845988273621,
      "learning_rate": 4.5765532544378705e-05,
      "loss": 0.3637,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.723638117313385,
      "learning_rate": 4.558062130177515e-05,
      "loss": 0.3636,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.7815013527870178,
      "learning_rate": 4.53957100591716e-05,
      "loss": 0.3123,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.6374711394309998,
      "learning_rate": 4.521079881656805e-05,
      "loss": 0.3637,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 1.0448187589645386,
      "learning_rate": 4.50258875739645e-05,
      "loss": 0.3616,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 1.0237454175949097,
      "learning_rate": 4.484097633136095e-05,
      "loss": 0.39,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.6566723585128784,
      "learning_rate": 4.4656065088757396e-05,
      "loss": 0.4541,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.6311634182929993,
      "learning_rate": 4.447115384615384e-05,
      "loss": 0.3346,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.9347183108329773,
      "learning_rate": 4.4286242603550295e-05,
      "loss": 0.4047,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.776522159576416,
      "learning_rate": 4.410133136094675e-05,
      "loss": 0.3676,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.8351211547851562,
      "learning_rate": 4.39164201183432e-05,
      "loss": 0.3762,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.7610623240470886,
      "learning_rate": 4.373150887573965e-05,
      "loss": 0.381,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.8610846400260925,
      "learning_rate": 4.35465976331361e-05,
      "loss": 0.421,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.411176472902298,
      "learning_rate": 4.336168639053255e-05,
      "loss": 0.3902,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.8221755623817444,
      "learning_rate": 4.317677514792899e-05,
      "loss": 0.3425,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.6072688102722168,
      "learning_rate": 4.2991863905325446e-05,
      "loss": 0.391,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.49926093220710754,
      "learning_rate": 4.280695266272189e-05,
      "loss": 0.3893,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.6220537424087524,
      "learning_rate": 4.2622041420118345e-05,
      "loss": 0.3625,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.878628134727478,
      "learning_rate": 4.243713017751479e-05,
      "loss": 0.3872,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.6484164595603943,
      "learning_rate": 4.2252218934911244e-05,
      "loss": 0.3769,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.5418857932090759,
      "learning_rate": 4.20673076923077e-05,
      "loss": 0.3303,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.5652867555618286,
      "learning_rate": 4.1882396449704144e-05,
      "loss": 0.3859,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.7693144083023071,
      "learning_rate": 4.1697485207100597e-05,
      "loss": 0.4203,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.5214940905570984,
      "learning_rate": 4.151257396449704e-05,
      "loss": 0.324,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.6434569358825684,
      "learning_rate": 4.1327662721893496e-05,
      "loss": 0.3901,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.8299868702888489,
      "learning_rate": 4.114275147928994e-05,
      "loss": 0.3879,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.8346062302589417,
      "learning_rate": 4.095784023668639e-05,
      "loss": 0.3903,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.39007505774497986,
      "learning_rate": 4.077292899408284e-05,
      "loss": 0.3553,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 1.0470235347747803,
      "learning_rate": 4.058801775147929e-05,
      "loss": 0.3852,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.4971875846385956,
      "learning_rate": 4.040310650887574e-05,
      "loss": 0.3496,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.5399430394172668,
      "learning_rate": 4.021819526627219e-05,
      "loss": 0.3419,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.8807582259178162,
      "learning_rate": 4.0033284023668646e-05,
      "loss": 0.3344,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.7638674378395081,
      "learning_rate": 3.984837278106509e-05,
      "loss": 0.4023,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.6130251884460449,
      "learning_rate": 3.966346153846154e-05,
      "loss": 0.3729,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.6843592524528503,
      "learning_rate": 3.947855029585799e-05,
      "loss": 0.4049,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.368865430355072,
      "learning_rate": 3.929363905325444e-05,
      "loss": 0.3742,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.35295844078063965,
      "learning_rate": 3.910872781065089e-05,
      "loss": 0.4053,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.3707742691040039,
      "learning_rate": 3.892381656804734e-05,
      "loss": 0.4015,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.9093976020812988,
      "learning_rate": 3.873890532544378e-05,
      "loss": 0.3514,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.8623837828636169,
      "learning_rate": 3.8553994082840236e-05,
      "loss": 0.4068,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.6721979975700378,
      "learning_rate": 3.836908284023669e-05,
      "loss": 0.3751,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.7002836465835571,
      "learning_rate": 3.818417159763314e-05,
      "loss": 0.4232,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.35613763332366943,
      "learning_rate": 3.799926035502959e-05,
      "loss": 0.4094,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.6556509137153625,
      "learning_rate": 3.781434911242604e-05,
      "loss": 0.3682,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.681384801864624,
      "learning_rate": 3.762943786982249e-05,
      "loss": 0.3763,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.43811357021331787,
      "learning_rate": 3.7444526627218934e-05,
      "loss": 0.3447,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.40129923820495605,
      "learning_rate": 3.725961538461539e-05,
      "loss": 0.4014,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.6946911215782166,
      "learning_rate": 3.707470414201183e-05,
      "loss": 0.3687,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.7925137281417847,
      "learning_rate": 3.6889792899408286e-05,
      "loss": 0.3539,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.535254716873169,
      "learning_rate": 3.670488165680473e-05,
      "loss": 0.3592,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.7346944808959961,
      "learning_rate": 3.6519970414201185e-05,
      "loss": 0.3878,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 1.034429907798767,
      "learning_rate": 3.633505917159764e-05,
      "loss": 0.3946,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.7240991592407227,
      "learning_rate": 3.6150147928994085e-05,
      "loss": 0.3661,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.417341947555542,
      "learning_rate": 3.596523668639054e-05,
      "loss": 0.3345,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.9493842124938965,
      "learning_rate": 3.5780325443786984e-05,
      "loss": 0.3939,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.9266827702522278,
      "learning_rate": 3.559541420118344e-05,
      "loss": 0.4019,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.7368626594543457,
      "learning_rate": 3.541050295857988e-05,
      "loss": 0.3582,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.5193295478820801,
      "learning_rate": 3.522559171597633e-05,
      "loss": 0.3789,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.9104666709899902,
      "learning_rate": 3.504068047337278e-05,
      "loss": 0.4312,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.5399556159973145,
      "learning_rate": 3.485576923076923e-05,
      "loss": 0.4232,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.5979005694389343,
      "learning_rate": 3.467085798816568e-05,
      "loss": 0.3542,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.6207601428031921,
      "learning_rate": 3.4485946745562134e-05,
      "loss": 0.3806,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.33755016326904297,
      "learning_rate": 3.430103550295858e-05,
      "loss": 0.3609,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.5451485514640808,
      "learning_rate": 3.4116124260355034e-05,
      "loss": 0.3418,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3822547197341919,
      "eval_runtime": 73.9697,
      "eval_samples_per_second": 50.832,
      "eval_steps_per_second": 12.708,
      "step": 9180
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.040057571429581e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
