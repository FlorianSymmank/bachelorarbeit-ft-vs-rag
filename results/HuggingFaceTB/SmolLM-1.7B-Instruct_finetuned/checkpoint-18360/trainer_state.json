{
  "best_metric": 0.34556326270103455,
  "best_model_checkpoint": "./results/HuggingFaceTB/SmolLM-1.7B-Instruct_finetuned/checkpoint-18360",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 18360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 10.202404975891113,
      "learning_rate": 9.4e-06,
      "loss": 18.4116,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 24.747426986694336,
      "learning_rate": 1.94e-05,
      "loss": 12.0648,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.4179091155529022,
      "learning_rate": 2.94e-05,
      "loss": 2.2882,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.0755775049328804,
      "learning_rate": 3.94e-05,
      "loss": 0.4402,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.13037656247615814,
      "learning_rate": 4.94e-05,
      "loss": 0.4098,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.05418256297707558,
      "learning_rate": 4.9826183431952665e-05,
      "loss": 0.4241,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.12606164813041687,
      "learning_rate": 4.964127218934911e-05,
      "loss": 0.4034,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.12901273369789124,
      "learning_rate": 4.9456360946745564e-05,
      "loss": 0.4116,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.16382232308387756,
      "learning_rate": 4.927144970414202e-05,
      "loss": 0.3681,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.05079525336623192,
      "learning_rate": 4.9086538461538464e-05,
      "loss": 0.3639,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.04782479256391525,
      "learning_rate": 4.8901627218934917e-05,
      "loss": 0.3799,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.09966930001974106,
      "learning_rate": 4.871671597633136e-05,
      "loss": 0.3852,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.12840193510055542,
      "learning_rate": 4.8531804733727816e-05,
      "loss": 0.4016,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.1889074444770813,
      "learning_rate": 4.834689349112426e-05,
      "loss": 0.4475,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.05398119240999222,
      "learning_rate": 4.8161982248520715e-05,
      "loss": 0.3495,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.06622859090566635,
      "learning_rate": 4.797707100591716e-05,
      "loss": 0.3742,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.02863861434161663,
      "learning_rate": 4.779215976331361e-05,
      "loss": 0.3498,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.29314371943473816,
      "learning_rate": 4.760724852071006e-05,
      "loss": 0.3763,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.062427323311567307,
      "learning_rate": 4.7422337278106513e-05,
      "loss": 0.3651,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.12179996073246002,
      "learning_rate": 4.723742603550296e-05,
      "loss": 0.3109,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.12951461970806122,
      "learning_rate": 4.705251479289941e-05,
      "loss": 0.3498,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.19646887481212616,
      "learning_rate": 4.686760355029586e-05,
      "loss": 0.3109,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.08163560926914215,
      "learning_rate": 4.668269230769231e-05,
      "loss": 0.3777,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.1627122163772583,
      "learning_rate": 4.649778106508876e-05,
      "loss": 0.3885,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.13221606612205505,
      "learning_rate": 4.631286982248521e-05,
      "loss": 0.3405,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.16222405433654785,
      "learning_rate": 4.612795857988166e-05,
      "loss": 0.4047,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.1986977607011795,
      "learning_rate": 4.594304733727811e-05,
      "loss": 0.3334,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.18935087323188782,
      "learning_rate": 4.5759985207100594e-05,
      "loss": 0.3474,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.18881405889987946,
      "learning_rate": 4.557507396449705e-05,
      "loss": 0.3352,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.12135960906744003,
      "learning_rate": 4.539016272189349e-05,
      "loss": 0.2938,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.15833397209644318,
      "learning_rate": 4.5205251479289946e-05,
      "loss": 0.3347,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.1996930092573166,
      "learning_rate": 4.502034023668639e-05,
      "loss": 0.328,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.25015756487846375,
      "learning_rate": 4.483542899408284e-05,
      "loss": 0.3618,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.1345953792333603,
      "learning_rate": 4.465051775147929e-05,
      "loss": 0.4182,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.19022555649280548,
      "learning_rate": 4.446560650887574e-05,
      "loss": 0.3161,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.23616495728492737,
      "learning_rate": 4.428069526627219e-05,
      "loss": 0.3687,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.2162170112133026,
      "learning_rate": 4.4095784023668643e-05,
      "loss": 0.3345,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.20552922785282135,
      "learning_rate": 4.3910872781065096e-05,
      "loss": 0.3487,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.204591304063797,
      "learning_rate": 4.372596153846154e-05,
      "loss": 0.3483,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.2627176344394684,
      "learning_rate": 4.354105029585799e-05,
      "loss": 0.3871,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.4026908278465271,
      "learning_rate": 4.335613905325444e-05,
      "loss": 0.3519,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.2215585857629776,
      "learning_rate": 4.317122781065089e-05,
      "loss": 0.3154,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.1443396806716919,
      "learning_rate": 4.298631656804734e-05,
      "loss": 0.3552,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.044494565576314926,
      "learning_rate": 4.280140532544379e-05,
      "loss": 0.3563,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.14184799790382385,
      "learning_rate": 4.261649408284024e-05,
      "loss": 0.3298,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.24986961483955383,
      "learning_rate": 4.2431582840236686e-05,
      "loss": 0.3549,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.19195714592933655,
      "learning_rate": 4.224667159763314e-05,
      "loss": 0.3402,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.16409572958946228,
      "learning_rate": 4.206176035502959e-05,
      "loss": 0.2981,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.1834597885608673,
      "learning_rate": 4.187684911242604e-05,
      "loss": 0.361,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.20354537665843964,
      "learning_rate": 4.169193786982249e-05,
      "loss": 0.3868,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.14501361548900604,
      "learning_rate": 4.150702662721894e-05,
      "loss": 0.2916,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.12868736684322357,
      "learning_rate": 4.1322115384615384e-05,
      "loss": 0.3509,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.1682722568511963,
      "learning_rate": 4.113720414201184e-05,
      "loss": 0.3542,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.25890910625457764,
      "learning_rate": 4.095229289940828e-05,
      "loss": 0.3527,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.15371482074260712,
      "learning_rate": 4.0767381656804736e-05,
      "loss": 0.3253,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.26127567887306213,
      "learning_rate": 4.058247041420118e-05,
      "loss": 0.3607,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.12872643768787384,
      "learning_rate": 4.0397559171597635e-05,
      "loss": 0.3212,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.15838801860809326,
      "learning_rate": 4.021264792899408e-05,
      "loss": 0.3117,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.2455035001039505,
      "learning_rate": 4.0027736686390535e-05,
      "loss": 0.3043,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.20444710552692413,
      "learning_rate": 3.984282544378699e-05,
      "loss": 0.3672,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.1894065886735916,
      "learning_rate": 3.9657914201183434e-05,
      "loss": 0.3319,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.17011885344982147,
      "learning_rate": 3.947300295857989e-05,
      "loss": 0.3726,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.1111421138048172,
      "learning_rate": 3.928809171597633e-05,
      "loss": 0.3409,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.08676633983850479,
      "learning_rate": 3.910318047337278e-05,
      "loss": 0.3703,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.0649731382727623,
      "learning_rate": 3.891826923076923e-05,
      "loss": 0.3639,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.24836425483226776,
      "learning_rate": 3.873335798816568e-05,
      "loss": 0.3198,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.2881031036376953,
      "learning_rate": 3.854844674556213e-05,
      "loss": 0.3674,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.17470021545886993,
      "learning_rate": 3.836353550295858e-05,
      "loss": 0.3432,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.20273207128047943,
      "learning_rate": 3.817862426035503e-05,
      "loss": 0.3842,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.06761541962623596,
      "learning_rate": 3.7993713017751484e-05,
      "loss": 0.3694,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.15280619263648987,
      "learning_rate": 3.780880177514793e-05,
      "loss": 0.3332,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.138803169131279,
      "learning_rate": 3.762389053254438e-05,
      "loss": 0.3456,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.12431109696626663,
      "learning_rate": 3.743897928994083e-05,
      "loss": 0.3145,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.11979172378778458,
      "learning_rate": 3.725406804733728e-05,
      "loss": 0.3662,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.19156068563461304,
      "learning_rate": 3.706915680473373e-05,
      "loss": 0.3312,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.17729784548282623,
      "learning_rate": 3.688424556213018e-05,
      "loss": 0.3223,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.1818736493587494,
      "learning_rate": 3.669933431952663e-05,
      "loss": 0.3238,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.22786156833171844,
      "learning_rate": 3.6514423076923074e-05,
      "loss": 0.354,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.2734528183937073,
      "learning_rate": 3.632951183431953e-05,
      "loss": 0.3595,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.24442268908023834,
      "learning_rate": 3.614460059171598e-05,
      "loss": 0.3312,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.12845642864704132,
      "learning_rate": 3.595968934911243e-05,
      "loss": 0.2996,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.21891959011554718,
      "learning_rate": 3.577477810650888e-05,
      "loss": 0.3574,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.22715559601783752,
      "learning_rate": 3.5589866863905325e-05,
      "loss": 0.3645,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.12405971437692642,
      "learning_rate": 3.540495562130178e-05,
      "loss": 0.328,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.12705278396606445,
      "learning_rate": 3.522189349112426e-05,
      "loss": 0.3454,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.1322285681962967,
      "learning_rate": 3.5036982248520714e-05,
      "loss": 0.3883,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.15869903564453125,
      "learning_rate": 3.485207100591716e-05,
      "loss": 0.3824,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.17268365621566772,
      "learning_rate": 3.4667159763313614e-05,
      "loss": 0.3273,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.24670852720737457,
      "learning_rate": 3.448224852071006e-05,
      "loss": 0.3441,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.10388366132974625,
      "learning_rate": 3.429733727810651e-05,
      "loss": 0.3293,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.1363777220249176,
      "learning_rate": 3.411242603550296e-05,
      "loss": 0.3074,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3480151891708374,
      "eval_runtime": 162.5374,
      "eval_samples_per_second": 23.133,
      "eval_steps_per_second": 5.783,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.1295882761478424,
      "learning_rate": 3.392751479289941e-05,
      "loss": 0.3166,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.17867009341716766,
      "learning_rate": 3.374260355029586e-05,
      "loss": 0.3655,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.17165888845920563,
      "learning_rate": 3.3557692307692304e-05,
      "loss": 0.3492,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.21851535141468048,
      "learning_rate": 3.337278106508876e-05,
      "loss": 0.3344,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.2005460262298584,
      "learning_rate": 3.3187869822485204e-05,
      "loss": 0.3124,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.2112969607114792,
      "learning_rate": 3.300295857988166e-05,
      "loss": 0.3458,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.21598592400550842,
      "learning_rate": 3.281804733727811e-05,
      "loss": 0.3056,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.24844151735305786,
      "learning_rate": 3.263313609467456e-05,
      "loss": 0.3212,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.10980769246816635,
      "learning_rate": 3.244822485207101e-05,
      "loss": 0.3416,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 0.24628335237503052,
      "learning_rate": 3.2263313609467455e-05,
      "loss": 0.346,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.11974045634269714,
      "learning_rate": 3.207840236686391e-05,
      "loss": 0.3292,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 0.24853059649467468,
      "learning_rate": 3.1893491124260354e-05,
      "loss": 0.3422,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 0.2580288052558899,
      "learning_rate": 3.170857988165681e-05,
      "loss": 0.3498,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.10699180513620377,
      "learning_rate": 3.1523668639053253e-05,
      "loss": 0.3567,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.24070991575717926,
      "learning_rate": 3.1338757396449706e-05,
      "loss": 0.3527,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.3577801585197449,
      "learning_rate": 3.115384615384615e-05,
      "loss": 0.319,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.20760983228683472,
      "learning_rate": 3.0968934911242606e-05,
      "loss": 0.3388,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.05383550375699997,
      "learning_rate": 3.078402366863906e-05,
      "loss": 0.3365,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.17032983899116516,
      "learning_rate": 3.0599112426035505e-05,
      "loss": 0.341,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.26285332441329956,
      "learning_rate": 3.0414201183431958e-05,
      "loss": 0.3414,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 0.26076191663742065,
      "learning_rate": 3.0229289940828404e-05,
      "loss": 0.3305,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.1571454405784607,
      "learning_rate": 3.004437869822485e-05,
      "loss": 0.3507,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.20765085518360138,
      "learning_rate": 2.9859467455621303e-05,
      "loss": 0.3633,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.19134800136089325,
      "learning_rate": 2.9674556213017753e-05,
      "loss": 0.3211,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.27166974544525146,
      "learning_rate": 2.9489644970414202e-05,
      "loss": 0.3631,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.16866657137870789,
      "learning_rate": 2.9304733727810652e-05,
      "loss": 0.3042,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.033148281276226044,
      "learning_rate": 2.9119822485207105e-05,
      "loss": 0.3416,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.24400462210178375,
      "learning_rate": 2.893491124260355e-05,
      "loss": 0.3462,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.0005499105900526047,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.3261,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.2687492370605469,
      "learning_rate": 2.856508875739645e-05,
      "loss": 0.3322,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.11816928535699844,
      "learning_rate": 2.83801775147929e-05,
      "loss": 0.3728,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.23878395557403564,
      "learning_rate": 2.8195266272189353e-05,
      "loss": 0.3416,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.11017780750989914,
      "learning_rate": 2.80103550295858e-05,
      "loss": 0.3575,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.10931181162595749,
      "learning_rate": 2.7825443786982252e-05,
      "loss": 0.3637,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.16247397661209106,
      "learning_rate": 2.76405325443787e-05,
      "loss": 0.2927,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.2155086249113083,
      "learning_rate": 2.7455621301775148e-05,
      "loss": 0.3457,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.2770383358001709,
      "learning_rate": 2.72707100591716e-05,
      "loss": 0.3267,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.17775370180606842,
      "learning_rate": 2.7085798816568047e-05,
      "loss": 0.3453,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.12175928056240082,
      "learning_rate": 2.69008875739645e-05,
      "loss": 0.3329,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 0.3013369143009186,
      "learning_rate": 2.6715976331360946e-05,
      "loss": 0.317,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.2796021103858948,
      "learning_rate": 2.6531065088757396e-05,
      "loss": 0.3734,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.22323459386825562,
      "learning_rate": 2.634615384615385e-05,
      "loss": 0.3059,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.21187864243984222,
      "learning_rate": 2.6161242603550295e-05,
      "loss": 0.2826,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.361630380153656,
      "learning_rate": 2.5976331360946748e-05,
      "loss": 0.3634,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.05022856965661049,
      "learning_rate": 2.5791420118343194e-05,
      "loss": 0.3724,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.021330637857317924,
      "learning_rate": 2.5606508875739647e-05,
      "loss": 0.3082,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.1431906819343567,
      "learning_rate": 2.5421597633136097e-05,
      "loss": 0.3232,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.09541945159435272,
      "learning_rate": 2.5236686390532543e-05,
      "loss": 0.3429,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.16580411791801453,
      "learning_rate": 2.5051775147928996e-05,
      "loss": 0.3054,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.17430804669857025,
      "learning_rate": 2.4866863905325442e-05,
      "loss": 0.3221,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 0.21085786819458008,
      "learning_rate": 2.4681952662721895e-05,
      "loss": 0.3521,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.1979880928993225,
      "learning_rate": 2.4497041420118345e-05,
      "loss": 0.3245,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.19119736552238464,
      "learning_rate": 2.4312130177514795e-05,
      "loss": 0.3637,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.18685124814510345,
      "learning_rate": 2.4127218934911244e-05,
      "loss": 0.3304,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.10904156416654587,
      "learning_rate": 2.3942307692307694e-05,
      "loss": 0.3435,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.21480156481266022,
      "learning_rate": 2.3757396449704143e-05,
      "loss": 0.2973,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.08528705686330795,
      "learning_rate": 2.3572485207100593e-05,
      "loss": 0.3553,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 0.16283877193927765,
      "learning_rate": 2.3387573964497043e-05,
      "loss": 0.2999,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.2362067848443985,
      "learning_rate": 2.3202662721893492e-05,
      "loss": 0.3249,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.11280771344900131,
      "learning_rate": 2.3017751479289942e-05,
      "loss": 0.3325,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.21272629499435425,
      "learning_rate": 2.283284023668639e-05,
      "loss": 0.3269,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.024504318833351135,
      "learning_rate": 2.264792899408284e-05,
      "loss": 0.3439,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.23519612848758698,
      "learning_rate": 2.246301775147929e-05,
      "loss": 0.3453,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.27159401774406433,
      "learning_rate": 2.227810650887574e-05,
      "loss": 0.3083,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.1295700967311859,
      "learning_rate": 2.209319526627219e-05,
      "loss": 0.3256,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.10546217858791351,
      "learning_rate": 2.190828402366864e-05,
      "loss": 0.349,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 0.10096969455480576,
      "learning_rate": 2.172337278106509e-05,
      "loss": 0.2868,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.0642644390463829,
      "learning_rate": 2.1538461538461542e-05,
      "loss": 0.328,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 0.13915786147117615,
      "learning_rate": 2.1353550295857988e-05,
      "loss": 0.324,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.1961098313331604,
      "learning_rate": 2.1168639053254438e-05,
      "loss": 0.3749,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.2729574143886566,
      "learning_rate": 2.0985576923076925e-05,
      "loss": 0.3699,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.26185452938079834,
      "learning_rate": 2.0800665680473374e-05,
      "loss": 0.3844,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.1762312799692154,
      "learning_rate": 2.0615754437869824e-05,
      "loss": 0.322,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.18508976697921753,
      "learning_rate": 2.0430843195266273e-05,
      "loss": 0.3361,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 0.23551113903522491,
      "learning_rate": 2.0245931952662723e-05,
      "loss": 0.3706,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.032335877418518066,
      "learning_rate": 2.0061020710059173e-05,
      "loss": 0.3312,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.18832990527153015,
      "learning_rate": 1.9876109467455622e-05,
      "loss": 0.3382,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.08398588746786118,
      "learning_rate": 1.9691198224852072e-05,
      "loss": 0.3703,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.14638182520866394,
      "learning_rate": 1.950628698224852e-05,
      "loss": 0.3234,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.06936682015657425,
      "learning_rate": 1.932137573964497e-05,
      "loss": 0.3535,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.25185254216194153,
      "learning_rate": 1.913646449704142e-05,
      "loss": 0.3401,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.15272803604602814,
      "learning_rate": 1.895155325443787e-05,
      "loss": 0.3352,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.1697985678911209,
      "learning_rate": 1.876664201183432e-05,
      "loss": 0.3471,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.16440364718437195,
      "learning_rate": 1.858173076923077e-05,
      "loss": 0.3304,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.11450856924057007,
      "learning_rate": 1.8396819526627222e-05,
      "loss": 0.3412,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.2548016607761383,
      "learning_rate": 1.821190828402367e-05,
      "loss": 0.3409,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.051023803651332855,
      "learning_rate": 1.8026997041420118e-05,
      "loss": 0.3389,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.1097753494977951,
      "learning_rate": 1.7842085798816568e-05,
      "loss": 0.3136,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": NaN,
      "learning_rate": 1.7659023668639055e-05,
      "loss": 0.3463,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.18044988811016083,
      "learning_rate": 1.7474112426035504e-05,
      "loss": 0.3464,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.15953132510185242,
      "learning_rate": 1.7289201183431954e-05,
      "loss": 0.3503,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.09403881430625916,
      "learning_rate": 1.7104289940828404e-05,
      "loss": 0.3345,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.34556326270103455,
      "eval_runtime": 162.6896,
      "eval_samples_per_second": 23.112,
      "eval_steps_per_second": 5.778,
      "step": 18360
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.6354686592221184e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
