{
  "best_metric": 0.3402848243713379,
  "best_model_checkpoint": "./results/stabilityai/stablelm-2-1_6b-chat_finetuned/checkpoint-27540",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 27540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 55.089744567871094,
      "learning_rate": 9.4e-06,
      "loss": 10.6828,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 0.752615213394165,
      "learning_rate": 1.93e-05,
      "loss": 2.6834,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.7172284126281738,
      "learning_rate": 2.93e-05,
      "loss": 0.3928,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.2722102999687195,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.3912,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.4664934277534485,
      "learning_rate": 4.93e-05,
      "loss": 0.3719,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.2196418046951294,
      "learning_rate": 4.98280325443787e-05,
      "loss": 0.3782,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.4949098825454712,
      "learning_rate": 4.9643121301775155e-05,
      "loss": 0.3636,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.45592623949050903,
      "learning_rate": 4.94582100591716e-05,
      "loss": 0.3794,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.5538867115974426,
      "learning_rate": 4.927329881656805e-05,
      "loss": 0.3334,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.25675317645072937,
      "learning_rate": 4.90883875739645e-05,
      "loss": 0.335,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.147898331284523,
      "learning_rate": 4.890347633136095e-05,
      "loss": 0.3479,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.40344178676605225,
      "learning_rate": 4.87185650887574e-05,
      "loss": 0.3661,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.45365530252456665,
      "learning_rate": 4.8533653846153846e-05,
      "loss": 0.3765,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.5299400687217712,
      "learning_rate": 4.834874260355029e-05,
      "loss": 0.4201,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.23613637685775757,
      "learning_rate": 4.8163831360946745e-05,
      "loss": 0.3357,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.19029651582241058,
      "learning_rate": 4.79789201183432e-05,
      "loss": 0.3449,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.15804798901081085,
      "learning_rate": 4.779400887573965e-05,
      "loss": 0.3368,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.7801129221916199,
      "learning_rate": 4.76090976331361e-05,
      "loss": 0.3531,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.17849820852279663,
      "learning_rate": 4.742603550295858e-05,
      "loss": 0.3452,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.36214521527290344,
      "learning_rate": 4.724112426035503e-05,
      "loss": 0.2996,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.6680884957313538,
      "learning_rate": 4.705621301775148e-05,
      "loss": 0.3375,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.5754653215408325,
      "learning_rate": 4.687130177514793e-05,
      "loss": 0.295,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.23009802401065826,
      "learning_rate": 4.668639053254438e-05,
      "loss": 0.3592,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.4689042568206787,
      "learning_rate": 4.650147928994083e-05,
      "loss": 0.3768,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.43022510409355164,
      "learning_rate": 4.631656804733728e-05,
      "loss": 0.3259,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 10.964241981506348,
      "learning_rate": 4.613165680473373e-05,
      "loss": 0.389,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5543901920318604,
      "learning_rate": 4.594674556213018e-05,
      "loss": 0.3273,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.5382692217826843,
      "learning_rate": 4.576183431952663e-05,
      "loss": 0.3257,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.5290961861610413,
      "learning_rate": 4.557692307692308e-05,
      "loss": 0.3229,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.38377368450164795,
      "learning_rate": 4.539201183431953e-05,
      "loss": 0.2789,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.3884059488773346,
      "learning_rate": 4.5207100591715976e-05,
      "loss": 0.3227,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.6102374196052551,
      "learning_rate": 4.502218934911242e-05,
      "loss": 0.3211,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.6515123248100281,
      "learning_rate": 4.4837278106508876e-05,
      "loss": 0.35,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.35295647382736206,
      "learning_rate": 4.465236686390533e-05,
      "loss": 0.4064,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.4813276529312134,
      "learning_rate": 4.446745562130178e-05,
      "loss": 0.3004,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.6485409736633301,
      "learning_rate": 4.428254437869823e-05,
      "loss": 0.3634,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5327566862106323,
      "learning_rate": 4.409763313609468e-05,
      "loss": 0.3286,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.47332555055618286,
      "learning_rate": 4.391272189349113e-05,
      "loss": 0.3372,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.5165919065475464,
      "learning_rate": 4.372781065088757e-05,
      "loss": 0.341,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.5201700329780579,
      "learning_rate": 4.3542899408284026e-05,
      "loss": 0.3774,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.2728283703327179,
      "learning_rate": 4.335798816568047e-05,
      "loss": 0.3466,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.5965912938117981,
      "learning_rate": 4.3173076923076925e-05,
      "loss": 0.3085,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.3426434397697449,
      "learning_rate": 4.298816568047337e-05,
      "loss": 0.3496,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.14336124062538147,
      "learning_rate": 4.2803254437869824e-05,
      "loss": 0.3505,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.4112838804721832,
      "learning_rate": 4.261834319526628e-05,
      "loss": 0.3254,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.6258859038352966,
      "learning_rate": 4.2433431952662724e-05,
      "loss": 0.3465,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.49914228916168213,
      "learning_rate": 4.224852071005918e-05,
      "loss": 0.3382,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.37115979194641113,
      "learning_rate": 4.206360946745562e-05,
      "loss": 0.2959,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.4355422258377075,
      "learning_rate": 4.1878698224852076e-05,
      "loss": 0.3468,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5299144387245178,
      "learning_rate": 4.169378698224852e-05,
      "loss": 0.3792,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.3743817210197449,
      "learning_rate": 4.150887573964497e-05,
      "loss": 0.2873,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.2842583656311035,
      "learning_rate": 4.132396449704142e-05,
      "loss": 0.3476,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.40866780281066895,
      "learning_rate": 4.113905325443787e-05,
      "loss": 0.3449,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.6741466522216797,
      "learning_rate": 4.095414201183432e-05,
      "loss": 0.3496,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.32453545928001404,
      "learning_rate": 4.0769230769230773e-05,
      "loss": 0.3166,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.570182204246521,
      "learning_rate": 4.0584319526627226e-05,
      "loss": 0.3424,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 1.3129000663757324,
      "learning_rate": 4.039940828402367e-05,
      "loss": 0.3119,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.36641982197761536,
      "learning_rate": 4.021449704142012e-05,
      "loss": 0.3044,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.41946572065353394,
      "learning_rate": 4.002958579881657e-05,
      "loss": 0.2975,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.6438071131706238,
      "learning_rate": 3.984467455621302e-05,
      "loss": 0.3563,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.4193032383918762,
      "learning_rate": 3.965976331360947e-05,
      "loss": 0.3312,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.4889548420906067,
      "learning_rate": 3.947485207100592e-05,
      "loss": 0.3593,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.27095699310302734,
      "learning_rate": 3.9289940828402364e-05,
      "loss": 0.3349,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.24983209371566772,
      "learning_rate": 3.9105029585798816e-05,
      "loss": 0.3604,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.16062688827514648,
      "learning_rate": 3.892011834319527e-05,
      "loss": 0.3585,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.627445638179779,
      "learning_rate": 3.873520710059172e-05,
      "loss": 0.3122,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.47996124625205994,
      "learning_rate": 3.855029585798817e-05,
      "loss": 0.3632,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.42834237217903137,
      "learning_rate": 3.836538461538462e-05,
      "loss": 0.3317,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.5936610698699951,
      "learning_rate": 3.818047337278107e-05,
      "loss": 0.3754,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.15372228622436523,
      "learning_rate": 3.7995562130177514e-05,
      "loss": 0.3637,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.40033209323883057,
      "learning_rate": 3.781065088757397e-05,
      "loss": 0.3264,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.4785565435886383,
      "learning_rate": 3.762573964497041e-05,
      "loss": 0.3335,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.33510205149650574,
      "learning_rate": 3.7440828402366866e-05,
      "loss": 0.3074,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.2882387042045593,
      "learning_rate": 3.725591715976331e-05,
      "loss": 0.355,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.43327340483665466,
      "learning_rate": 3.7071005917159765e-05,
      "loss": 0.3288,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.5716768503189087,
      "learning_rate": 3.688609467455622e-05,
      "loss": 0.3145,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3299937844276428,
      "learning_rate": 3.6701183431952665e-05,
      "loss": 0.3209,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5112987756729126,
      "learning_rate": 3.651627218934912e-05,
      "loss": 0.348,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.693402111530304,
      "learning_rate": 3.6331360946745564e-05,
      "loss": 0.3534,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.6532469987869263,
      "learning_rate": 3.614644970414202e-05,
      "loss": 0.328,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.40952321887016296,
      "learning_rate": 3.596153846153846e-05,
      "loss": 0.3002,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.25254398584365845,
      "learning_rate": 3.577662721893491e-05,
      "loss": 0.3497,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.5576775074005127,
      "learning_rate": 3.559171597633136e-05,
      "loss": 0.3576,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.21366597712039948,
      "learning_rate": 3.540680473372781e-05,
      "loss": 0.3203,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3009472191333771,
      "learning_rate": 3.522189349112426e-05,
      "loss": 0.3386,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.1837523728609085,
      "learning_rate": 3.5036982248520714e-05,
      "loss": 0.3852,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.42382562160491943,
      "learning_rate": 3.485207100591716e-05,
      "loss": 0.3782,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.43138930201530457,
      "learning_rate": 3.4667159763313614e-05,
      "loss": 0.3156,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.506370484828949,
      "learning_rate": 3.448224852071006e-05,
      "loss": 0.3413,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.2113662213087082,
      "learning_rate": 3.429733727810651e-05,
      "loss": 0.321,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.4137279987335205,
      "learning_rate": 3.411242603550296e-05,
      "loss": 0.3045,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.34202200174331665,
      "eval_runtime": 132.9655,
      "eval_samples_per_second": 28.278,
      "eval_steps_per_second": 7.07,
      "step": 9180
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 0.37118127942085266,
      "learning_rate": 3.392751479289941e-05,
      "loss": 0.314,
      "step": 9200
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.5361920595169067,
      "learning_rate": 3.374260355029586e-05,
      "loss": 0.3638,
      "step": 9300
    },
    {
      "epoch": 1.0239651416122004,
      "grad_norm": 0.5060569643974304,
      "learning_rate": 3.3557692307692304e-05,
      "loss": 0.3399,
      "step": 9400
    },
    {
      "epoch": 1.0348583877995643,
      "grad_norm": 0.5774902701377869,
      "learning_rate": 3.337278106508876e-05,
      "loss": 0.3275,
      "step": 9500
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.5259742736816406,
      "learning_rate": 3.3187869822485204e-05,
      "loss": 0.303,
      "step": 9600
    },
    {
      "epoch": 1.056644880174292,
      "grad_norm": 0.6346148252487183,
      "learning_rate": 3.300295857988166e-05,
      "loss": 0.3375,
      "step": 9700
    },
    {
      "epoch": 1.0675381263616557,
      "grad_norm": 0.5102452635765076,
      "learning_rate": 3.281804733727811e-05,
      "loss": 0.2957,
      "step": 9800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.6737669706344604,
      "learning_rate": 3.263313609467456e-05,
      "loss": 0.3147,
      "step": 9900
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 0.28088968992233276,
      "learning_rate": 3.244822485207101e-05,
      "loss": 0.3342,
      "step": 10000
    },
    {
      "epoch": 1.1002178649237473,
      "grad_norm": 0.6427978873252869,
      "learning_rate": 3.2263313609467455e-05,
      "loss": 0.3424,
      "step": 10100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.3554701805114746,
      "learning_rate": 3.207840236686391e-05,
      "loss": 0.3255,
      "step": 10200
    },
    {
      "epoch": 1.122004357298475,
      "grad_norm": 0.471605122089386,
      "learning_rate": 3.1893491124260354e-05,
      "loss": 0.3339,
      "step": 10300
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 0.6775126457214355,
      "learning_rate": 3.170857988165681e-05,
      "loss": 0.3366,
      "step": 10400
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.3449634313583374,
      "learning_rate": 3.1523668639053253e-05,
      "loss": 0.3478,
      "step": 10500
    },
    {
      "epoch": 1.1546840958605664,
      "grad_norm": 0.6176945567131042,
      "learning_rate": 3.1338757396449706e-05,
      "loss": 0.3392,
      "step": 10600
    },
    {
      "epoch": 1.1655773420479303,
      "grad_norm": 0.5235493183135986,
      "learning_rate": 3.115384615384615e-05,
      "loss": 0.3162,
      "step": 10700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.4136418104171753,
      "learning_rate": 3.0968934911242606e-05,
      "loss": 0.3294,
      "step": 10800
    },
    {
      "epoch": 1.187363834422658,
      "grad_norm": 0.18776483833789825,
      "learning_rate": 3.078402366863906e-05,
      "loss": 0.3329,
      "step": 10900
    },
    {
      "epoch": 1.1982570806100217,
      "grad_norm": 0.4795582592487335,
      "learning_rate": 3.0599112426035505e-05,
      "loss": 0.3302,
      "step": 11000
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.6963767409324646,
      "learning_rate": 3.0414201183431958e-05,
      "loss": 0.3391,
      "step": 11100
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 0.6844226717948914,
      "learning_rate": 3.0229289940828404e-05,
      "loss": 0.3227,
      "step": 11200
    },
    {
      "epoch": 1.2309368191721133,
      "grad_norm": 0.31852036714553833,
      "learning_rate": 3.004437869822485e-05,
      "loss": 0.3425,
      "step": 11300
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.5360894799232483,
      "learning_rate": 2.9859467455621303e-05,
      "loss": 0.3573,
      "step": 11400
    },
    {
      "epoch": 1.252723311546841,
      "grad_norm": 0.49224087595939636,
      "learning_rate": 2.9674556213017753e-05,
      "loss": 0.3166,
      "step": 11500
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 0.6789183616638184,
      "learning_rate": 2.9489644970414202e-05,
      "loss": 0.3533,
      "step": 11600
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.46507611870765686,
      "learning_rate": 2.9304733727810652e-05,
      "loss": 0.2958,
      "step": 11700
    },
    {
      "epoch": 1.2854030501089324,
      "grad_norm": 0.13732406497001648,
      "learning_rate": 2.9119822485207105e-05,
      "loss": 0.3351,
      "step": 11800
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.6054152250289917,
      "learning_rate": 2.893491124260355e-05,
      "loss": 0.3411,
      "step": 11900
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.0006715451600030065,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.3222,
      "step": 12000
    },
    {
      "epoch": 1.318082788671024,
      "grad_norm": 0.6399731636047363,
      "learning_rate": 2.856508875739645e-05,
      "loss": 0.3229,
      "step": 12100
    },
    {
      "epoch": 1.3289760348583877,
      "grad_norm": 0.32210811972618103,
      "learning_rate": 2.83801775147929e-05,
      "loss": 0.3614,
      "step": 12200
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.5203412175178528,
      "learning_rate": 2.8195266272189353e-05,
      "loss": 0.3316,
      "step": 12300
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 0.2910449504852295,
      "learning_rate": 2.8012204142011833e-05,
      "loss": 0.3551,
      "step": 12400
    },
    {
      "epoch": 1.3616557734204793,
      "grad_norm": 0.3023012578487396,
      "learning_rate": 2.7827292899408286e-05,
      "loss": 0.3499,
      "step": 12500
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.31839337944984436,
      "learning_rate": 2.7642381656804732e-05,
      "loss": 0.2866,
      "step": 12600
    },
    {
      "epoch": 1.383442265795207,
      "grad_norm": 0.5204738974571228,
      "learning_rate": 2.7457470414201185e-05,
      "loss": 0.3415,
      "step": 12700
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.7520673274993896,
      "learning_rate": 2.7272559171597635e-05,
      "loss": 0.313,
      "step": 12800
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.4923194944858551,
      "learning_rate": 2.7087647928994088e-05,
      "loss": 0.3336,
      "step": 12900
    },
    {
      "epoch": 1.4161220043572984,
      "grad_norm": 0.32948020100593567,
      "learning_rate": 2.6902736686390534e-05,
      "loss": 0.3267,
      "step": 13000
    },
    {
      "epoch": 1.4270152505446623,
      "grad_norm": 0.4897218942642212,
      "learning_rate": 2.671782544378698e-05,
      "loss": 0.311,
      "step": 13100
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.7274028062820435,
      "learning_rate": 2.6532914201183433e-05,
      "loss": 0.3687,
      "step": 13200
    },
    {
      "epoch": 1.44880174291939,
      "grad_norm": 0.5709896087646484,
      "learning_rate": 2.6348002958579883e-05,
      "loss": 0.3056,
      "step": 13300
    },
    {
      "epoch": 1.4596949891067539,
      "grad_norm": 0.9481261372566223,
      "learning_rate": 2.6163091715976336e-05,
      "loss": 0.2784,
      "step": 13400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.0179810523986816,
      "learning_rate": 2.5978180473372782e-05,
      "loss": 0.354,
      "step": 13500
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.11687304824590683,
      "learning_rate": 2.5793269230769235e-05,
      "loss": 0.3657,
      "step": 13600
    },
    {
      "epoch": 1.4923747276688453,
      "grad_norm": 0.10932960361242294,
      "learning_rate": 2.560835798816568e-05,
      "loss": 0.2968,
      "step": 13700
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.44177523255348206,
      "learning_rate": 2.542344674556213e-05,
      "loss": 0.3152,
      "step": 13800
    },
    {
      "epoch": 1.514161220043573,
      "grad_norm": 0.21610663831233978,
      "learning_rate": 2.5238535502958584e-05,
      "loss": 0.3392,
      "step": 13900
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 0.4077690839767456,
      "learning_rate": 2.505362426035503e-05,
      "loss": 0.2997,
      "step": 14000
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 0.4468502104282379,
      "learning_rate": 2.486871301775148e-05,
      "loss": 0.3129,
      "step": 14100
    },
    {
      "epoch": 1.5468409586056646,
      "grad_norm": 0.6239659190177917,
      "learning_rate": 2.468380177514793e-05,
      "loss": 0.3416,
      "step": 14200
    },
    {
      "epoch": 1.5577342047930283,
      "grad_norm": 0.4520465135574341,
      "learning_rate": 2.449889053254438e-05,
      "loss": 0.3205,
      "step": 14300
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.47372058033943176,
      "learning_rate": 2.4313979289940832e-05,
      "loss": 0.3604,
      "step": 14400
    },
    {
      "epoch": 1.579520697167756,
      "grad_norm": 0.5488377809524536,
      "learning_rate": 2.412906804733728e-05,
      "loss": 0.3264,
      "step": 14500
    },
    {
      "epoch": 1.5904139433551199,
      "grad_norm": 0.2689151167869568,
      "learning_rate": 2.3944156804733728e-05,
      "loss": 0.3338,
      "step": 14600
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 0.4983134865760803,
      "learning_rate": 2.3759245562130177e-05,
      "loss": 0.2937,
      "step": 14700
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 0.25053200125694275,
      "learning_rate": 2.3574334319526627e-05,
      "loss": 0.3526,
      "step": 14800
    },
    {
      "epoch": 1.6230936819172115,
      "grad_norm": 0.4409714937210083,
      "learning_rate": 2.338942307692308e-05,
      "loss": 0.2932,
      "step": 14900
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.5897258520126343,
      "learning_rate": 2.320451183431953e-05,
      "loss": 0.3152,
      "step": 15000
    },
    {
      "epoch": 1.644880174291939,
      "grad_norm": 0.24090620875358582,
      "learning_rate": 2.301960059171598e-05,
      "loss": 0.3245,
      "step": 15100
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 0.5587374567985535,
      "learning_rate": 2.2834689349112425e-05,
      "loss": 0.3173,
      "step": 15200
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.0999952182173729,
      "learning_rate": 2.2649778106508875e-05,
      "loss": 0.3378,
      "step": 15300
    },
    {
      "epoch": 1.6775599128540306,
      "grad_norm": 0.6785791516304016,
      "learning_rate": 2.2464866863905325e-05,
      "loss": 0.3452,
      "step": 15400
    },
    {
      "epoch": 1.6884531590413943,
      "grad_norm": 0.6003766655921936,
      "learning_rate": 2.2279955621301777e-05,
      "loss": 0.2991,
      "step": 15500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.32943955063819885,
      "learning_rate": 2.2095044378698227e-05,
      "loss": 0.3226,
      "step": 15600
    },
    {
      "epoch": 1.710239651416122,
      "grad_norm": 0.24225445091724396,
      "learning_rate": 2.1910133136094677e-05,
      "loss": 0.3391,
      "step": 15700
    },
    {
      "epoch": 1.7211328976034859,
      "grad_norm": 0.22469010949134827,
      "learning_rate": 2.1725221893491126e-05,
      "loss": 0.2828,
      "step": 15800
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 0.14733469486236572,
      "learning_rate": 2.1540310650887573e-05,
      "loss": 0.3228,
      "step": 15900
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 0.26349008083343506,
      "learning_rate": 2.1355399408284025e-05,
      "loss": 0.3171,
      "step": 16000
    },
    {
      "epoch": 1.7538126361655775,
      "grad_norm": 0.4855821132659912,
      "learning_rate": 2.1170488165680475e-05,
      "loss": 0.3655,
      "step": 16100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.5871396660804749,
      "learning_rate": 2.0985576923076925e-05,
      "loss": 0.3583,
      "step": 16200
    },
    {
      "epoch": 1.775599128540305,
      "grad_norm": 0.6782153844833374,
      "learning_rate": 2.0800665680473374e-05,
      "loss": 0.3747,
      "step": 16300
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 0.6844796538352966,
      "learning_rate": 2.0615754437869824e-05,
      "loss": 0.3173,
      "step": 16400
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.5044263601303101,
      "learning_rate": 2.0430843195266273e-05,
      "loss": 0.3322,
      "step": 16500
    },
    {
      "epoch": 1.8082788671023966,
      "grad_norm": 0.572893500328064,
      "learning_rate": 2.0245931952662723e-05,
      "loss": 0.3627,
      "step": 16600
    },
    {
      "epoch": 1.8191721132897603,
      "grad_norm": 0.1170722171664238,
      "learning_rate": 2.0061020710059173e-05,
      "loss": 0.3242,
      "step": 16700
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.44304361939430237,
      "learning_rate": 1.9876109467455622e-05,
      "loss": 0.3309,
      "step": 16800
    },
    {
      "epoch": 1.840958605664488,
      "grad_norm": 0.30047884583473206,
      "learning_rate": 1.9691198224852072e-05,
      "loss": 0.3653,
      "step": 16900
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.33631592988967896,
      "learning_rate": 1.950628698224852e-05,
      "loss": 0.3149,
      "step": 17000
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.2271062731742859,
      "learning_rate": 1.932137573964497e-05,
      "loss": 0.345,
      "step": 17100
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 0.6042652130126953,
      "learning_rate": 1.913646449704142e-05,
      "loss": 0.3283,
      "step": 17200
    },
    {
      "epoch": 1.8845315904139435,
      "grad_norm": 0.3785965144634247,
      "learning_rate": 1.8953402366863908e-05,
      "loss": 0.3307,
      "step": 17300
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.35872194170951843,
      "learning_rate": 1.8768491124260357e-05,
      "loss": 0.3391,
      "step": 17400
    },
    {
      "epoch": 1.906318082788671,
      "grad_norm": 0.43217897415161133,
      "learning_rate": 1.8583579881656807e-05,
      "loss": 0.3182,
      "step": 17500
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 0.3302152752876282,
      "learning_rate": 1.8398668639053253e-05,
      "loss": 0.334,
      "step": 17600
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 0.6458600163459778,
      "learning_rate": 1.8213757396449706e-05,
      "loss": 0.3407,
      "step": 17700
    },
    {
      "epoch": 1.9389978213507626,
      "grad_norm": 0.15382103621959686,
      "learning_rate": 1.8028846153846156e-05,
      "loss": 0.3255,
      "step": 17800
    },
    {
      "epoch": 1.9498910675381262,
      "grad_norm": 0.28734004497528076,
      "learning_rate": 1.7843934911242605e-05,
      "loss": 0.3081,
      "step": 17900
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.4511219263076782,
      "learning_rate": 1.7659023668639055e-05,
      "loss": 0.3232,
      "step": 18000
    },
    {
      "epoch": 1.971677559912854,
      "grad_norm": 0.4805167615413666,
      "learning_rate": 1.7474112426035504e-05,
      "loss": 0.3363,
      "step": 18100
    },
    {
      "epoch": 1.9825708061002179,
      "grad_norm": 0.4614277780056,
      "learning_rate": 1.7289201183431954e-05,
      "loss": 0.3436,
      "step": 18200
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 0.24928073585033417,
      "learning_rate": 1.7104289940828404e-05,
      "loss": 0.3219,
      "step": 18300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.34056299924850464,
      "eval_runtime": 132.9229,
      "eval_samples_per_second": 28.287,
      "eval_steps_per_second": 7.072,
      "step": 18360
    },
    {
      "epoch": 2.0043572984749454,
      "grad_norm": 0.40440434217453003,
      "learning_rate": 1.6919378698224853e-05,
      "loss": 0.3316,
      "step": 18400
    },
    {
      "epoch": 2.0152505446623095,
      "grad_norm": 0.35644450783729553,
      "learning_rate": 1.6734467455621303e-05,
      "loss": 0.3193,
      "step": 18500
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.31512343883514404,
      "learning_rate": 1.6549556213017752e-05,
      "loss": 0.3221,
      "step": 18600
    },
    {
      "epoch": 2.037037037037037,
      "grad_norm": 0.770400881767273,
      "learning_rate": 1.6364644970414202e-05,
      "loss": 0.3079,
      "step": 18700
    },
    {
      "epoch": 2.047930283224401,
      "grad_norm": 0.6590482592582703,
      "learning_rate": 1.617973372781065e-05,
      "loss": 0.3114,
      "step": 18800
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.3966089189052582,
      "learning_rate": 1.59948224852071e-05,
      "loss": 0.3049,
      "step": 18900
    },
    {
      "epoch": 2.0697167755991286,
      "grad_norm": 0.4662024676799774,
      "learning_rate": 1.580991124260355e-05,
      "loss": 0.3229,
      "step": 19000
    },
    {
      "epoch": 2.0806100217864922,
      "grad_norm": 0.5575804710388184,
      "learning_rate": 1.5625e-05,
      "loss": 0.3087,
      "step": 19100
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.6104158163070679,
      "learning_rate": 1.544008875739645e-05,
      "loss": 0.3341,
      "step": 19200
    },
    {
      "epoch": 2.10239651416122,
      "grad_norm": 11.003497123718262,
      "learning_rate": 1.5255177514792901e-05,
      "loss": 0.3127,
      "step": 19300
    },
    {
      "epoch": 2.113289760348584,
      "grad_norm": 0.35803869366645813,
      "learning_rate": 1.507026627218935e-05,
      "loss": 0.3494,
      "step": 19400
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 0.6268186569213867,
      "learning_rate": 1.4885355029585799e-05,
      "loss": 0.3046,
      "step": 19500
    },
    {
      "epoch": 2.1350762527233114,
      "grad_norm": 0.36508986353874207,
      "learning_rate": 1.4700443786982248e-05,
      "loss": 0.3318,
      "step": 19600
    },
    {
      "epoch": 2.1459694989106755,
      "grad_norm": 0.6430808901786804,
      "learning_rate": 1.45155325443787e-05,
      "loss": 0.3435,
      "step": 19700
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.5012984275817871,
      "learning_rate": 1.433062130177515e-05,
      "loss": 0.336,
      "step": 19800
    },
    {
      "epoch": 2.167755991285403,
      "grad_norm": 0.28415432572364807,
      "learning_rate": 1.4145710059171599e-05,
      "loss": 0.3205,
      "step": 19900
    },
    {
      "epoch": 2.178649237472767,
      "grad_norm": 0.23302558064460754,
      "learning_rate": 1.3960798816568048e-05,
      "loss": 0.3305,
      "step": 20000
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 0.3213450610637665,
      "learning_rate": 1.3775887573964496e-05,
      "loss": 0.365,
      "step": 20100
    },
    {
      "epoch": 2.2004357298474946,
      "grad_norm": 0.9829449653625488,
      "learning_rate": 1.3590976331360946e-05,
      "loss": 0.3229,
      "step": 20200
    },
    {
      "epoch": 2.2113289760348582,
      "grad_norm": 0.3341066837310791,
      "learning_rate": 1.3406065088757397e-05,
      "loss": 0.2923,
      "step": 20300
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.4346153736114502,
      "learning_rate": 1.3221153846153847e-05,
      "loss": 0.2928,
      "step": 20400
    },
    {
      "epoch": 2.233115468409586,
      "grad_norm": 0.2938001751899719,
      "learning_rate": 1.3036242603550296e-05,
      "loss": 0.3049,
      "step": 20500
    },
    {
      "epoch": 2.24400871459695,
      "grad_norm": 0.44897574186325073,
      "learning_rate": 1.2851331360946748e-05,
      "loss": 0.3237,
      "step": 20600
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 0.5755824446678162,
      "learning_rate": 1.2666420118343194e-05,
      "loss": 0.3268,
      "step": 20700
    },
    {
      "epoch": 2.265795206971678,
      "grad_norm": 0.6337593197822571,
      "learning_rate": 1.2481508875739647e-05,
      "loss": 0.3603,
      "step": 20800
    },
    {
      "epoch": 2.2766884531590414,
      "grad_norm": 0.46823716163635254,
      "learning_rate": 1.229844674556213e-05,
      "loss": 0.3543,
      "step": 20900
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.7522816061973572,
      "learning_rate": 1.211353550295858e-05,
      "loss": 0.3311,
      "step": 21000
    },
    {
      "epoch": 2.298474945533769,
      "grad_norm": 0.7304108142852783,
      "learning_rate": 1.192862426035503e-05,
      "loss": 0.2984,
      "step": 21100
    },
    {
      "epoch": 2.309368191721133,
      "grad_norm": 0.2084091305732727,
      "learning_rate": 1.1743713017751481e-05,
      "loss": 0.321,
      "step": 21200
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 0.5090867280960083,
      "learning_rate": 1.155880177514793e-05,
      "loss": 0.3383,
      "step": 21300
    },
    {
      "epoch": 2.3311546840958606,
      "grad_norm": 0.44246914982795715,
      "learning_rate": 1.1375739644970416e-05,
      "loss": 0.3552,
      "step": 21400
    },
    {
      "epoch": 2.342047930283224,
      "grad_norm": 0.601832926273346,
      "learning_rate": 1.1190828402366863e-05,
      "loss": 0.3267,
      "step": 21500
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.39372915029525757,
      "learning_rate": 1.1005917159763315e-05,
      "loss": 0.3129,
      "step": 21600
    },
    {
      "epoch": 2.363834422657952,
      "grad_norm": 0.7278059124946594,
      "learning_rate": 1.0821005917159764e-05,
      "loss": 0.2961,
      "step": 21700
    },
    {
      "epoch": 2.374727668845316,
      "grad_norm": 0.6050499081611633,
      "learning_rate": 1.0636094674556212e-05,
      "loss": 0.338,
      "step": 21800
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 0.563778281211853,
      "learning_rate": 1.0451183431952664e-05,
      "loss": 0.3205,
      "step": 21900
    },
    {
      "epoch": 2.3965141612200433,
      "grad_norm": 0.4967847764492035,
      "learning_rate": 1.0266272189349113e-05,
      "loss": 0.2978,
      "step": 22000
    },
    {
      "epoch": 2.4074074074074074,
      "grad_norm": 0.35417917370796204,
      "learning_rate": 1.0081360946745563e-05,
      "loss": 0.3227,
      "step": 22100
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.0010693032527342439,
      "learning_rate": 9.896449704142012e-06,
      "loss": 0.3238,
      "step": 22200
    },
    {
      "epoch": 2.429193899782135,
      "grad_norm": 0.36042165756225586,
      "learning_rate": 9.711538461538462e-06,
      "loss": 0.3202,
      "step": 22300
    },
    {
      "epoch": 2.440087145969499,
      "grad_norm": 0.3381052017211914,
      "learning_rate": 9.526627218934912e-06,
      "loss": 0.3662,
      "step": 22400
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 0.4684167802333832,
      "learning_rate": 9.341715976331361e-06,
      "loss": 0.3078,
      "step": 22500
    },
    {
      "epoch": 2.4618736383442266,
      "grad_norm": 0.6968412399291992,
      "learning_rate": 9.15680473372781e-06,
      "loss": 0.357,
      "step": 22600
    },
    {
      "epoch": 2.47276688453159,
      "grad_norm": 0.5702014565467834,
      "learning_rate": 8.971893491124262e-06,
      "loss": 0.3168,
      "step": 22700
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.5166116952896118,
      "learning_rate": 8.78698224852071e-06,
      "loss": 0.2908,
      "step": 22800
    },
    {
      "epoch": 2.494553376906318,
      "grad_norm": 0.4688570499420166,
      "learning_rate": 8.60207100591716e-06,
      "loss": 0.3673,
      "step": 22900
    },
    {
      "epoch": 2.505446623093682,
      "grad_norm": 3.5541458129882812,
      "learning_rate": 8.417159763313611e-06,
      "loss": 0.3473,
      "step": 23000
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 0.6468369960784912,
      "learning_rate": 8.232248520710059e-06,
      "loss": 0.3337,
      "step": 23100
    },
    {
      "epoch": 2.52723311546841,
      "grad_norm": 0.4751010239124298,
      "learning_rate": 8.04733727810651e-06,
      "loss": 0.2908,
      "step": 23200
    },
    {
      "epoch": 2.5381263616557734,
      "grad_norm": 0.6008033156394958,
      "learning_rate": 7.86242603550296e-06,
      "loss": 0.3379,
      "step": 23300
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.7613735198974609,
      "learning_rate": 7.677514792899408e-06,
      "loss": 0.3215,
      "step": 23400
    },
    {
      "epoch": 2.559912854030501,
      "grad_norm": 0.40668001770973206,
      "learning_rate": 7.492603550295858e-06,
      "loss": 0.2739,
      "step": 23500
    },
    {
      "epoch": 2.570806100217865,
      "grad_norm": 0.1355678290128708,
      "learning_rate": 7.3076923076923085e-06,
      "loss": 0.3253,
      "step": 23600
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 0.3084687888622284,
      "learning_rate": 7.122781065088757e-06,
      "loss": 0.2937,
      "step": 23700
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.6645896434783936,
      "learning_rate": 6.937869822485208e-06,
      "loss": 0.342,
      "step": 23800
    },
    {
      "epoch": 2.6034858387799567,
      "grad_norm": 0.42489731311798096,
      "learning_rate": 6.752958579881657e-06,
      "loss": 0.3509,
      "step": 23900
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.606938898563385,
      "learning_rate": 6.568047337278106e-06,
      "loss": 0.2975,
      "step": 24000
    },
    {
      "epoch": 2.625272331154684,
      "grad_norm": 0.41112759709358215,
      "learning_rate": 6.3831360946745565e-06,
      "loss": 0.3242,
      "step": 24100
    },
    {
      "epoch": 2.636165577342048,
      "grad_norm": 0.4929637610912323,
      "learning_rate": 6.198224852071006e-06,
      "loss": 0.3177,
      "step": 24200
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.48866164684295654,
      "learning_rate": 6.013313609467456e-06,
      "loss": 0.298,
      "step": 24300
    },
    {
      "epoch": 2.6579520697167753,
      "grad_norm": 0.40884479880332947,
      "learning_rate": 5.830251479289941e-06,
      "loss": 0.3112,
      "step": 24400
    },
    {
      "epoch": 2.6688453159041394,
      "grad_norm": 0.001580980489961803,
      "learning_rate": 5.645340236686391e-06,
      "loss": 0.3504,
      "step": 24500
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.48677316308021545,
      "learning_rate": 5.46042899408284e-06,
      "loss": 0.3591,
      "step": 24600
    },
    {
      "epoch": 2.690631808278867,
      "grad_norm": 0.703615128993988,
      "learning_rate": 5.27551775147929e-06,
      "loss": 0.3332,
      "step": 24700
    },
    {
      "epoch": 2.701525054466231,
      "grad_norm": 0.4166734218597412,
      "learning_rate": 5.09060650887574e-06,
      "loss": 0.3047,
      "step": 24800
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 0.2650297284126282,
      "learning_rate": 4.90569526627219e-06,
      "loss": 0.2906,
      "step": 24900
    },
    {
      "epoch": 2.7233115468409586,
      "grad_norm": 0.4470681846141815,
      "learning_rate": 4.720784023668639e-06,
      "loss": 0.3029,
      "step": 25000
    },
    {
      "epoch": 2.734204793028322,
      "grad_norm": 0.6035124659538269,
      "learning_rate": 4.535872781065089e-06,
      "loss": 0.3202,
      "step": 25100
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.47366732358932495,
      "learning_rate": 4.3509615384615385e-06,
      "loss": 0.3552,
      "step": 25200
    },
    {
      "epoch": 2.7559912854030504,
      "grad_norm": 0.3329267203807831,
      "learning_rate": 4.166050295857989e-06,
      "loss": 0.3421,
      "step": 25300
    },
    {
      "epoch": 2.766884531590414,
      "grad_norm": 0.2932263910770416,
      "learning_rate": 3.981139053254438e-06,
      "loss": 0.3495,
      "step": 25400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.5046412944793701,
      "learning_rate": 3.7962278106508877e-06,
      "loss": 0.3481,
      "step": 25500
    },
    {
      "epoch": 2.7886710239651418,
      "grad_norm": 0.3864251971244812,
      "learning_rate": 3.6113165680473377e-06,
      "loss": 0.3022,
      "step": 25600
    },
    {
      "epoch": 2.7995642701525054,
      "grad_norm": 0.5184235572814941,
      "learning_rate": 3.426405325443787e-06,
      "loss": 0.3674,
      "step": 25700
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.0013061834033578634,
      "learning_rate": 3.2414940828402365e-06,
      "loss": 0.32,
      "step": 25800
    },
    {
      "epoch": 2.821350762527233,
      "grad_norm": 0.42900797724723816,
      "learning_rate": 3.058431952662722e-06,
      "loss": 0.3286,
      "step": 25900
    },
    {
      "epoch": 2.832244008714597,
      "grad_norm": 0.359091192483902,
      "learning_rate": 2.873520710059172e-06,
      "loss": 0.3326,
      "step": 26000
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 0.10181742906570435,
      "learning_rate": 2.6886094674556213e-06,
      "loss": 0.3403,
      "step": 26100
    },
    {
      "epoch": 2.8540305010893245,
      "grad_norm": 0.3926907181739807,
      "learning_rate": 2.5036982248520713e-06,
      "loss": 0.3139,
      "step": 26200
    },
    {
      "epoch": 2.8649237472766886,
      "grad_norm": 0.5378299951553345,
      "learning_rate": 2.318786982248521e-06,
      "loss": 0.3368,
      "step": 26300
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.5029115676879883,
      "learning_rate": 2.135724852071006e-06,
      "loss": 0.3734,
      "step": 26400
    },
    {
      "epoch": 2.886710239651416,
      "grad_norm": 0.36714762449264526,
      "learning_rate": 1.9508136094674556e-06,
      "loss": 0.3598,
      "step": 26500
    },
    {
      "epoch": 2.89760348583878,
      "grad_norm": 0.633794367313385,
      "learning_rate": 1.7659023668639054e-06,
      "loss": 0.3092,
      "step": 26600
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 0.564524233341217,
      "learning_rate": 1.5809911242603552e-06,
      "loss": 0.2966,
      "step": 26700
    },
    {
      "epoch": 2.9193899782135078,
      "grad_norm": 0.49158480763435364,
      "learning_rate": 1.3960798816568048e-06,
      "loss": 0.289,
      "step": 26800
    },
    {
      "epoch": 2.9302832244008714,
      "grad_norm": 0.46929192543029785,
      "learning_rate": 1.2111686390532544e-06,
      "loss": 0.3364,
      "step": 26900
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.5369512438774109,
      "learning_rate": 1.0262573964497043e-06,
      "loss": 0.3819,
      "step": 27000
    },
    {
      "epoch": 2.952069716775599,
      "grad_norm": 0.2664756178855896,
      "learning_rate": 8.413461538461539e-07,
      "loss": 0.3421,
      "step": 27100
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.0017595946555957198,
      "learning_rate": 6.564349112426036e-07,
      "loss": 0.3197,
      "step": 27200
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 0.6644044518470764,
      "learning_rate": 4.7152366863905327e-07,
      "loss": 0.321,
      "step": 27300
    },
    {
      "epoch": 2.9847494553376905,
      "grad_norm": 0.2759222090244293,
      "learning_rate": 2.8661242603550297e-07,
      "loss": 0.3143,
      "step": 27400
    },
    {
      "epoch": 2.9956427015250546,
      "grad_norm": 0.4437488317489624,
      "learning_rate": 1.0170118343195266e-07,
      "loss": 0.3335,
      "step": 27500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.3402848243713379,
      "eval_runtime": 132.6937,
      "eval_samples_per_second": 28.336,
      "eval_steps_per_second": 7.084,
      "step": 27540
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.87211892612268e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
