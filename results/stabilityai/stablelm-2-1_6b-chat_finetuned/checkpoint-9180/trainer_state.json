{
  "best_metric": 0.34202200174331665,
  "best_model_checkpoint": "./results/stabilityai/stablelm-2-1_6b-chat_finetuned/checkpoint-9180",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 55.089744567871094,
      "learning_rate": 9.4e-06,
      "loss": 10.6828,
      "step": 100
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 0.752615213394165,
      "learning_rate": 1.93e-05,
      "loss": 2.6834,
      "step": 200
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.7172284126281738,
      "learning_rate": 2.93e-05,
      "loss": 0.3928,
      "step": 300
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.2722102999687195,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.3912,
      "step": 400
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.4664934277534485,
      "learning_rate": 4.93e-05,
      "loss": 0.3719,
      "step": 500
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.2196418046951294,
      "learning_rate": 4.98280325443787e-05,
      "loss": 0.3782,
      "step": 600
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.4949098825454712,
      "learning_rate": 4.9643121301775155e-05,
      "loss": 0.3636,
      "step": 700
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.45592623949050903,
      "learning_rate": 4.94582100591716e-05,
      "loss": 0.3794,
      "step": 800
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.5538867115974426,
      "learning_rate": 4.927329881656805e-05,
      "loss": 0.3334,
      "step": 900
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.25675317645072937,
      "learning_rate": 4.90883875739645e-05,
      "loss": 0.335,
      "step": 1000
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.147898331284523,
      "learning_rate": 4.890347633136095e-05,
      "loss": 0.3479,
      "step": 1100
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.40344178676605225,
      "learning_rate": 4.87185650887574e-05,
      "loss": 0.3661,
      "step": 1200
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.45365530252456665,
      "learning_rate": 4.8533653846153846e-05,
      "loss": 0.3765,
      "step": 1300
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.5299400687217712,
      "learning_rate": 4.834874260355029e-05,
      "loss": 0.4201,
      "step": 1400
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.23613637685775757,
      "learning_rate": 4.8163831360946745e-05,
      "loss": 0.3357,
      "step": 1500
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.19029651582241058,
      "learning_rate": 4.79789201183432e-05,
      "loss": 0.3449,
      "step": 1600
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.15804798901081085,
      "learning_rate": 4.779400887573965e-05,
      "loss": 0.3368,
      "step": 1700
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.7801129221916199,
      "learning_rate": 4.76090976331361e-05,
      "loss": 0.3531,
      "step": 1800
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.17849820852279663,
      "learning_rate": 4.742603550295858e-05,
      "loss": 0.3452,
      "step": 1900
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.36214521527290344,
      "learning_rate": 4.724112426035503e-05,
      "loss": 0.2996,
      "step": 2000
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.6680884957313538,
      "learning_rate": 4.705621301775148e-05,
      "loss": 0.3375,
      "step": 2100
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.5754653215408325,
      "learning_rate": 4.687130177514793e-05,
      "loss": 0.295,
      "step": 2200
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.23009802401065826,
      "learning_rate": 4.668639053254438e-05,
      "loss": 0.3592,
      "step": 2300
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.4689042568206787,
      "learning_rate": 4.650147928994083e-05,
      "loss": 0.3768,
      "step": 2400
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.43022510409355164,
      "learning_rate": 4.631656804733728e-05,
      "loss": 0.3259,
      "step": 2500
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 10.964241981506348,
      "learning_rate": 4.613165680473373e-05,
      "loss": 0.389,
      "step": 2600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5543901920318604,
      "learning_rate": 4.594674556213018e-05,
      "loss": 0.3273,
      "step": 2700
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.5382692217826843,
      "learning_rate": 4.576183431952663e-05,
      "loss": 0.3257,
      "step": 2800
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.5290961861610413,
      "learning_rate": 4.557692307692308e-05,
      "loss": 0.3229,
      "step": 2900
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.38377368450164795,
      "learning_rate": 4.539201183431953e-05,
      "loss": 0.2789,
      "step": 3000
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.3884059488773346,
      "learning_rate": 4.5207100591715976e-05,
      "loss": 0.3227,
      "step": 3100
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.6102374196052551,
      "learning_rate": 4.502218934911242e-05,
      "loss": 0.3211,
      "step": 3200
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.6515123248100281,
      "learning_rate": 4.4837278106508876e-05,
      "loss": 0.35,
      "step": 3300
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.35295647382736206,
      "learning_rate": 4.465236686390533e-05,
      "loss": 0.4064,
      "step": 3400
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.4813276529312134,
      "learning_rate": 4.446745562130178e-05,
      "loss": 0.3004,
      "step": 3500
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.6485409736633301,
      "learning_rate": 4.428254437869823e-05,
      "loss": 0.3634,
      "step": 3600
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.5327566862106323,
      "learning_rate": 4.409763313609468e-05,
      "loss": 0.3286,
      "step": 3700
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.47332555055618286,
      "learning_rate": 4.391272189349113e-05,
      "loss": 0.3372,
      "step": 3800
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.5165919065475464,
      "learning_rate": 4.372781065088757e-05,
      "loss": 0.341,
      "step": 3900
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.5201700329780579,
      "learning_rate": 4.3542899408284026e-05,
      "loss": 0.3774,
      "step": 4000
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.2728283703327179,
      "learning_rate": 4.335798816568047e-05,
      "loss": 0.3466,
      "step": 4100
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.5965912938117981,
      "learning_rate": 4.3173076923076925e-05,
      "loss": 0.3085,
      "step": 4200
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.3426434397697449,
      "learning_rate": 4.298816568047337e-05,
      "loss": 0.3496,
      "step": 4300
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.14336124062538147,
      "learning_rate": 4.2803254437869824e-05,
      "loss": 0.3505,
      "step": 4400
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.4112838804721832,
      "learning_rate": 4.261834319526628e-05,
      "loss": 0.3254,
      "step": 4500
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.6258859038352966,
      "learning_rate": 4.2433431952662724e-05,
      "loss": 0.3465,
      "step": 4600
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.49914228916168213,
      "learning_rate": 4.224852071005918e-05,
      "loss": 0.3382,
      "step": 4700
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.37115979194641113,
      "learning_rate": 4.206360946745562e-05,
      "loss": 0.2959,
      "step": 4800
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.4355422258377075,
      "learning_rate": 4.1878698224852076e-05,
      "loss": 0.3468,
      "step": 4900
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.5299144387245178,
      "learning_rate": 4.169378698224852e-05,
      "loss": 0.3792,
      "step": 5000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.3743817210197449,
      "learning_rate": 4.150887573964497e-05,
      "loss": 0.2873,
      "step": 5100
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.2842583656311035,
      "learning_rate": 4.132396449704142e-05,
      "loss": 0.3476,
      "step": 5200
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.40866780281066895,
      "learning_rate": 4.113905325443787e-05,
      "loss": 0.3449,
      "step": 5300
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.6741466522216797,
      "learning_rate": 4.095414201183432e-05,
      "loss": 0.3496,
      "step": 5400
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.32453545928001404,
      "learning_rate": 4.0769230769230773e-05,
      "loss": 0.3166,
      "step": 5500
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.570182204246521,
      "learning_rate": 4.0584319526627226e-05,
      "loss": 0.3424,
      "step": 5600
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 1.3129000663757324,
      "learning_rate": 4.039940828402367e-05,
      "loss": 0.3119,
      "step": 5700
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.36641982197761536,
      "learning_rate": 4.021449704142012e-05,
      "loss": 0.3044,
      "step": 5800
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.41946572065353394,
      "learning_rate": 4.002958579881657e-05,
      "loss": 0.2975,
      "step": 5900
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.6438071131706238,
      "learning_rate": 3.984467455621302e-05,
      "loss": 0.3563,
      "step": 6000
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.4193032383918762,
      "learning_rate": 3.965976331360947e-05,
      "loss": 0.3312,
      "step": 6100
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.4889548420906067,
      "learning_rate": 3.947485207100592e-05,
      "loss": 0.3593,
      "step": 6200
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.27095699310302734,
      "learning_rate": 3.9289940828402364e-05,
      "loss": 0.3349,
      "step": 6300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.24983209371566772,
      "learning_rate": 3.9105029585798816e-05,
      "loss": 0.3604,
      "step": 6400
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.16062688827514648,
      "learning_rate": 3.892011834319527e-05,
      "loss": 0.3585,
      "step": 6500
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.627445638179779,
      "learning_rate": 3.873520710059172e-05,
      "loss": 0.3122,
      "step": 6600
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.47996124625205994,
      "learning_rate": 3.855029585798817e-05,
      "loss": 0.3632,
      "step": 6700
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.42834237217903137,
      "learning_rate": 3.836538461538462e-05,
      "loss": 0.3317,
      "step": 6800
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.5936610698699951,
      "learning_rate": 3.818047337278107e-05,
      "loss": 0.3754,
      "step": 6900
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.15372228622436523,
      "learning_rate": 3.7995562130177514e-05,
      "loss": 0.3637,
      "step": 7000
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.40033209323883057,
      "learning_rate": 3.781065088757397e-05,
      "loss": 0.3264,
      "step": 7100
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.4785565435886383,
      "learning_rate": 3.762573964497041e-05,
      "loss": 0.3335,
      "step": 7200
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.33510205149650574,
      "learning_rate": 3.7440828402366866e-05,
      "loss": 0.3074,
      "step": 7300
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.2882387042045593,
      "learning_rate": 3.725591715976331e-05,
      "loss": 0.355,
      "step": 7400
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.43327340483665466,
      "learning_rate": 3.7071005917159765e-05,
      "loss": 0.3288,
      "step": 7500
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.5716768503189087,
      "learning_rate": 3.688609467455622e-05,
      "loss": 0.3145,
      "step": 7600
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.3299937844276428,
      "learning_rate": 3.6701183431952665e-05,
      "loss": 0.3209,
      "step": 7700
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.5112987756729126,
      "learning_rate": 3.651627218934912e-05,
      "loss": 0.348,
      "step": 7800
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.693402111530304,
      "learning_rate": 3.6331360946745564e-05,
      "loss": 0.3534,
      "step": 7900
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.6532469987869263,
      "learning_rate": 3.614644970414202e-05,
      "loss": 0.328,
      "step": 8000
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.40952321887016296,
      "learning_rate": 3.596153846153846e-05,
      "loss": 0.3002,
      "step": 8100
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.25254398584365845,
      "learning_rate": 3.577662721893491e-05,
      "loss": 0.3497,
      "step": 8200
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.5576775074005127,
      "learning_rate": 3.559171597633136e-05,
      "loss": 0.3576,
      "step": 8300
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.21366597712039948,
      "learning_rate": 3.540680473372781e-05,
      "loss": 0.3203,
      "step": 8400
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.3009472191333771,
      "learning_rate": 3.522189349112426e-05,
      "loss": 0.3386,
      "step": 8500
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.1837523728609085,
      "learning_rate": 3.5036982248520714e-05,
      "loss": 0.3852,
      "step": 8600
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.42382562160491943,
      "learning_rate": 3.485207100591716e-05,
      "loss": 0.3782,
      "step": 8700
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.43138930201530457,
      "learning_rate": 3.4667159763313614e-05,
      "loss": 0.3156,
      "step": 8800
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.506370484828949,
      "learning_rate": 3.448224852071006e-05,
      "loss": 0.3413,
      "step": 8900
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.2113662213087082,
      "learning_rate": 3.429733727810651e-05,
      "loss": 0.321,
      "step": 9000
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.4137279987335205,
      "learning_rate": 3.411242603550296e-05,
      "loss": 0.3045,
      "step": 9100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.34202200174331665,
      "eval_runtime": 132.9655,
      "eval_samples_per_second": 28.278,
      "eval_steps_per_second": 7.07,
      "step": 9180
    }
  ],
  "logging_steps": 100,
  "max_steps": 27540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6240396420408934e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
